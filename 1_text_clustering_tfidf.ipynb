{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3181f415-767a-4ee2-ae56-80627a8291b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4beac865-c98d-44b9-a94a-fb02e3cd6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ddc7d49-b6a3-46e4-9c4a-fb92e881f23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "import jsonpickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import set_config\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4bfcdf-c558-4d15-ad97-65f6f29229f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.clean.clean_data\n",
    "from src.clean.clean_data import TextCleaner\n",
    "\n",
    "%aimport src.workflows.clustering_utils\n",
    "from src.workflows.clustering_utils import run_clustering_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf66eaf3-e6cc-47ca-a0b0-bd2bc3eb933f",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9e3c84-7375-4427-962c-16d626e6ebb6",
   "metadata": {},
   "source": [
    "Process StackExchange posts using text pre-processing techniques and perform clustering on processed data with the `KMeans` clustering algorithm.\n",
    "\n",
    "This notebook requires a single `.parquet` file of stackexchange posts to be stored in `data/raw/text_clustering_data.parquet.gzip`. This file was created by `1_get_data.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ca94a-c17d-4e7e-8e43-276fdbd5570e",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c2f174-9882-4f3f-a18f-ede650b12ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets to load\n",
    "topics = [\"biology\", \"cooking\", \"crypto\", \"diy\", \"robotics\", \"travel\"]\n",
    "\n",
    "# Data\n",
    "num_samples_to_use = 86000\n",
    "raw_data_filepath = \"data/raw/text_clustering_data.parquet.gzip\"\n",
    "\n",
    "# Clustering\n",
    "n_clusters = 6\n",
    "kmeans_random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9477b54-bb9b-44a8-9487-8d67ab092b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stop_words = set(stopwords.words(\"english\"))\n",
    "manual_stop_words = [\n",
    "    # HTML tags\n",
    "    \"http\",\n",
    "    \"href\",\n",
    "    \"jpg\",\n",
    "    \"imgur\",\n",
    "    \"com\",\n",
    "    \"img\",\n",
    "    \"alt\",\n",
    "    \"li\",\n",
    "    \"ul\",\n",
    "    \"ol\",\n",
    "    \"src\",\n",
    "    \"em\",\n",
    "    \"en\",\n",
    "    \"rel\",\n",
    "    \"nofollow\",\n",
    "    \"blockquote\",\n",
    "    \"www\",\n",
    "    \"png\",\n",
    "]\n",
    "\n",
    "# Manually add to stop words\n",
    "for manual_stop_word in manual_stop_words:\n",
    "    all_stop_words.add(manual_stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b46296a2-0ed9-4842-84ba-2c84d5e5b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(pipe: Pipeline, df: pd.DataFrame) -> List:\n",
    "    \"\"\"Clean text data.\"\"\"\n",
    "    corpus = pipe.fit_transform(df).tolist()\n",
    "    return [corpus, pipe]\n",
    "\n",
    "\n",
    "def train(pipe: Pipeline, corpus: List) -> Pipeline:\n",
    "    _ = pipe.fit(corpus)\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def get_top_10_terms(pipe: Pipeline, n_clusters: int) -> Dict:\n",
    "    print(\"Top 10 words per cluster:\")\n",
    "\n",
    "    # Get the cluster centroids\n",
    "    order_centroids = pipe.named_steps[\"clusterer\"].cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "    # Get all words for each cluster\n",
    "    terms = pipe.named_steps[\"vectorizer\"].get_feature_names_out()\n",
    "\n",
    "    # Print top 10 words per cluster\n",
    "    d_top_ten = {}\n",
    "    for i in range(n_clusters):\n",
    "        t10_terms = []\n",
    "        print(f\"Cluster {i}: \", end=\"\")\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            t10_terms.append(terms[ind])\n",
    "        print(\", \".join(t10_terms))\n",
    "        d_top_ten[f\"cluster_{i}\"] = t10_terms\n",
    "    return d_top_ten\n",
    "\n",
    "\n",
    "def get_cluster_numbers(pipe: Pipeline) -> List:\n",
    "    cluster_numbers = pipe.named_steps[\"clusterer\"].labels_.tolist()\n",
    "    return cluster_numbers\n",
    "\n",
    "\n",
    "def get_cluster_posts(\n",
    "    df: pd.DataFrame,\n",
    "    cluster_numbers: List,\n",
    "    cluster_num: int,\n",
    "    num_docs_to_read: int = 5,\n",
    ") -> Dict:\n",
    "    d_cluster_articles = {}\n",
    "    df_with_clusters = df.assign(cluster=cluster_numbers)[\n",
    "        df.assign(cluster=cluster_numbers)[\"cluster\"] == cluster_num\n",
    "    ].iloc[:num_docs_to_read]\n",
    "    for k, article in df_with_clusters[\"content\"].iteritems():\n",
    "        d_cluster_articles[k] = article\n",
    "    return d_cluster_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fec08f-7e6f-4b72-9162-e2cdff020237",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93948012-44bd-49ef-a90f-6f35e17ca78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15061</th>\n",
       "      <td>2661</td>\n",
       "      <td>What meteorological conditions do I need to co...</td>\n",
       "      <td>&lt;p&gt;It's always difficult to decide what clothe...</td>\n",
       "      <td>gear clothing weather-and-climate</td>\n",
       "      <td>diy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65232</th>\n",
       "      <td>33841</td>\n",
       "      <td>New device checking rules for flights to/from USA</td>\n",
       "      <td>&lt;p&gt;I see the TSA have brought in &lt;a href=\"http...</td>\n",
       "      <td>air-travel airport-security tsa</td>\n",
       "      <td>diy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>64471</td>\n",
       "      <td>Riding motorcycles in Medellin, Colombia with ...</td>\n",
       "      <td>&lt;p&gt;I'm planning to visit Medellin and Bogota s...</td>\n",
       "      <td>driving-licenses motorcycles colombia</td>\n",
       "      <td>diy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11890</th>\n",
       "      <td>16020</td>\n",
       "      <td>How to make kidney beans tender?</td>\n",
       "      <td>&lt;p&gt;The way I currently cook kidney beans is to...</td>\n",
       "      <td>cooking-time beans</td>\n",
       "      <td>biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33566</th>\n",
       "      <td>39339</td>\n",
       "      <td>Can I have multiple valid ESTAs in different p...</td>\n",
       "      <td>&lt;p&gt;I'm a citizen of country X and have a valid...</td>\n",
       "      <td>usa passports esta dual-nationality</td>\n",
       "      <td>diy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "15061   2661  What meteorological conditions do I need to co...   \n",
       "65232  33841  New device checking rules for flights to/from USA   \n",
       "6061   64471  Riding motorcycles in Medellin, Colombia with ...   \n",
       "11890  16020                   How to make kidney beans tender?   \n",
       "33566  39339  Can I have multiple valid ESTAs in different p...   \n",
       "\n",
       "                                                 content  \\\n",
       "15061  <p>It's always difficult to decide what clothe...   \n",
       "65232  <p>I see the TSA have brought in <a href=\"http...   \n",
       "6061   <p>I'm planning to visit Medellin and Bogota s...   \n",
       "11890  <p>The way I currently cook kidney beans is to...   \n",
       "33566  <p>I'm a citizen of country X and have a valid...   \n",
       "\n",
       "                                        tags    topic  \n",
       "15061      gear clothing weather-and-climate      diy  \n",
       "65232        air-travel airport-security tsa      diy  \n",
       "6061   driving-licenses motorcycles colombia      diy  \n",
       "11890                     cooking-time beans  biology  \n",
       "33566    usa passports esta dual-nationality      diy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(raw_data_filepath, engine=\"auto\").sample(n=num_samples_to_use)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0236b9ae-4de8-47dc-9dfe-4e818ba8145d",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a677c4-7718-4390-9ab3-d0b893db3bef",
   "metadata": {},
   "source": [
    "The following text cleaning tasks are performed\n",
    "- cleaning\n",
    "  - lowercase\n",
    "  - remove HTML tags (`<abbr></abbr>`, `<link>`, `<head></head>`, etc.)\n",
    "    - web scraping\n",
    "  - keep letters, numbers and underscore (drop everything else. eg. `$`, `%`, `^`, `&`)\n",
    "  - remove space, new lines, tab character (` `, `\\n`, `\\t`)\n",
    "  - remove punctuation (`,`, `.`, `!`, etc.)\n",
    "- tokenization\n",
    "  - splits each document into a list of its words (tokens)\n",
    "  - `['the big dog ...']` becomes `['the', 'big', 'dog', ...]`\n",
    "- remove stop words\n",
    "  - eg. *the*, *and*, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3343047-2a38-4ed2-a979-1c78fac4c9be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 188 ms, total: 30.3 s\n",
      "Wall time: 30.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe_clean = Pipeline([(\"cleantext\", TextCleaner(\"content\"))])\n",
    "corpus, pipe_clean_trained = clean(pipe_clean, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1330d72-afb4-4908-a7f9-52013f73a986",
   "metadata": {},
   "source": [
    "The resulting list of tokens represents the text corpus that encapsulates our documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f31a6-21e3-44ac-a221-4f08ea368d15",
   "metadata": {},
   "source": [
    "## Converting Text to Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717aa5e-3674-4936-a360-22fc01b464a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fefe4-35a7-45fe-9658-9be0c5ed075d",
   "metadata": {},
   "source": [
    "We now need to convert all our text tokens into number since ML algorithms usually deal with numbers. This is the process of vectorization and the output is a vector of numbers.\n",
    "\n",
    "Each number in the vector represents a word in a all the documents in the text corpus (data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a6a48-6d30-494e-a3e3-87a110b7d002",
   "metadata": {},
   "source": [
    "### Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5666a91-f25b-4224-a86f-afaa138aee11",
   "metadata": {},
   "source": [
    "To do this, we will a technique called [TFIDF](https://monkeylearn.com/blog/what-is-tf-idf/) which associates every token with a number representing how relevant the token is to a document. Documents with similar relevant words (tokens) will have similar word vectors, which an ML algorithm can be trained on.\n",
    "\n",
    "Briefly\n",
    "- first count word occurrences by document\n",
    "- then give a higher weighting to words that occur frequently within a document but not frequently within the entire corpus (all the documents), since these words are assumed to contain more meaning in relation to a given document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fefb73e-c854-4e13-82fc-68737bf41cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.85,  # ignore tokens with a document freq > 80%\n",
    "    min_df=15,  # ignore terms with doc freq < 20%\n",
    "    stop_words=all_stop_words,  # we did this during the cleaning\n",
    "    ngram_range=(1, 1),  # unigrams\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4e21e-8e47-465c-9ea9-05173cbbcaa9",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. `max_df`\n",
    "   - if a token is in more than 80% of the documents, then it probably has little meanining in the context of topics (cooking, travel, etc.)\n",
    "2. `min_df`\n",
    "   - the token must be in at least 20% of the documents\n",
    "   - eg. a word might appear in many documents in many topics but carries no real meaning for separating the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7be97c-ea1a-4867-b898-abee550b8ee7",
   "metadata": {},
   "source": [
    "### Result of TFIDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3bf2fe-2d7c-4466-b61d-2981f39665a2",
   "metadata": {},
   "source": [
    "The result of TFIDF vectorization will be numeric features (`X`) that can be used by a ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353c52cf-cb8c-4660-aca8-71ebfa4a77b6",
   "metadata": {},
   "source": [
    "## ML Algorithm for Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8d136-5855-4d34-b349-c9f5eb1e9ceb",
   "metadata": {},
   "source": [
    "We will use the `KMeans` algorithm to cluster the documents after vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5b01452-c84f-4765-9271-50e8030ec940",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9256b801-4a5d-4501-931b-136a0792b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "est = KMeans(\n",
    "    n_clusters=n_clusters,\n",
    "    max_iter=500,\n",
    "    n_init=10,\n",
    "    random_state=kmeans_random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1992b416-2a12-4f7c-8a93-14fe3a973a76",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. `KMeans` may require multiple runs to reach convergence and so `n_init` is set to a larger value than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876da178-a21b-429a-821d-5d513a31cfa7",
   "metadata": {},
   "source": [
    "Define a ML pipeline with the\n",
    "- text vectorizer\n",
    "- ML clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b00ae0b-5cc5-43a5-bcdb-110e8255f2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(max_df=0.85, min_df=15,\n",
       "                                 stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'alt', 'am', 'an', 'and', 'any',\n",
       "                                             'are', 'aren', \"aren't\", 'as',\n",
       "                                             'at', 'be', 'because', 'been',\n",
       "                                             'before', 'being', 'below',\n",
       "                                             'between', 'blockquote', 'both',\n",
       "                                             'but', 'by', 'can', ...})),\n",
       "                ('clusterer',\n",
       "                 KMeans(max_iter=500, n_clusters=6, random_state=42))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", vectorizer),\n",
    "        (\"clusterer\", est),\n",
    "    ]\n",
    ")\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08a35b-8d21-4716-9c97-d2c85de4fa58",
   "metadata": {},
   "source": [
    "### ML Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb70567-0bc1-4836-8f14-8fd88e150c52",
   "metadata": {},
   "source": [
    "Train the pipeline on the entire corpus we created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0966a88-3252-4560-9b2b-87617b65cc82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 121 ms, total: 1min 9s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = train(pipe, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b450a08-a9f3-4e6e-abf2-28e0e6cb3a9e",
   "metadata": {},
   "source": [
    "### Inspect Top Tokens in Each Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48a72f4-47e7-409f-8359-5b08b443b4fe",
   "metadata": {},
   "source": [
    "We will now inspect the clusters that our ML model has learned during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d469017-259c-4425-bf7e-2e44abdf9aa3",
   "metadata": {},
   "source": [
    "We'll first get the top 10 words in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaee083a-6f3c-4279-9c56-1ff831fd00ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words per cluster:\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n"
     ]
    }
   ],
   "source": [
    "d_top_ten = get_top_10_terms(pipe, n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac4758-e238-4822-99e6-747d242f77d3",
   "metadata": {},
   "source": [
    "## Assign Names to Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de07e56c-ecfa-40f5-9b3a-a72eae5edfe0",
   "metadata": {},
   "source": [
    "### Assign Cluster Numbers to Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3856aaf3-7f5a-4b0a-9b2b-3fcfdf340d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_numbers = get_cluster_numbers(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b009a-3111-4329-be2c-172eb17b4762",
   "metadata": {},
   "source": [
    "### Read the Documents in a Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe27f2f-d227-4cc6-8029-c87e525d8587",
   "metadata": {},
   "source": [
    "Start reading the text of each document in a given cluster. Decide on what is the topic of the text. Consider the top 10 words for each cluster. With all this in mind, suggest a name for the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d4c967-1181-4ef8-9081-49c2b8db2f62",
   "metadata": {},
   "source": [
    "#### Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5cd6e34-65e5-4f96-9653-e22a4afefce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words per cluster:\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 2, Raw data index = 81,864\n",
      "I live in the Midwest of the United States, and we not-too-rarely get a large amount of rain coming down at one time both in the spring and sometimes in the fall. Last night was no different (aside from random earthquakes..) than usual, but after I went to bed, my smoke alarm went off. I quickly determined that there was in fact no fire, so I went to take the smoke alarm off of its mounting and when I removed it, I found that there was a decent amount of water in the smoke detector. If I had to guess I'd say about 50 mL. So not a huge amount, but enough to set it off.I left it off for a time, and did not notice any more water coming from the opening in the ceiling (which is a recess where the detector and power wiring sits, not fully open to the attic (just where the wires come in, as far as I know. I didn't examine it terribly closely), even though it was still raining fairly hard (though not nearly as hard as it had been). This morning, I went to have a look around the attic to see if I could see anywhere it was leaking (it is still misting outside, but not raining any longer), but I was unable to detect any wet spots in the roof.What should my next step be? The roof (and indeed the house) is 1 year old, so I would hope that it hasn't sprung a leak, but I can't think of how else water would have gotten into the smoke detector. I also suspect paying someone to go and try to find a leak is going to be fairly expensive as well.The detector itself appears to be working. If I test it, and it functions, should I still replace it because of potential water damage?UpdateHere is a picture of the socket in question, and there is indeed cool air coming from it. I'm not totally convinced it is just condensation, elsewise this would have happened last year during the winter, I would think, but am unsure.\n",
      "\n",
      "Cluster = 2, Raw data index = 22,211\n",
      "We discovered a bath tub leak from our second floor bathroom which dripped through the sidings. The bathroom has the original fixtures from 1989. It leaks when there's excess amount of water used.Would this be a simple problem of refinishing everything using plumber's putty?\n",
      "\n",
      "Cluster = 2, Raw data index = 74,198\n",
      "The air quality in my basement is unpleasant. I don't know if I have mold. How to test for it? How is the smell of mold?I know that we had a water problem in the basement, the walls were cracked so every rainy day, we had humidity and water in the basement. But I have never seen signs of mold. How to check for mold?\n",
      "\n",
      "Cluster = 2, Raw data index = 44,660\n",
      "Many instances of this worm-like creature were found in a water system for a mountain cabin in the Sierra Nevada mountains of the US, in late June / early July.  The water system collects water from an enclosed spring.  Can you help identify this creature?  Clues:The worms have two \"points\" on their heads. They can stretch out and be long and thin, or when poked (or are resting) they contract into a small blob.  Here is a picture of a single worm with markings shown.Here is a picture of a few worms, somewhat contracted. Here is a movie of them moving, in natural light.  Here is a movie of them moving, with backlight.Here are pictures of their undersides and their internal structures.Whenever I pull some out of the water and put them into a tupperware with the same water, they only survive for around 24 hours, after which they seem to disintegrate.  Here is a picture of about 20 of the worms after about 24 hours, the bulk of them have halfway-decomposed and form a heap in the upper right.  After another day it'll just look like debris in the water, you wouldn't even recognize that there were worms in it.  There is a piece of bacon in there because some suggested putting it there to test if they were leeches, but this disintegration happens repeatably and regardless of the bacon; please ignore the bacon.Someone suggested that they are trematodes, but there are no snails, frogs, or other creatures in the storage and collection sections of the water system;  we have looked very closely.  There may be something within a 30-foot section of pipe, but we doubt it.  Can you help us identify this creature?  Even just possible families of creatures or general categories would be helpful for us.\n",
      "\n",
      "Cluster = 2, Raw data index = 45,540\n",
      "People may tend to spend time in a hot water spring. Is it possible to get hyperthermia (like a sun stroke) due to this?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = 2\n",
    "_ = get_top_10_terms(pipe, n_clusters)\n",
    "d_selected_cluster_posts = get_cluster_posts(df, cluster_numbers, 2, 5)\n",
    "print()\n",
    "for k, post in d_selected_cluster_posts.items():\n",
    "    post_without_html = re.sub(r\"\\<[^<>]*\\>\", \"\", post).replace(\"\\n\", \"\").strip()\n",
    "    print(f\"Cluster = {q}, Raw data index = {k:,}\\n{post_without_html}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf05967-c6dc-4d18-9ab9-9325db5aef0d",
   "metadata": {},
   "source": [
    "**Suggested Cluster Label = Biological Studies** (some posts are talking about home repair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767efb8d-0431-4d9f-94af-48979c563b2f",
   "metadata": {},
   "source": [
    "#### Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed18c7e-a612-40d7-9de0-5005d2b782b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words per cluster:\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 3, Raw data index = 63,096\n",
      "I bought a new house about a month ago, and have since noticed some plumbing issues in the laundry room:laundry tub drains slowlyoccasional \"musty\" smell, which seems to come from the drainsI did some research online and found that lack of drain ventilation could cause both of these problems. So I checked the plumbing and it looks like both the washing machine and adjacent wash basin drain into the same pipe. As far as I can tell, there is no ventilation on these drains (photo below); it looks like a stacked pair of S-traps.The laundry room is in a little addition at the back of the house. So I probably cannot tie this back in to the main house venting stack without a lot of work. I gather the simplest solution is to locally install an air admittance valve (AAV). Does that sound like a reasonable approach here?If so, am I on the right track with one of these:http://www.rona.ca/en/air-admittance-valvehttp://www.amazon.ca/gp/product/B000H5SLWM?psc=1&amp;redirect=true&amp;ref_=ox_sc_act_title_1&amp;smid=A23X8TYK8IHNZFMy plan is to remove the upper S-trap. Then install a sanitary T, going to: AAV (top) and P-trap (horizontal). Does that sound right?\n",
      "\n",
      "Cluster = 3, Raw data index = 31,500\n",
      "I have read a lot about proper insulation and ventilation, including some posts on this site, but none adequately answer my questions.My goal is to operate an electric heat source in the winter and have ~60 &deg;F temperature maintained when working in the garage.  In the summer, I think we will typically leave the garage door open, however it would be nice to one day have it stay cool in there if it's 90-100 &deg;F outside.This is in Ohio, where we typically have temps of 0-95 &deg;F throughout the year, it can also get pretty humid.I do not have soffit vents, but there is a ridge vent on the roof already installed.  I do not want to drywall nor do I want to build a ceiling.As you see in the photos I have already insulated the walls with R15 Batt installation.  Now I'm unsure where to go from here for roof 2x6's.  I bought some radiant barrier R11-equivelent insulation (seen in photos as well), which I was planning to attach to the end of the 2x6's above, which leaves plenty of ventilation behind them, should be \"ok\" in the winter and pretty decent in the summer.  However, not having soffit vents, I'm unsure if that is the proper use-case.You'll see from the wall install that I have no concerns about a vapor barrier, and do not care to seal my garage 100% (I only got faced insulation because it was cheaper =)  ).  However, I am concerned about mold/moisture problems in the space.  I would love some feedback as to the proper way to proceed here.  Ideally I can make use of my radiant barriers, and ideally I won't have to cut in soffit vents.Full resolution images here for reference: http://imgur.com/a/4Wd9Q and http://imgur.com/a/ud8os\n",
      "\n",
      "Cluster = 3, Raw data index = 8,153\n",
      "What's the best way for a DIY granite counter top to be cut?  What tools do I need that will do the job without breaking the bank?\n",
      "\n",
      "Cluster = 3, Raw data index = 6,644\n",
      "I'm remodeling my bathroom and shower and I'll be replacing the insulation on the external wall. This wall is the \"back\" of the shower (opposite from where the water supply lines are). With this in mind, I should be able to just choose some insulation and then plop it in when I have the wall torn down.The main question and concern I have is about vapor barrier. I will be using cement board with a liquid topical membrane (like Redgard) for waterproofing the shower which means I'm not supposed to put a vapor barrier on the back side of the wall because it is bad to trap moisture. How does this affect insulating? Am I safe to nix the vapor barrier around the shower? What should I do for the rest of the bathroom?I'm not too concerned with price so if there are other options besides batting insulation (such as foam, etc...) that would solve my problem, I'm willing to hear those ideas as well.\n",
      "\n",
      "Cluster = 3, Raw data index = 65,112\n",
      "I am doing some minor renovations to my basement with the drop ceiling and found that one of the geniuses that owned the house before me, used fibreglass ceiling tiles to seal off an old vent for a gas fireplace. Obviously this will not do. I'm thinking of building a section of 2x4's around the old exhaust and then filling it with rigid foam and spray foam. I can't take the old exhaust off the side of the house, since it is a condo and I doubt that I'm going to convince them to replace the siding where this exhaust vent is, not to mention it will probably cost me. Open to any suggestions. I would post a pic but the settings don't allow it, kinda odd.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = 3\n",
    "_ = get_top_10_terms(pipe, n_clusters)\n",
    "d_selected_cluster_posts = get_cluster_posts(df, cluster_numbers, 3, 5)\n",
    "print()\n",
    "for k, post in d_selected_cluster_posts.items():\n",
    "    post_without_html = re.sub(r\"\\<[^<>]*\\>\", \"\", post).replace(\"\\n\", \"\").strip()\n",
    "    print(f\"Cluster = {q}, Raw data index = {k:,}\\n{post_without_html}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1710e16-87fa-4f76-b7bb-cc81a50d97e1",
   "metadata": {},
   "source": [
    "**Suggested Cluster Label = Home Repairs, Home Rennovations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f09a9-f588-4e0c-9162-2d6e29970658",
   "metadata": {},
   "source": [
    "#### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1c645d9-15f5-4f57-b030-723912d36e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words per cluster:\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 1, Raw data index = 60,884\n",
      "I'm trying to put my RV into the breaker box I've got a 30 amp breaker double pole I've got10/2 wire, do I use a single pole or double pole 30 amp breaker hand my RV plug is a 4 prong plug how do I make this work\n",
      "\n",
      "Cluster = 1, Raw data index = 62,339\n",
      "I just installed 6 new 4\" halo can lights. When they are on I can smell a slight odor coming from them in the attic. Is this normal? I felt the light housing in the attic and is just warm. I also felt each wire going from light to light and it is cool to the touch.\n",
      "\n",
      "Cluster = 1, Raw data index = 6,276\n",
      "I have an odd wiring situation at one of my switches, and like a rookie took it all apart before taking a picture.I have 9 wires running into the box, 3 white, 3 black and 3 ground.The switch is a standard two-way that controls a light in the basement. This appears to be the start of the line, with another switch (controlling a different light) and an outlet further down the line. What's odd, is that one of the lines (BW pair) are both hot. As such, I can't figure out how this switch needs to be connected. Any thoughts?\n",
      "\n",
      "Cluster = 1, Raw data index = 63,446\n",
      "I have an existing three way switch hooked up already, it works fine. I would like to add another three way switch by connecting another switch to the existing three way switch. Can this be done with 14/2 romex between the two switches?\n",
      "\n",
      "Cluster = 1, Raw data index = 7,857\n",
      "Can I temporarily ground an outlet by attaching a wire to its central screw and then to a grounding rod situated outside my house?  I want to use an electrical pressure washer, but it requires a ground that none of my outlets have.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = 1\n",
    "_ = get_top_10_terms(pipe, n_clusters)\n",
    "d_selected_cluster_posts = get_cluster_posts(df, cluster_numbers, 1, 5)\n",
    "print()\n",
    "for k, post in d_selected_cluster_posts.items():\n",
    "    post_without_html = re.sub(r\"\\<[^<>]*\\>\", \"\", post).replace(\"\\n\", \"\").strip()\n",
    "    print(f\"Cluster = {q}, Raw data index = {k:,}\\n{post_without_html}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945e9142-bd62-4f07-899a-a20fefd40145",
   "metadata": {},
   "source": [
    "**Suggested Cluster Label = Personal Electronic Devices, Home Automation and Home Electricity**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecc9c2b-d203-4f8c-857e-e21b75d03838",
   "metadata": {},
   "source": [
    "#### Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c6b86d1-01ac-4130-9648-95898cc5c5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words per cluster:\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 0, Raw data index = 33,566\n",
      "I'm a citizen of country X and have a valid United States ESTA in my X passport.  Recently, I became of citizen of Y and now have a Y passport as well, which I would like to use for future travel to the US.  Both countries qualify for the Visa Waiver Program.  Can I have ESTAs in both passports at the same time?The official CBP site seems contradictory, first implying that I should get a new ESTA:  If you obtain a new passport or change your name, gender or country of  citizenship, you will be required to apply for a new travel  authorization. This is also required if one of your answers to any of  the VWP eligibility questions changes. The associated fee of $14 will  be charged for each new application.And then saying that I should not have two simultaneous ESTAs:  If you have dual citizenship and have registered with ESTA, you should  use your VWP-eligible passport to board the plane when you leave your  country of departure and when you arrive in the U.S. If both your  countries of citizenship are VWP-eligible, then we strongly recommend  you choose which one you want to claim for purposes of travel to the  U.S., and use that country's passport each time you travel. One person  with two different ESTA authorizations creates confusion that will  only delay your travel.Cancelling the old ESTA would seem a valid way to fulfill both requirements, but there doesn't appear to be any way to do this?\n",
      "\n",
      "Cluster = 0, Raw data index = 48,613\n",
      "I am not sure this is the right place to ask this question but assuming any traveler might have come across this situation/have information,requesting to please guide.I had arrived USA 2 months before on B1/B2 visa.As I-94 forms are now paperless, i did not receive one at the time of arrival at USA airport. But i can see details of same on cbs.gov website. In paperless I-94, where do we need to return the form / do we need to return the form when I leave USA? I checked website but it had information regarding the case when paper I-94 is received.\n",
      "\n",
      "Cluster = 0, Raw data index = 55,030\n",
      "My old passport have 2-year valid visa of DRCongo and it is expire on 04.06.2016. Now I am on holiday and going back at DRCongo on 01.05.2016. My old passport have remain 2 blank page so my boss told me to make new passport and I got a new passport.Will the immigration officer accept my visa if it is on my old passport?\n",
      "\n",
      "Cluster = 0, Raw data index = 49,361\n",
      "I am flying from London to Central America and back this summer on a bit of an extended holiday. I am considering stopping over in NYC on the way back for a few days. (My flight from Panama to London would be through NYC anyway and got offered a good deal by a travel agent.) I am residing in London as an EU citizen and I always use my EU passport to get around the world. However as I was born in the States I am also a fully fledged US citizen with the blue passport. The only time I've used my US passport in the past was for a US holiday a decade ago. I've never lived in the States so I don't sound American etc. I want to book my flights and travel around Central America using my EU passport for simplicity's sake. However I have come across on the US foreign office website a bit stating that US dual citizens can only enter and exit the State with a US passport. What should I do? I assume that I can't check into my flight on a European passport then enter and exit US border control with a US passport? Can I just ignore the fact that I've got a US passport and hope they don't clock on it? My EU passport will state my place of birth as the States but as I've said I don't sound American or anything. Is that risky? I don't want to be turned back at the gates on my first NYC trip!\n",
      "\n",
      "Cluster = 0, Raw data index = 55,078\n",
      "My wife has a Schengen visa issued by the Italian consulate in the UK.It expires at the beginning of December, and as we want to travel to Europe for the Christmas holiday, we were hoping to cancel the current Schengen visa early in order to apply for another one in time.I have contacted the Italian consulate in London by email, and they have told me that they are unable to do this. After a quick search online, it seems other people have had more luck cancelling their visas. So my question is: has anyone cancelled a Schengen visa issued by Italy, and if so - how?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = 0\n",
    "_ = get_top_10_terms(pipe, n_clusters)\n",
    "d_selected_cluster_posts = get_cluster_posts(df, cluster_numbers, q, 5)\n",
    "print()\n",
    "for k, post in d_selected_cluster_posts.items():\n",
    "    post_without_html = re.sub(r\"\\<[^<>]*\\>\", \"\", post).replace(\"\\n\", \"\").strip()\n",
    "    print(f\"Cluster = {q}, Raw data index = {k:,}\\n{post_without_html}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4704e8-3ffb-470d-9cd5-9046017a01fd",
   "metadata": {},
   "source": [
    "**Suggested Cluster Label = International Travel**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e8437b-926e-4208-9b3a-dc3bd21f1723",
   "metadata": {},
   "source": [
    "#### Cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e66958c-4f7f-47ed-9a11-081681c50ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words per cluster:\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 4, Raw data index = 15,061\n",
      "It's always difficult to decide what clothes to take with you when you go to a new place. Usually I check Wikipedia to get an idea of approximate climate and weather conditions, but it often doesn't have much data besides average temperatures. Other factors, such as wind and precipitation, might enter into the equation, and the same temperature can \"feel like\" differently in two distinct locations.Perhaps not the same factors are important whether one travels to tropical/equatorial locations, or to temperate/subarctic places.So, in short:  If I travel to a new place, which weather factors should I look into to decide what to take with me?\n",
      "\n",
      "Cluster = 4, Raw data index = 65,232\n",
      "I see the TSA have brought in new rules for devices, in response to intelligence that terrorists may be trying to pack mobile phones with explosive, so checks before flights can include having to prove the device can power on.Although fearing the worst and allowing lots of extra time at airports, I have not yet encountered any checks of this sort over and above the usual taking devices out of bags so they can be scanned separately.From various news articles, there doesn't appear to be any consistent view as to what checks will be carried out.Can anyone here clarify what they do? Do you have to prove a phone can make a call, or just show it is powered on?\n",
      "\n",
      "Cluster = 4, Raw data index = 6,061\n",
      "I'm planning to visit Medellin and Bogota sometime in the near future. I've a U.S. DL which endorses motorcycles. Is it legal to ride motorcycles in Colombia with a US driver's license? Is it required to carry any other identification other than the U.S. DL in case if I'm on the road?\n",
      "\n",
      "Cluster = 4, Raw data index = 11,890\n",
      "The way I currently cook kidney beans is to soak them overnight. But still they have to be cooked for a long time on gas before they get tender enough to be edible.Anything that can be added or be done in a different way to reduce the time over heat?\n",
      "\n",
      "Cluster = 4, Raw data index = 57,730\n",
      "To quote Goodman &amp; Gilman :  An alternative way of defining the anesthetic state is to consider it  as a collection of “component” changes in behavior or perception. The  components of the anesthetic state include:  • amnesia  • immobility in  response to noxious stimulation  • attenuation of autonomic responses  to noxious stimulation  • analgesia  • unconsciousnessMy question is, does not the state of Unconsciousness already imply other components of analgesia and amnesia? Analgesia is the absence of the perception of pain, which is granted if there is unconsciousness which would be the absence of all perceptions. I am not certain if unconsciousness also entails amnesia, but it seems that remembering what happened when unconscious seems considerably unlikely.  Apart from a reductionist argument for minimizing the constraints required for classification as a general anesthetic, I am more interested in cases where unconsciousness would be achieved without analgesia or amnesia, which could be a likely rationale behind including the additional caveats in the definition.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = 4\n",
    "_ = get_top_10_terms(pipe, n_clusters)\n",
    "d_selected_cluster_posts = get_cluster_posts(df, cluster_numbers, q, 5)\n",
    "print()\n",
    "for k, post in d_selected_cluster_posts.items():\n",
    "    post_without_html = re.sub(r\"\\<[^<>]*\\>\", \"\", post).replace(\"\\n\", \"\").strip()\n",
    "    print(f\"Cluster = {q}, Raw data index = {k:,}\\n{post_without_html}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3273e7b-91e8-4fc3-936e-17f75cb1a0c8",
   "metadata": {},
   "source": [
    "**Suggested Cluster Label = Food and Meals** (some posts are talking about home repair and others are talking about international travel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4be8df-12d4-440d-81c1-77066f829a72",
   "metadata": {},
   "source": [
    "#### Cluster 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "763f9100-ed7c-4572-9c0a-3efa666f4a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words per cluster:\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 5, Raw data index = 42,634\n",
      "I have designed an SQL aggregate function in Oracle that bitwise XORs all MD5 sums of the values stored in a column.For example, if my table is:+-----+----------+---------+| Key | Sequence |  Value  |+-----+----------+---------+|   1 |        1 | 'Hello' ||   1 |        2 | 'World' ||   2 |        1 | '1234'  ||   3 |        0 | (empty) ||   4 |        1 | 'Hello' ||   4 |        3 | 'World' |+-----+----------+---------+I can run the following query in Oracle:with t AS (select 1 key, 1 sequence, 'Hello' value FROM dual           union all select 1, 2, 'World' from dual           union all select 2, 1, '1234' from dual           union all select 3, 0, '' from dual /* ... */          )   select key, md5_agg(value) from t group by keyand get (unfortunately aggregate functions in Oracle ignore NULL values and '' is considered as NULL)+---+----------------------------------+|key| md5_agg(value)                   |+---+----------------------------------+| 1 | 7EBD0B1DA67F965F802D31DF25C4B321 || 2 | 81DC9BDB52D04DC20036DBD8313ED055 || 3 | 00000000000000000000000000000000 || 4 | 7EBD0B1DA67F965F802D31DF25C4B321 |+---+----------------------------------+I would like to use this approach to compare if the contents of some columns are equal when I compare subsets of the same table (think of finding duplicates in a complex structures that spans over multiple rows in the same table). Here with this results I know that I have the same subsets for keys 1 and 4.What are the limits of such an approach? Here are the ones I could list:This is interesting only if my column contains distinct values. If my columns contains twice the same string, the xor operation will be a no-op.Due to Oracle limitations, if my column contains empty values, they do not count.With those limitations in mind, is it still possible to infer, from two equal md5_agg results computed from distinct and non-empty values, that the original values make up the same sets?In order to reformulate, are there odds that the MD5 sums of distinct strings XOR to 0?\n",
      "\n",
      "Cluster = 5, Raw data index = 69,637\n",
      "For the reasons I cannot go into details, I need to design my own protocol and overall security system which will be used to establish secure data exchange between various devices (most notably desktops of all three major OSes, Android and iOS devices and Raspberry Pi, with the possibility to extend it to other embedded systems). Since I wouldn't dare to do my own crypto algorithms implementation, this implies that I have to rely on tried and tested libraries available for those platforms (i.e. OpenSSL, BouncyCastle, CommonCrypto, …) so I settled with what they all support - RSA for signing/authentication, DHE/ECDHE for session establishment, AES for encryption, PBKDF2 for key derivation and SHA2 for general hashing needs. The key sizes and complexity will depend on the hardware ability of targeted platforms.Now, I've done a fair bit of implementations of existing protocols and I like to think that I know my way around cryptography and perils that await if not applied properly, however I wouldn't dare to consider myself a cryptography expert and thus I decided to query the hive mind. Of course, once everything completed it will be properly audited and tested, but for now I need to know if I'm on the right track, that I haven't done some glaring omissions and if it is possible to improve it even further.The system I'm building should both cover the storage on devices and the communication between them and to preserve forward and backward secrecy.For the storage part I plan to utilize AES in CBC mode, storing the randomly generated IVs with each individual encrypted file. The 'master' key itself will be randomly generated and also AES-encrypted using a key derived from the user's password using PBKDF2, stored along with the salt and iterations used in it. My main concern is the IV part as if generated randomly it might repeat thus compromising the encrypted files if they happen to be similar enough or even the same. It's quite a low chance buy I don't like leaving anything to chance so the question is - given that the IV is public knowledge anyway, is it safe to use incremental progression/timestamp as IV in this case?The communication part will be a bit trickier as the devices will never communicate directly - instead the data exchange between them will be relied through a third party database to which they periodically connect, which is one of the prime reasons I'm designing my own protocol. If we except this oddity, the data exchange itself should function quite the same as if they were communicating directly, namely the devices will establish a session each time they 'contact' each other and then use the session key for encryption.To establish a session I plan to use a variation of STS protocol adapted to this environment. The only oddity here is that in some instances only one of the parties involved in communication will posses the RSA key of the other so it won't be fully authenticated - my understanding is that even in this case no successful MITM attack can be performed as at least one of the parties will reject communication if the signature doesn't match. Is that a safe assumption?Once DH/ECDH keys are exchanged an actual session AES key will be derived from them using SHA2 and the rest of the data exchange will be encrypted using that key, again in CBC mode - until the session expires, when the process repeats. I'm still not clear on how to approach the message integrity and authenticity verification - at first I thought that signing the message with the device's RSA key will be enough, but since it may happen that only one of the parties has the other party's certificate I might add a HMAC alongside with the exchanged messages as well. What would be a recommended, cryptographically secure way to handle that?\n",
      "\n",
      "Cluster = 5, Raw data index = 86,569\n",
      "Apple OS X can create encrypted AES 128/256 DMG volumes. Here is written about a men who was able to hack it. And also that DMGs use PBKDF2-HMAC-SHA-1. I couldn't find more information about encrypted DMGs. So does that mean that apples encrypted DMGs could be hacked?\n",
      "\n",
      "Cluster = 5, Raw data index = 9,433\n",
      "Hashcash is a proof-of-work system in which the Sender needs to find $Y$ such as the first (let's say 20) bits of $H(X+Y)$ are zeros where $H$ is a one-way hash function, $X$ is a fixed value and $+$ means concatenation. The Sender starts with an initial random number $Y$. It then computes the hash of $X+Y$. If the first 20 bits of the hash are zeros, then $Y$ is an acceptable number. If not, then the sender increments the random number and tries again. Since about $1$ in $2^{20}$ headers will have $20$ zeros as the beginning of the hash, the sender will on average have to try $2^{20}$ random numbers to find a valid number.My question is: The average number of tries is $2^{20}$ but is there a number of tries after which Hashcash is guaranted to be solved?\n",
      "\n",
      "Cluster = 5, Raw data index = 28,252\n",
      "I've always been interested in encryption but I have never found a good explanation (beginners explanation) of how encryption with public key and decryption with private key works.How does it encrypt something with one key and decipher it with another key?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = 5\n",
    "_ = get_top_10_terms(pipe, n_clusters)\n",
    "d_selected_cluster_posts = get_cluster_posts(df, cluster_numbers, q, 5)\n",
    "print()\n",
    "for k, post in d_selected_cluster_posts.items():\n",
    "    post_without_html = re.sub(r\"\\<[^<>]*\\>\", \"\", post).replace(\"\\n\", \"\").strip()\n",
    "    print(f\"Cluster = {q}, Raw data index = {k:,}\\n{post_without_html}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698c11f6-c10b-43ba-9a31-b56803a3cd49",
   "metadata": {},
   "source": [
    "**Suggested Cluster Label = Encryption, Cryptographic Block Cyphers, Padding Oracle Attack**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12856c7-309c-4a90-a716-5c2d6a849748",
   "metadata": {},
   "source": [
    "We'll summarize these cluster labels below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "caf8bcd4-a922-4e70-a183-115158cf31e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster Number</th>\n",
       "      <th>Suggested Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Encryption, Cryptographic Block Cyphers, Paddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Food and Meals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Biological Studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>International Travel Experiences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Home Repairs, Home Rennovations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Personal Electronic Devices, Home Automation a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster Number                                    Suggested Label\n",
       "0               5  Encryption, Cryptographic Block Cyphers, Paddi...\n",
       "1               4                                     Food and Meals\n",
       "2               2                                 Biological Studies\n",
       "3               0                   International Travel Experiences\n",
       "4               3                    Home Repairs, Home Rennovations\n",
       "5               1  Personal Electronic Devices, Home Automation a..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cluster_label_names = {\n",
    "    5: \"Encryption, Cryptographic Block Cyphers, Padding Oracle Attack\",\n",
    "    4: \"Food and Meals\",\n",
    "    2: \"Biological Studies\",\n",
    "    0: \"International Travel Experiences\",\n",
    "    3: \"Home Repairs, Home Rennovations\",\n",
    "    1: \"Personal Electronic Devices, Home Automation and Home Electricity\",\n",
    "}\n",
    "df_cluster_label_names = (\n",
    "    pd.DataFrame.from_dict(\n",
    "        d_cluster_label_names,\n",
    "        orient=\"index\",\n",
    "    )\n",
    "    .reset_index()\n",
    "    .rename(\n",
    "        columns={0: \"Suggested Label\", \"index\": \"Cluster Number\"},\n",
    "    )\n",
    ")\n",
    "df_cluster_label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b15a8f-7a94-4fb0-a9a8-68fd436d7bd2",
   "metadata": {},
   "source": [
    "### Assign Cluster Names as Column in Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f619049-3c15-4eb0-9a1f-21e50fcee693",
   "metadata": {
    "tags": []
   },
   "source": [
    "Assign cluster names to raw data and show the true topic name and the suggested cluster name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2be96de-78dc-499e-a978-1f414990c480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>cluster_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33128</th>\n",
       "      <td>&lt;p&gt;I have an old house which probably dates back to 1920s or so. Most walls are plaster and the ...</td>\n",
       "      <td>Home Repairs, Home Rennovations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>&lt;p&gt;I have trouble cooking the &lt;a href=\"http://www.st-hubert.com/epicerie/produits/categorie-sauc...</td>\n",
       "      <td>Food and Meals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>&lt;p&gt;I have heard that offspring can't grow taller than either of their parents but I've also hear...</td>\n",
       "      <td>Food and Meals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49908</th>\n",
       "      <td>&lt;p&gt;In some literature it is written that the private key should be chosen random from &lt;/p&gt;\\n\\n&lt;p...</td>\n",
       "      <td>Encryption, Cryptographic Block Cyphers, Padding Oracle Attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31946</th>\n",
       "      <td>&lt;p&gt;There doesn't appear to be PKCS#7 or CMS support in pyCrypto. I'd appreciate a recommendation...</td>\n",
       "      <td>Encryption, Cryptographic Block Cyphers, Padding Oracle Attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22859</th>\n",
       "      <td>&lt;p&gt;How do you dial in the right amount of thickness vs soft melt in your mouth style?&lt;/p&gt;\\n\\n&lt;p&gt;...</td>\n",
       "      <td>Food and Meals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64769</th>\n",
       "      <td>&lt;p&gt;Do I need to adjust the oven temperature in a roast duck recipe if I want to put more than on...</td>\n",
       "      <td>Food and Meals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56031</th>\n",
       "      <td>&lt;p&gt;I would like to know if there is a good source that combines Slam problem with vision. From m...</td>\n",
       "      <td>Food and Meals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49549</th>\n",
       "      <td>&lt;p&gt;In a couple of weeks I will be going to Edinburgh, Scotland. I've been told that the weather ...</td>\n",
       "      <td>Food and Meals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51833</th>\n",
       "      <td>&lt;p&gt;I made some pasta dough this morning and put it in the fridge. When I ran the first batches t...</td>\n",
       "      <td>Food and Meals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41449</th>\n",
       "      <td>&lt;p&gt;We are building a new house and are getting ready to install the drywall on the ceilings. We ...</td>\n",
       "      <td>Home Repairs, Home Rennovations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25760</th>\n",
       "      <td>&lt;p&gt;We're in a split level, in Massachusetts, that was built in 1997 with contractor grade vinyl ...</td>\n",
       "      <td>Home Repairs, Home Rennovations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27685</th>\n",
       "      <td>&lt;p&gt;I checked prices on some sites and have feeling of strong misunderstanding: according to Wikw...</td>\n",
       "      <td>Food and Meals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34062</th>\n",
       "      <td>&lt;p&gt;I am an American student studying in Dijon for a semester and had a question regarding the OF...</td>\n",
       "      <td>Food and Meals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17204</th>\n",
       "      <td>&lt;p&gt;Carrying a Pakistani passport do require transit visa for Amsterdam airport. But I am travell...</td>\n",
       "      <td>International Travel Experiences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   content  \\\n",
       "33128  <p>I have an old house which probably dates back to 1920s or so. Most walls are plaster and the ...   \n",
       "3999   <p>I have trouble cooking the <a href=\"http://www.st-hubert.com/epicerie/produits/categorie-sauc...   \n",
       "8879   <p>I have heard that offspring can't grow taller than either of their parents but I've also hear...   \n",
       "49908  <p>In some literature it is written that the private key should be chosen random from </p>\\n\\n<p...   \n",
       "31946  <p>There doesn't appear to be PKCS#7 or CMS support in pyCrypto. I'd appreciate a recommendation...   \n",
       "22859  <p>How do you dial in the right amount of thickness vs soft melt in your mouth style?</p>\\n\\n<p>...   \n",
       "64769  <p>Do I need to adjust the oven temperature in a roast duck recipe if I want to put more than on...   \n",
       "56031  <p>I would like to know if there is a good source that combines Slam problem with vision. From m...   \n",
       "49549  <p>In a couple of weeks I will be going to Edinburgh, Scotland. I've been told that the weather ...   \n",
       "51833  <p>I made some pasta dough this morning and put it in the fridge. When I ran the first batches t...   \n",
       "41449  <p>We are building a new house and are getting ready to install the drywall on the ceilings. We ...   \n",
       "25760  <p>We're in a split level, in Massachusetts, that was built in 1997 with contractor grade vinyl ...   \n",
       "27685  <p>I checked prices on some sites and have feeling of strong misunderstanding: according to Wikw...   \n",
       "34062  <p>I am an American student studying in Dijon for a semester and had a question regarding the OF...   \n",
       "17204  <p>Carrying a Pakistani passport do require transit visa for Amsterdam airport. But I am travell...   \n",
       "\n",
       "                                                         cluster_name  \n",
       "33128                                 Home Repairs, Home Rennovations  \n",
       "3999                                                   Food and Meals  \n",
       "8879                                                   Food and Meals  \n",
       "49908  Encryption, Cryptographic Block Cyphers, Padding Oracle Attack  \n",
       "31946  Encryption, Cryptographic Block Cyphers, Padding Oracle Attack  \n",
       "22859                                                  Food and Meals  \n",
       "64769                                                  Food and Meals  \n",
       "56031                                                  Food and Meals  \n",
       "49549                                                  Food and Meals  \n",
       "51833                                                  Food and Meals  \n",
       "41449                                 Home Repairs, Home Rennovations  \n",
       "25760                                 Home Repairs, Home Rennovations  \n",
       "27685                                                  Food and Meals  \n",
       "34062                                                  Food and Meals  \n",
       "17204                                International Travel Experiences  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"cluster_name\"] = list(map(d_cluster_label_names.get, cluster_numbers))\n",
    "with pd.option_context(\"display.max_colwidth\", 100):\n",
    "    display(df[[\"content\", \"cluster_name\"]].sample(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e79f5e-6611-44b1-a244-7d8f7b4bfcfa",
   "metadata": {},
   "source": [
    "## Export to Disk for Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec1427-4eb0-4291-9119-13bd46f56a09",
   "metadata": {},
   "source": [
    "Export the Pipeline so it can be used during deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7301d2dc-78f1-43a5-bea0-4575300a99b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(pipe, \"cluster_v1.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378bcfc-f16d-41ad-b7b6-47d62bb61b6f",
   "metadata": {},
   "source": [
    "## Iterating over End-to-End Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be5a2762-5e9c-4ae2-93c0-18670d816590",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_clean = Pipeline([(\"cleantext\", TextCleaner(\"content\"))])\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.85,  # ignore tokens with a document freq > 80%\n",
    "    min_df=15,  # ignore terms with doc freq < 20%\n",
    "    stop_words=all_stop_words,  # we did this during the cleaning\n",
    "    ngram_range=(1, 1),  # unigrams\n",
    ")\n",
    "kmeans_random_state = 42\n",
    "est = KMeans(\n",
    "    n_clusters=n_clusters,\n",
    "    max_iter=500,\n",
    "    n_init=10,\n",
    "    random_state=kmeans_random_state,\n",
    ")\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", vectorizer),\n",
    "        (\"clusterer\", est),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"vectorizer__max_df\": [0.85, 0.75],\n",
    "    \"vectorizer__min_df\": [15, 50],\n",
    "    \"clusterer__max_iter\": [500, 750],\n",
    "    \"clusterer__n_init\": [10],\n",
    "    \"clusterer__n_clusters\": [6],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30f991f4-ba6d-4082-b308-1f0e0e3466cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:31:10.761 | Beginning flow run 'adept-gharial' for flow 'Run through complete Clustering Workflow'...\n",
      "16:31:10.762 | Starting task runner `SequentialTaskRunner`...\n",
      "16:31:16.952 | Beginning subflow run 'brainy-capuchin' for flow 'Preprocess Text Data'...\n",
      "16:31:16.952 | Starting task runner `SequentialTaskRunner`...\n",
      "16:31:23.294 | Cleaning...\n",
      "16:31:54.304 | Done\n",
      "16:31:54.785 | Shutting down task runner `SequentialTaskRunner`...\n",
      "16:31:57.169 | Subflow run 'brainy-capuchin' finished in state Completed(message=None, type=COMPLETED)\n",
      "16:32:04.009 | Beginning subflow run 'tiny-beetle' for flow 'Cluster Data'...\n",
      "16:32:04.010 | Starting task runner `DaskTaskRunner`...\n",
      "16:32:04.010 | Creating a new Dask cluster with `distributed.deploy.local.LocalCluster`\n",
      "16:32:04.750 | The Dask dashboard is available at http://127.0.0.1:8787/status\n",
      "16:32:08.088 | Submitting task run 'cluster_data-902e7ee1-0' to task runner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edesz/Downloads/text-clustering/.tox/build/lib/python3.9/site-packages/distributed/worker.py:4370: UserWarning: Large object of size 115.04 MiB detected in task graph: \n",
      "  {'task': <prefect.tasks.Task object at 0x7f7bc2977 ... ait_for': None}\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:32:12.228 | Submitting task run 'cluster_data-902e7ee1-1' to task runner...\n",
      "16:32:13.392 | Training with {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}...\n",
      "16:32:15.743 | Submitting task run 'cluster_data-902e7ee1-2' to task runner...\n",
      "16:32:16.908 | Training with {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}...\n",
      "16:32:19.326 | Submitting task run 'cluster_data-902e7ee1-3' to task runner...\n",
      "16:32:20.565 | Training with {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}...\n",
      "16:32:23.006 | Submitting task run 'cluster_data-902e7ee1-4' to task runner...\n",
      "16:32:24.331 | Training with {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}...\n",
      "16:32:27.019 | Submitting task run 'cluster_data-902e7ee1-5' to task runner...\n",
      "16:32:30.140 | Done.\n",
      "16:32:30.140 | Getting top 10 tokens (by TFIDF weight) per cluster...\n",
      "16:32:30.264 | Done\n",
      "16:32:30.264 | Getting assigned cluster numbers from Pipeline attribute...\n",
      "16:32:30.382 | Done\n",
      "16:32:30.382 | Getting posts for each cluster...\n",
      "16:32:31.079 | Submitting task run 'cluster_data-902e7ee1-6' to task runner...\n",
      "16:32:31.363 | Done\n",
      "16:32:31.370 | Getting post 1 (row index=81,864) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.370 | Done\n",
      "16:32:31.370 | Getting post 2 (row index=22,211) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.370 | Done\n",
      "16:32:31.370 | Getting post 3 (row index=74,198) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.370 | Done\n",
      "16:32:31.371 | Getting post 4 (row index=44,660) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.371 | Done\n",
      "16:32:31.371 | Getting post 5 (row index=45,540) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.371 | Done\n",
      "16:32:31.372 | Getting post 1 (row index=63,096) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.372 | Done\n",
      "16:32:31.372 | Getting post 2 (row index=31,500) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.372 | Done\n",
      "16:32:31.372 | Getting post 3 (row index=8,153) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.372 | Done\n",
      "16:32:31.372 | Getting post 4 (row index=6,644) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.372 | Done\n",
      "16:32:31.372 | Getting post 5 (row index=65,112) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.373 | Done\n",
      "16:32:31.373 | Getting post 1 (row index=60,884) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.374 | Done\n",
      "16:32:31.374 | Getting post 2 (row index=62,339) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.374 | Done\n",
      "16:32:31.374 | Getting post 3 (row index=6,276) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.374 | Done\n",
      "16:32:31.374 | Getting post 4 (row index=63,446) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.374 | Done\n",
      "16:32:31.374 | Getting post 5 (row index=7,857) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.374 | Done\n",
      "16:32:31.375 | Getting post 1 (row index=33,566) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.375 | Done\n",
      "16:32:31.375 | Getting post 2 (row index=48,613) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.375 | Done\n",
      "16:32:31.375 | Getting post 3 (row index=55,030) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.375 | Done\n",
      "16:32:31.375 | Getting post 4 (row index=49,361) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.376 | Done\n",
      "16:32:31.376 | Getting post 5 (row index=55,078) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.376 | Done\n",
      "16:32:31.377 | Getting post 1 (row index=15,061) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.377 | Done\n",
      "16:32:31.377 | Getting post 2 (row index=65,232) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.377 | Done\n",
      "16:32:31.377 | Getting post 3 (row index=6,061) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.377 | Done\n",
      "16:32:31.377 | Getting post 4 (row index=11,890) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.377 | Done\n",
      "16:32:31.377 | Getting post 5 (row index=57,730) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.377 | Done\n",
      "16:32:31.378 | Getting post 1 (row index=42,634) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.378 | Done\n",
      "16:32:31.378 | Getting post 2 (row index=69,637) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.379 | Done\n",
      "16:32:31.379 | Getting post 3 (row index=86,569) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.379 | Done\n",
      "16:32:31.379 | Getting post 4 (row index=9,433) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.379 | Done\n",
      "16:32:31.379 | Getting post 5 (row index=28,252) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:31.379 | Done\n",
      "16:32:31.823 | Task run 'cluster_data-902e7ee1-0' finished in state Completed(message=None, type=COMPLETED)\n",
      "16:32:33.474 | Done.\n",
      "16:32:33.474 | Getting top 10 tokens (by TFIDF weight) per cluster...\n",
      "16:32:33.603 | Done\n",
      "16:32:33.603 | Getting assigned cluster numbers from Pipeline attribute...\n",
      "16:32:33.700 | Done\n",
      "16:32:33.700 | Getting posts for each cluster...\n",
      "16:32:34.612 | Done\n",
      "16:32:34.624 | Getting post 1 (row index=60,884) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.624 | Done\n",
      "16:32:34.624 | Getting post 2 (row index=62,339) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.624 | Done\n",
      "16:32:34.624 | Getting post 3 (row index=6,276) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.624 | Done\n",
      "16:32:34.624 | Getting post 4 (row index=63,446) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.624 | Done\n",
      "16:32:34.625 | Getting post 5 (row index=7,857) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.625 | Done\n",
      "16:32:34.626 | Getting post 1 (row index=42,634) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.626 | Done\n",
      "16:32:34.626 | Getting post 2 (row index=69,637) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.626 | Done\n",
      "16:32:34.626 | Getting post 3 (row index=86,569) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.626 | Done\n",
      "16:32:34.626 | Getting post 4 (row index=9,433) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.626 | Done\n",
      "16:32:34.626 | Getting post 5 (row index=28,252) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.626 | Done\n",
      "16:32:34.628 | Getting post 1 (row index=33,566) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.628 | Done\n",
      "16:32:34.628 | Getting post 2 (row index=48,613) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.628 | Done\n",
      "16:32:34.628 | Getting post 3 (row index=55,030) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.628 | Done\n",
      "16:32:34.629 | Getting post 4 (row index=49,361) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.629 | Done\n",
      "16:32:34.629 | Getting post 5 (row index=55,078) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.629 | Done\n",
      "16:32:34.630 | Getting post 1 (row index=81,864) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.630 | Done\n",
      "16:32:34.630 | Getting post 2 (row index=22,211) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.630 | Done\n",
      "16:32:34.631 | Getting post 3 (row index=74,198) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.631 | Done\n",
      "16:32:34.631 | Getting post 4 (row index=44,660) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.631 | Done\n",
      "16:32:34.631 | Getting post 5 (row index=83,398) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.631 | Done\n",
      "16:32:34.632 | Getting post 1 (row index=63,096) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.633 | Done\n",
      "16:32:34.633 | Getting post 2 (row index=31,500) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.633 | Done\n",
      "16:32:34.633 | Getting post 3 (row index=8,153) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.633 | Done\n",
      "16:32:34.633 | Getting post 4 (row index=6,644) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.633 | Done\n",
      "16:32:34.633 | Getting post 5 (row index=65,112) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.633 | Done\n",
      "16:32:34.635 | Getting post 1 (row index=15,061) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.635 | Done\n",
      "16:32:34.635 | Getting post 2 (row index=65,232) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.635 | Done\n",
      "16:32:34.635 | Getting post 3 (row index=6,061) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.635 | Done\n",
      "16:32:34.635 | Getting post 4 (row index=11,890) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.635 | Done\n",
      "16:32:34.635 | Getting post 5 (row index=57,730) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:32:34.636 | Done\n",
      "16:32:35.051 | Submitting task run 'cluster_data-902e7ee1-7' to task runner...\n",
      "16:32:35.536 | Task run 'cluster_data-902e7ee1-1' finished in state Completed(message=None, type=COMPLETED)\n",
      "16:32:35.942 | Training with {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}...\n",
      "16:32:37.883 | Done.\n",
      "16:32:37.885 | Getting top 10 tokens (by TFIDF weight) per cluster...\n",
      "16:32:37.999 | Done\n",
      "16:32:38.000 | Getting assigned cluster numbers from Pipeline attribute...\n",
      "16:32:38.104 | Done\n",
      "16:32:38.104 | Getting posts for each cluster...\n",
      "16:32:38.978 | Done\n",
      "16:32:38.984 | Getting post 1 (row index=81,864) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.984 | Done\n",
      "16:32:38.984 | Getting post 2 (row index=22,211) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.984 | Done\n",
      "16:32:38.984 | Getting post 3 (row index=74,198) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.984 | Done\n",
      "16:32:38.984 | Getting post 4 (row index=44,660) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.984 | Done\n",
      "16:32:38.984 | Getting post 5 (row index=45,540) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.984 | Done\n",
      "16:32:38.985 | Getting post 1 (row index=63,096) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.986 | Done\n",
      "16:32:38.986 | Getting post 2 (row index=31,500) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.986 | Done\n",
      "16:32:38.986 | Getting post 3 (row index=8,153) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.986 | Done\n",
      "16:32:38.986 | Getting post 4 (row index=6,644) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.986 | Done\n",
      "16:32:38.986 | Getting post 5 (row index=65,112) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.986 | Done\n",
      "16:32:38.987 | Getting post 1 (row index=60,884) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.987 | Done\n",
      "16:32:38.987 | Getting post 2 (row index=62,339) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.987 | Done\n",
      "16:32:38.987 | Getting post 3 (row index=6,276) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:38.987 | Done\n",
      "16:32:38.987 | Getting post 4 (row index=63,446) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.002 | Done\n",
      "16:32:39.002 | Getting post 5 (row index=7,857) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.002 | Done\n",
      "16:32:39.003 | Getting post 1 (row index=33,566) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.003 | Done\n",
      "16:32:39.003 | Getting post 2 (row index=48,613) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.003 | Done\n",
      "16:32:39.003 | Getting post 3 (row index=55,030) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.003 | Done\n",
      "16:32:39.003 | Getting post 4 (row index=49,361) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.004 | Done\n",
      "16:32:39.004 | Getting post 5 (row index=55,078) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.004 | Done\n",
      "16:32:39.005 | Getting post 1 (row index=15,061) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.005 | Done\n",
      "16:32:39.005 | Getting post 2 (row index=65,232) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.005 | Done\n",
      "16:32:39.005 | Getting post 3 (row index=6,061) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.005 | Done\n",
      "16:32:39.005 | Getting post 4 (row index=11,890) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.005 | Done\n",
      "16:32:39.005 | Getting post 5 (row index=57,730) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.005 | Done\n",
      "16:32:39.006 | Getting post 1 (row index=42,634) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.006 | Done\n",
      "16:32:39.006 | Getting post 2 (row index=69,637) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.006 | Done\n",
      "16:32:39.006 | Getting post 3 (row index=86,569) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.007 | Done\n",
      "16:32:39.007 | Getting post 4 (row index=9,433) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.007 | Done\n",
      "16:32:39.007 | Getting post 5 (row index=28,252) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:32:39.007 | Done\n",
      "16:32:41.542 | Done.\n",
      "16:32:41.542 | Getting top 10 tokens (by TFIDF weight) per cluster...\n",
      "16:32:41.651 | Done\n",
      "16:32:41.652 | Getting assigned cluster numbers from Pipeline attribute...\n",
      "16:32:41.750 | Done\n",
      "16:32:41.750 | Getting posts for each cluster...\n",
      "16:32:42.525 | Done\n",
      "16:32:42.548 | Getting post 1 (row index=60,884) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.548 | Done\n",
      "16:32:42.548 | Getting post 2 (row index=62,339) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.548 | Done\n",
      "16:32:42.548 | Getting post 3 (row index=6,276) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.548 | Done\n",
      "16:32:42.548 | Getting post 4 (row index=63,446) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.548 | Done\n",
      "16:32:42.548 | Getting post 5 (row index=7,857) to read in cluster 2 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.548 | Done\n",
      "16:32:42.549 | Getting post 1 (row index=42,634) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.549 | Done\n",
      "16:32:42.550 | Getting post 2 (row index=69,637) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.550 | Done\n",
      "16:32:42.550 | Getting post 3 (row index=86,569) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.550 | Done\n",
      "16:32:42.550 | Getting post 4 (row index=9,433) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.550 | Done\n",
      "16:32:42.550 | Getting post 5 (row index=28,252) to read in cluster 3 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.550 | Done\n",
      "16:32:42.551 | Getting post 1 (row index=33,566) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.551 | Done\n",
      "16:32:42.551 | Getting post 2 (row index=48,613) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.551 | Done\n",
      "16:32:42.551 | Getting post 3 (row index=55,030) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.551 | Done\n",
      "16:32:42.551 | Getting post 4 (row index=49,361) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.551 | Done\n",
      "16:32:42.551 | Getting post 5 (row index=55,078) to read in cluster 1 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.552 | Done\n",
      "16:32:42.552 | Getting post 1 (row index=81,864) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.553 | Done\n",
      "16:32:42.553 | Getting post 2 (row index=22,211) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.553 | Done\n",
      "16:32:42.553 | Getting post 3 (row index=74,198) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.553 | Done\n",
      "16:32:42.553 | Getting post 4 (row index=44,660) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.553 | Done\n",
      "16:32:42.553 | Getting post 5 (row index=83,398) to read in cluster 0 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.553 | Done\n",
      "16:32:42.554 | Getting post 1 (row index=63,096) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.554 | Done\n",
      "16:32:42.554 | Getting post 2 (row index=31,500) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.554 | Done\n",
      "16:32:42.554 | Getting post 3 (row index=8,153) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.554 | Done\n",
      "16:32:42.554 | Getting post 4 (row index=6,644) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.554 | Done\n",
      "16:32:42.555 | Getting post 5 (row index=65,112) to read in cluster 4 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.555 | Done\n",
      "16:32:42.555 | Getting post 1 (row index=15,061) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.556 | Done\n",
      "16:32:42.556 | Getting post 2 (row index=65,232) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.556 | Done\n",
      "16:32:42.556 | Getting post 3 (row index=6,061) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.556 | Done\n",
      "16:32:42.556 | Getting post 4 (row index=11,890) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.556 | Done\n",
      "16:32:42.556 | Getting post 5 (row index=57,730) to read in cluster 5 found using {'max_iter': 500, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:32:42.556 | Done\n",
      "16:32:51.065 | Done.\n",
      "16:32:51.065 | Getting top 10 tokens (by TFIDF weight) per cluster...\n",
      "16:32:51.178 | Done\n",
      "16:32:51.178 | Getting assigned cluster numbers from Pipeline attribute...\n",
      "16:32:51.276 | Done\n",
      "16:32:51.276 | Getting posts for each cluster...\n",
      "16:32:51.892 | Done\n",
      "16:32:51.896 | Getting post 1 (row index=81,864) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.896 | Done\n",
      "16:32:51.897 | Getting post 2 (row index=22,211) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.897 | Done\n",
      "16:32:51.897 | Getting post 3 (row index=74,198) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.897 | Done\n",
      "16:32:51.897 | Getting post 4 (row index=44,660) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.897 | Done\n",
      "16:32:51.897 | Getting post 5 (row index=45,540) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.897 | Done\n",
      "16:32:51.898 | Getting post 1 (row index=63,096) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.898 | Done\n",
      "16:32:51.898 | Getting post 2 (row index=31,500) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.898 | Done\n",
      "16:32:51.898 | Getting post 3 (row index=8,153) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.898 | Done\n",
      "16:32:51.898 | Getting post 4 (row index=6,644) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.898 | Done\n",
      "16:32:51.899 | Getting post 5 (row index=65,112) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.899 | Done\n",
      "16:32:51.899 | Getting post 1 (row index=60,884) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.899 | Done\n",
      "16:32:51.900 | Getting post 2 (row index=62,339) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.900 | Done\n",
      "16:32:51.900 | Getting post 3 (row index=6,276) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.900 | Done\n",
      "16:32:51.900 | Getting post 4 (row index=63,446) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.900 | Done\n",
      "16:32:51.900 | Getting post 5 (row index=7,857) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.900 | Done\n",
      "16:32:51.901 | Getting post 1 (row index=33,566) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.901 | Done\n",
      "16:32:51.901 | Getting post 2 (row index=48,613) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.901 | Done\n",
      "16:32:51.901 | Getting post 3 (row index=55,030) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.901 | Done\n",
      "16:32:51.901 | Getting post 4 (row index=49,361) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.901 | Done\n",
      "16:32:51.901 | Getting post 5 (row index=55,078) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.901 | Done\n",
      "16:32:51.902 | Getting post 1 (row index=15,061) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.916 | Done\n",
      "16:32:51.916 | Getting post 2 (row index=65,232) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.916 | Done\n",
      "16:32:51.916 | Getting post 3 (row index=6,061) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.916 | Done\n",
      "16:32:51.916 | Getting post 4 (row index=11,890) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.916 | Done\n",
      "16:32:51.917 | Getting post 5 (row index=57,730) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.917 | Done\n",
      "16:32:51.918 | Getting post 1 (row index=42,634) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.918 | Done\n",
      "16:32:51.918 | Getting post 2 (row index=69,637) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.918 | Done\n",
      "16:32:51.918 | Getting post 3 (row index=86,569) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.918 | Done\n",
      "16:32:51.918 | Getting post 4 (row index=9,433) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.919 | Done\n",
      "16:32:51.919 | Getting post 5 (row index=28,252) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 15}...\n",
      "16:32:51.919 | Done\n",
      "16:32:52.233 | Training with {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}...\n",
      "16:32:52.574 | Training with {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}...\n",
      "16:32:52.915 | Task run 'cluster_data-902e7ee1-2' finished in state Completed(message=None, type=COMPLETED)\n",
      "16:32:53.259 | Task run 'cluster_data-902e7ee1-3' finished in state Completed(message=None, type=COMPLETED)\n",
      "16:33:07.759 | Done.\n",
      "16:33:07.759 | Getting top 10 tokens (by TFIDF weight) per cluster...\n",
      "16:33:07.876 | Done\n",
      "16:33:07.876 | Getting assigned cluster numbers from Pipeline attribute...\n",
      "16:33:07.979 | Done\n",
      "16:33:07.980 | Getting posts for each cluster...\n",
      "16:33:08.086 | Done.\n",
      "16:33:08.086 | Getting top 10 tokens (by TFIDF weight) per cluster...\n",
      "16:33:08.192 | Done\n",
      "16:33:08.192 | Getting assigned cluster numbers from Pipeline attribute...\n",
      "16:33:08.293 | Done\n",
      "16:33:08.293 | Getting posts for each cluster...\n",
      "16:33:08.643 | Done\n",
      "16:33:08.648 | Getting post 1 (row index=81,864) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.648 | Done\n",
      "16:33:08.648 | Getting post 2 (row index=22,211) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.648 | Done\n",
      "16:33:08.648 | Getting post 3 (row index=74,198) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.649 | Done\n",
      "16:33:08.649 | Getting post 4 (row index=44,660) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.649 | Done\n",
      "16:33:08.649 | Getting post 5 (row index=45,540) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.649 | Done\n",
      "16:33:08.650 | Getting post 1 (row index=63,096) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.665 | Done\n",
      "16:33:08.665 | Getting post 2 (row index=31,500) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.666 | Done\n",
      "16:33:08.666 | Getting post 3 (row index=8,153) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.666 | Done\n",
      "16:33:08.666 | Getting post 4 (row index=6,644) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.666 | Done\n",
      "16:33:08.666 | Getting post 5 (row index=65,112) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.666 | Done\n",
      "16:33:08.667 | Getting post 1 (row index=60,884) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.668 | Done\n",
      "16:33:08.668 | Getting post 2 (row index=62,339) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.668 | Done\n",
      "16:33:08.668 | Getting post 3 (row index=6,276) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.668 | Done\n",
      "16:33:08.668 | Getting post 4 (row index=63,446) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.668 | Done\n",
      "16:33:08.668 | Getting post 5 (row index=7,857) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.668 | Done\n",
      "16:33:08.669 | Getting post 1 (row index=33,566) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.669 | Done\n",
      "16:33:08.669 | Getting post 2 (row index=48,613) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.669 | Done\n",
      "16:33:08.670 | Getting post 3 (row index=55,030) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.670 | Done\n",
      "16:33:08.670 | Getting post 4 (row index=49,361) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.670 | Done\n",
      "16:33:08.670 | Getting post 5 (row index=55,078) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.670 | Done\n",
      "16:33:08.671 | Getting post 1 (row index=15,061) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.671 | Done\n",
      "16:33:08.671 | Getting post 2 (row index=65,232) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.671 | Done\n",
      "16:33:08.671 | Getting post 3 (row index=6,061) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.671 | Done\n",
      "16:33:08.671 | Getting post 4 (row index=11,890) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.671 | Done\n",
      "16:33:08.672 | Getting post 5 (row index=57,730) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.672 | Done\n",
      "16:33:08.672 | Getting post 1 (row index=42,634) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.673 | Done\n",
      "16:33:08.673 | Getting post 2 (row index=69,637) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.673 | Done\n",
      "16:33:08.673 | Getting post 3 (row index=86,569) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.673 | Done\n",
      "16:33:08.673 | Getting post 4 (row index=9,433) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.673 | Done\n",
      "16:33:08.673 | Getting post 5 (row index=28,252) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 15}...\n",
      "16:33:08.673 | Done\n",
      "16:33:08.969 | Done\n",
      "16:33:08.974 | Getting post 1 (row index=60,884) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.974 | Done\n",
      "16:33:08.974 | Getting post 2 (row index=62,339) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.974 | Done\n",
      "16:33:08.974 | Getting post 3 (row index=6,276) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.974 | Done\n",
      "16:33:08.974 | Getting post 4 (row index=63,446) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.993 | Done\n",
      "16:33:08.993 | Getting post 5 (row index=7,857) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.993 | Done\n",
      "16:33:08.995 | Getting post 1 (row index=42,634) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.995 | Done\n",
      "16:33:08.995 | Getting post 2 (row index=69,637) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.995 | Done\n",
      "16:33:08.995 | Getting post 3 (row index=86,569) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.995 | Done\n",
      "16:33:08.995 | Getting post 4 (row index=9,433) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.995 | Done\n",
      "16:33:08.996 | Getting post 5 (row index=28,252) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.996 | Done\n",
      "16:33:08.997 | Getting post 1 (row index=33,566) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.997 | Done\n",
      "16:33:08.997 | Getting post 2 (row index=48,613) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.997 | Done\n",
      "16:33:08.997 | Getting post 3 (row index=55,030) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.997 | Done\n",
      "16:33:08.997 | Getting post 4 (row index=49,361) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.997 | Done\n",
      "16:33:08.997 | Getting post 5 (row index=55,078) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.997 | Done\n",
      "16:33:08.998 | Getting post 1 (row index=81,864) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.998 | Done\n",
      "16:33:08.998 | Getting post 2 (row index=22,211) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.999 | Done\n",
      "16:33:08.999 | Getting post 3 (row index=74,198) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.999 | Done\n",
      "16:33:08.999 | Getting post 4 (row index=44,660) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.999 | Done\n",
      "16:33:08.999 | Getting post 5 (row index=83,398) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:08.999 | Done\n",
      "16:33:09.000 | Getting post 1 (row index=63,096) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:09.000 | Done\n",
      "16:33:09.000 | Getting post 2 (row index=31,500) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:09.000 | Done\n",
      "16:33:09.000 | Getting post 3 (row index=8,153) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:09.000 | Done\n",
      "16:33:09.001 | Getting post 4 (row index=6,644) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:09.001 | Done\n",
      "16:33:09.001 | Getting post 5 (row index=65,112) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:09.001 | Done\n",
      "16:33:09.002 | Getting post 1 (row index=15,061) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:09.002 | Done\n",
      "16:33:09.002 | Getting post 2 (row index=65,232) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:09.002 | Done\n",
      "16:33:09.002 | Getting post 3 (row index=6,061) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:09.002 | Done\n",
      "16:33:09.002 | Getting post 4 (row index=11,890) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:09.002 | Done\n",
      "16:33:09.003 | Getting post 5 (row index=57,730) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.75, 'min_df': 50}...\n",
      "16:33:09.003 | Done\n",
      "16:33:09.029 | Task run 'cluster_data-902e7ee1-4' finished in state Completed(message=None, type=COMPLETED)\n",
      "16:33:09.359 | Task run 'cluster_data-902e7ee1-7' finished in state Completed(message=None, type=COMPLETED)\n",
      "16:33:09.682 | Training with {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}...\n",
      "16:33:10.061 | Task run 'cluster_data-902e7ee1-6' finished in state Completed(message=None, type=COMPLETED)\n",
      "16:33:23.766 | Done.\n",
      "16:33:23.766 | Getting top 10 tokens (by TFIDF weight) per cluster...\n",
      "16:33:23.862 | Done\n",
      "16:33:23.862 | Getting assigned cluster numbers from Pipeline attribute...\n",
      "16:33:23.950 | Done\n",
      "16:33:23.951 | Getting posts for each cluster...\n",
      "16:33:24.554 | Done\n",
      "16:33:24.559 | Getting post 1 (row index=60,884) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.559 | Done\n",
      "16:33:24.559 | Getting post 2 (row index=62,339) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.559 | Done\n",
      "16:33:24.559 | Getting post 3 (row index=6,276) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.559 | Done\n",
      "16:33:24.559 | Getting post 4 (row index=63,446) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.559 | Done\n",
      "16:33:24.560 | Getting post 5 (row index=7,857) to read in cluster 2 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.560 | Done\n",
      "16:33:24.561 | Getting post 1 (row index=42,634) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.561 | Done\n",
      "16:33:24.578 | Getting post 2 (row index=69,637) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.578 | Done\n",
      "16:33:24.578 | Getting post 3 (row index=86,569) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.578 | Done\n",
      "16:33:24.578 | Getting post 4 (row index=9,433) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.579 | Done\n",
      "16:33:24.579 | Getting post 5 (row index=28,252) to read in cluster 3 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.579 | Done\n",
      "16:33:24.580 | Getting post 1 (row index=33,566) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.580 | Done\n",
      "16:33:24.580 | Getting post 2 (row index=48,613) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.580 | Done\n",
      "16:33:24.580 | Getting post 3 (row index=55,030) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.580 | Done\n",
      "16:33:24.580 | Getting post 4 (row index=49,361) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.580 | Done\n",
      "16:33:24.581 | Getting post 5 (row index=55,078) to read in cluster 1 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.581 | Done\n",
      "16:33:24.581 | Getting post 1 (row index=81,864) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.582 | Done\n",
      "16:33:24.582 | Getting post 2 (row index=22,211) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.582 | Done\n",
      "16:33:24.582 | Getting post 3 (row index=74,198) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.582 | Done\n",
      "16:33:24.582 | Getting post 4 (row index=44,660) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.582 | Done\n",
      "16:33:24.582 | Getting post 5 (row index=83,398) to read in cluster 0 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.582 | Done\n",
      "16:33:24.583 | Getting post 1 (row index=63,096) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.583 | Done\n",
      "16:33:24.583 | Getting post 2 (row index=31,500) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.583 | Done\n",
      "16:33:24.584 | Getting post 3 (row index=8,153) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.584 | Done\n",
      "16:33:24.584 | Getting post 4 (row index=6,644) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.584 | Done\n",
      "16:33:24.584 | Getting post 5 (row index=65,112) to read in cluster 4 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.584 | Done\n",
      "16:33:24.585 | Getting post 1 (row index=15,061) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.585 | Done\n",
      "16:33:24.585 | Getting post 2 (row index=65,232) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.585 | Done\n",
      "16:33:24.585 | Getting post 3 (row index=6,061) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.585 | Done\n",
      "16:33:24.585 | Getting post 4 (row index=11,890) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.585 | Done\n",
      "16:33:24.585 | Getting post 5 (row index=57,730) to read in cluster 5 found using {'max_iter': 750, 'n_clusters': 6, 'n_init': 10, 'max_df': 0.85, 'min_df': 50}...\n",
      "16:33:24.586 | Done\n",
      "16:33:24.911 | Task run 'cluster_data-902e7ee1-5' finished in state Completed(message=None, type=COMPLETED)\n",
      "16:33:24.928 | Shutting down task runner `DaskTaskRunner`...\n",
      "16:33:28.431 | Subflow run 'tiny-beetle' finished in state Completed(message='All states completed.', type=COMPLETED)\n",
      "16:33:28.955 | Beginning subflow run 'tough-terrier' for flow 'Combine list of DataFrames'...\n",
      "16:33:28.955 | Starting task runner `SequentialTaskRunner`...\n",
      "16:33:29.214 | Combining 8 Summary DataFrames...\n",
      "16:33:29.243 | Done\n",
      "16:33:29.246 | Shutting down task runner `SequentialTaskRunner`...\n",
      "16:33:29.518 | Subflow run 'tough-terrier' finished in state Completed(message=None, type=COMPLETED)\n",
      "16:33:29.756 | Submitting task run 'combine_all_strs-1397981b-0' to task runner...\n",
      "16:33:29.994 | Combining string of posts to read...\n",
      "16:33:29.995 | Done\n",
      "16:33:30.244 | Task run 'combine_all_strs-1397981b-0' finished in state Completed(message=None, type=COMPLETED)\n",
      "16:33:30.256 | Shutting down task runner `SequentialTaskRunner`...\n",
      "16:33:32.470 | Flow run 'adept-gharial' finished in state Completed(message='All states completed.', type=COMPLETED)\n",
      "CPU times: user 1min 8s, sys: 15.2 s, total: 1min 23s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "state = run_clustering_trials(\n",
    "    jsonpickle.encode(pipe_clean),\n",
    "    jsonpickle.encode(pipe),\n",
    "    df.drop(columns=[\"cluster_name\"], errors=\"ignore\").to_json(orient='split'),\n",
    "    list(ParameterGrid(param_grid)),\n",
    "    5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67136735-9d81-48fa-a813-45e6b8381f57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>num_clusters</th>\n",
       "      <th>cluster</th>\n",
       "      <th>top_10_tokens</th>\n",
       "      <th>params_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33566</td>\n",
       "      <td>&lt;p&gt;I'm a citizen of country X and have a valid United States ESTA in my X passport.  Recently, I...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[visa, passport, uk, schengen, us, travel, days, need, transit, visit]</td>\n",
       "      <td>{'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48613</td>\n",
       "      <td>&lt;p&gt;I am not sure this is the right place to ask this question but assuming any traveler might ha...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[visa, passport, uk, schengen, us, travel, days, need, transit, visit]</td>\n",
       "      <td>{'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55030</td>\n",
       "      <td>&lt;p&gt;My old passport have 2-year valid visa of DRCongo and it is expire on 04.06.2016. Now I am on...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[visa, passport, uk, schengen, us, travel, days, need, transit, visit]</td>\n",
       "      <td>{'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49361</td>\n",
       "      <td>&lt;p&gt;I am flying from London to Central America and back this summer on a bit of an extended holid...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[visa, passport, uk, schengen, us, travel, days, need, transit, visit]</td>\n",
       "      <td>{'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55078</td>\n",
       "      <td>&lt;p&gt;My wife has a Schengen visa issued by the Italian consulate in the UK.&lt;/p&gt;\\n\\n&lt;p&gt;It expires a...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[visa, passport, uk, schengen, us, travel, days, need, transit, visit]</td>\n",
       "      <td>{'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15061</td>\n",
       "      <td>&lt;p&gt;It's always difficult to decide what clothes to take with you when you go to a new place. Usu...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>[would, like, one, know, use, get, time, make, find, way]</td>\n",
       "      <td>{'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>65232</td>\n",
       "      <td>&lt;p&gt;I see the TSA have brought in &lt;a href=\"http://www.nytimes.com/2014/07/08/us/new-tsa-rules-for...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>[would, like, one, know, use, get, time, make, find, way]</td>\n",
       "      <td>{'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6061</td>\n",
       "      <td>&lt;p&gt;I'm planning to visit Medellin and Bogota sometime in the near future. I've a U.S. DL which e...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>[would, like, one, know, use, get, time, make, find, way]</td>\n",
       "      <td>{'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11890</td>\n",
       "      <td>&lt;p&gt;The way I currently cook kidney beans is to soak them overnight. But still they have to be co...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>[would, like, one, know, use, get, time, make, find, way]</td>\n",
       "      <td>{'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>57730</td>\n",
       "      <td>&lt;p&gt;To quote Goodman &amp;amp; Gilman :&lt;/p&gt;\\n\\n&lt;blockquote&gt;\\n  &lt;p&gt;An alternative way of defining the ...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>[would, like, one, know, use, get, time, make, find, way]</td>\n",
       "      <td>{'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  \\\n",
       "0   33566   \n",
       "1   48613   \n",
       "2   55030   \n",
       "3   49361   \n",
       "4   55078   \n",
       "..    ...   \n",
       "25  15061   \n",
       "26  65232   \n",
       "27   6061   \n",
       "28  11890   \n",
       "29  57730   \n",
       "\n",
       "                                                                                                content  \\\n",
       "0   <p>I'm a citizen of country X and have a valid United States ESTA in my X passport.  Recently, I...   \n",
       "1   <p>I am not sure this is the right place to ask this question but assuming any traveler might ha...   \n",
       "2   <p>My old passport have 2-year valid visa of DRCongo and it is expire on 04.06.2016. Now I am on...   \n",
       "3   <p>I am flying from London to Central America and back this summer on a bit of an extended holid...   \n",
       "4   <p>My wife has a Schengen visa issued by the Italian consulate in the UK.</p>\\n\\n<p>It expires a...   \n",
       "..                                                                                                  ...   \n",
       "25  <p>It's always difficult to decide what clothes to take with you when you go to a new place. Usu...   \n",
       "26  <p>I see the TSA have brought in <a href=\"http://www.nytimes.com/2014/07/08/us/new-tsa-rules-for...   \n",
       "27  <p>I'm planning to visit Medellin and Bogota sometime in the near future. I've a U.S. DL which e...   \n",
       "28  <p>The way I currently cook kidney beans is to soak them overnight. But still they have to be co...   \n",
       "29  <p>To quote Goodman &amp; Gilman :</p>\\n\\n<blockquote>\\n  <p>An alternative way of defining the ...   \n",
       "\n",
       "    num_clusters  cluster  \\\n",
       "0              6        0   \n",
       "1              6        0   \n",
       "2              6        0   \n",
       "3              6        0   \n",
       "4              6        0   \n",
       "..           ...      ...   \n",
       "25             6        5   \n",
       "26             6        5   \n",
       "27             6        5   \n",
       "28             6        5   \n",
       "29             6        5   \n",
       "\n",
       "                                                             top_10_tokens  \\\n",
       "0   [visa, passport, uk, schengen, us, travel, days, need, transit, visit]   \n",
       "1   [visa, passport, uk, schengen, us, travel, days, need, transit, visit]   \n",
       "2   [visa, passport, uk, schengen, us, travel, days, need, transit, visit]   \n",
       "3   [visa, passport, uk, schengen, us, travel, days, need, transit, visit]   \n",
       "4   [visa, passport, uk, schengen, us, travel, days, need, transit, visit]   \n",
       "..                                                                     ...   \n",
       "25               [would, like, one, know, use, get, time, make, find, way]   \n",
       "26               [would, like, one, know, use, get, time, make, find, way]   \n",
       "27               [would, like, one, know, use, get, time, make, find, way]   \n",
       "28               [would, like, one, know, use, get, time, make, find, way]   \n",
       "29               [would, like, one, know, use, get, time, make, find, way]   \n",
       "\n",
       "                                                                                             params_str  \n",
       "0   {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...  \n",
       "1   {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...  \n",
       "2   {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...  \n",
       "3   {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...  \n",
       "4   {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...  \n",
       "..                                                                                                  ...  \n",
       "25  {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...  \n",
       "26  {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...  \n",
       "27  {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...  \n",
       "28  {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...  \n",
       "29  {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__m...  \n",
       "\n",
       "[240 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 2, Raw data index = 81,864, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I live in the Midwest of the United States, and we not-too-rarely get a large amount of rain coming down at one time both in the spring and sometimes in the fall. Last night was no different (aside from random earthquakes..) than usual, but after I went to bed, my smoke alarm went off. I quickly determined that there was in fact no fire, so I went to take the smoke alarm off of its mounting and when I removed it, I found that there was a decent amount of water in the smoke detector. If I had to guess I'd say about 50 mL. So not a huge amount, but enough to set it off.I left it off for a time, and did not notice any more water coming from the opening in the ceiling (which is a recess where the detector and power wiring sits, not fully open to the attic (just where the wires come in, as far as I know. I didn't examine it terribly closely), even though it was still raining fairly hard (though not nearly as hard as it had been). This morning, I went to have a look around the attic to see if I could see anywhere it was leaking (it is still misting outside, but not raining any longer), but I was unable to detect any wet spots in the roof.What should my next step be? The roof (and indeed the house) is 1 year old, so I would hope that it hasn't sprung a leak, but I can't think of how else water would have gotten into the smoke detector. I also suspect paying someone to go and try to find a leak is going to be fairly expensive as well.The detector itself appears to be working. If I test it, and it functions, should I still replace it because of potential water damage?UpdateHere is a picture of the socket in question, and there is indeed cool air coming from it. I'm not totally convinced it is just condensation, elsewise this would have happened last year during the winter, I would think, but am unsure.\n",
      "\n",
      "Cluster = 2, Raw data index = 22,211, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "We discovered a bath tub leak from our second floor bathroom which dripped through the sidings. The bathroom has the original fixtures from 1989. It leaks when there's excess amount of water used.Would this be a simple problem of refinishing everything using plumber's putty?\n",
      "\n",
      "Cluster = 2, Raw data index = 74,198, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "The air quality in my basement is unpleasant. I don't know if I have mold. How to test for it? How is the smell of mold?I know that we had a water problem in the basement, the walls were cracked so every rainy day, we had humidity and water in the basement. But I have never seen signs of mold. How to check for mold?\n",
      "\n",
      "Cluster = 2, Raw data index = 44,660, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "Many instances of this worm-like creature were found in a water system for a mountain cabin in the Sierra Nevada mountains of the US, in late June / early July.  The water system collects water from an enclosed spring.  Can you help identify this creature?  Clues:The worms have two \"points\" on their heads. They can stretch out and be long and thin, or when poked (or are resting) they contract into a small blob.  Here is a picture of a single worm with markings shown.Here is a picture of a few worms, somewhat contracted. Here is a movie of them moving, in natural light.  Here is a movie of them moving, with backlight.Here are pictures of their undersides and their internal structures.Whenever I pull some out of the water and put them into a tupperware with the same water, they only survive for around 24 hours, after which they seem to disintegrate.  Here is a picture of about 20 of the worms after about 24 hours, the bulk of them have halfway-decomposed and form a heap in the upper right.  After another day it'll just look like debris in the water, you wouldn't even recognize that there were worms in it.  There is a piece of bacon in there because some suggested putting it there to test if they were leeches, but this disintegration happens repeatably and regardless of the bacon; please ignore the bacon.Someone suggested that they are trematodes, but there are no snails, frogs, or other creatures in the storage and collection sections of the water system;  we have looked very closely.  There may be something within a 30-foot section of pipe, but we doubt it.  Can you help us identify this creature?  Even just possible families of creatures or general categories would be helpful for us.\n",
      "\n",
      "Cluster = 2, Raw data index = 45,540, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "People may tend to spend time in a hot water spring. Is it possible to get hyperthermia (like a sun stroke) due to this?\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 3, Raw data index = 63,096, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I bought a new house about a month ago, and have since noticed some plumbing issues in the laundry room:laundry tub drains slowlyoccasional \"musty\" smell, which seems to come from the drainsI did some research online and found that lack of drain ventilation could cause both of these problems. So I checked the plumbing and it looks like both the washing machine and adjacent wash basin drain into the same pipe. As far as I can tell, there is no ventilation on these drains (photo below); it looks like a stacked pair of S-traps.The laundry room is in a little addition at the back of the house. So I probably cannot tie this back in to the main house venting stack without a lot of work. I gather the simplest solution is to locally install an air admittance valve (AAV). Does that sound like a reasonable approach here?If so, am I on the right track with one of these:http://www.rona.ca/en/air-admittance-valvehttp://www.amazon.ca/gp/product/B000H5SLWM?psc=1&amp;redirect=true&amp;ref_=ox_sc_act_title_1&amp;smid=A23X8TYK8IHNZFMy plan is to remove the upper S-trap. Then install a sanitary T, going to: AAV (top) and P-trap (horizontal). Does that sound right?\n",
      "\n",
      "Cluster = 3, Raw data index = 31,500, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I have read a lot about proper insulation and ventilation, including some posts on this site, but none adequately answer my questions.My goal is to operate an electric heat source in the winter and have ~60 &deg;F temperature maintained when working in the garage.  In the summer, I think we will typically leave the garage door open, however it would be nice to one day have it stay cool in there if it's 90-100 &deg;F outside.This is in Ohio, where we typically have temps of 0-95 &deg;F throughout the year, it can also get pretty humid.I do not have soffit vents, but there is a ridge vent on the roof already installed.  I do not want to drywall nor do I want to build a ceiling.As you see in the photos I have already insulated the walls with R15 Batt installation.  Now I'm unsure where to go from here for roof 2x6's.  I bought some radiant barrier R11-equivelent insulation (seen in photos as well), which I was planning to attach to the end of the 2x6's above, which leaves plenty of ventilation behind them, should be \"ok\" in the winter and pretty decent in the summer.  However, not having soffit vents, I'm unsure if that is the proper use-case.You'll see from the wall install that I have no concerns about a vapor barrier, and do not care to seal my garage 100% (I only got faced insulation because it was cheaper =)  ).  However, I am concerned about mold/moisture problems in the space.  I would love some feedback as to the proper way to proceed here.  Ideally I can make use of my radiant barriers, and ideally I won't have to cut in soffit vents.Full resolution images here for reference: http://imgur.com/a/4Wd9Q and http://imgur.com/a/ud8os\n",
      "\n",
      "Cluster = 3, Raw data index = 8,153, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "What's the best way for a DIY granite counter top to be cut?  What tools do I need that will do the job without breaking the bank?\n",
      "\n",
      "Cluster = 3, Raw data index = 6,644, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I'm remodeling my bathroom and shower and I'll be replacing the insulation on the external wall. This wall is the \"back\" of the shower (opposite from where the water supply lines are). With this in mind, I should be able to just choose some insulation and then plop it in when I have the wall torn down.The main question and concern I have is about vapor barrier. I will be using cement board with a liquid topical membrane (like Redgard) for waterproofing the shower which means I'm not supposed to put a vapor barrier on the back side of the wall because it is bad to trap moisture. How does this affect insulating? Am I safe to nix the vapor barrier around the shower? What should I do for the rest of the bathroom?I'm not too concerned with price so if there are other options besides batting insulation (such as foam, etc...) that would solve my problem, I'm willing to hear those ideas as well.\n",
      "\n",
      "Cluster = 3, Raw data index = 65,112, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I am doing some minor renovations to my basement with the drop ceiling and found that one of the geniuses that owned the house before me, used fibreglass ceiling tiles to seal off an old vent for a gas fireplace. Obviously this will not do. I'm thinking of building a section of 2x4's around the old exhaust and then filling it with rigid foam and spray foam. I can't take the old exhaust off the side of the house, since it is a condo and I doubt that I'm going to convince them to replace the siding where this exhaust vent is, not to mention it will probably cost me. Open to any suggestions. I would post a pic but the settings don't allow it, kinda odd.\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 1, Raw data index = 60,884, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I'm trying to put my RV into the breaker box I've got a 30 amp breaker double pole I've got10/2 wire, do I use a single pole or double pole 30 amp breaker hand my RV plug is a 4 prong plug how do I make this work\n",
      "\n",
      "Cluster = 1, Raw data index = 62,339, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I just installed 6 new 4\" halo can lights. When they are on I can smell a slight odor coming from them in the attic. Is this normal? I felt the light housing in the attic and is just warm. I also felt each wire going from light to light and it is cool to the touch.\n",
      "\n",
      "Cluster = 1, Raw data index = 6,276, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I have an odd wiring situation at one of my switches, and like a rookie took it all apart before taking a picture.I have 9 wires running into the box, 3 white, 3 black and 3 ground.The switch is a standard two-way that controls a light in the basement. This appears to be the start of the line, with another switch (controlling a different light) and an outlet further down the line. What's odd, is that one of the lines (BW pair) are both hot. As such, I can't figure out how this switch needs to be connected. Any thoughts?\n",
      "\n",
      "Cluster = 1, Raw data index = 63,446, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I have an existing three way switch hooked up already, it works fine. I would like to add another three way switch by connecting another switch to the existing three way switch. Can this be done with 14/2 romex between the two switches?\n",
      "\n",
      "Cluster = 1, Raw data index = 7,857, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "Can I temporarily ground an outlet by attaching a wire to its central screw and then to a grounding rod situated outside my house?  I want to use an electrical pressure washer, but it requires a ground that none of my outlets have.\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 0, Raw data index = 33,566, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I'm a citizen of country X and have a valid United States ESTA in my X passport.  Recently, I became of citizen of Y and now have a Y passport as well, which I would like to use for future travel to the US.  Both countries qualify for the Visa Waiver Program.  Can I have ESTAs in both passports at the same time?The official CBP site seems contradictory, first implying that I should get a new ESTA:  If you obtain a new passport or change your name, gender or country of  citizenship, you will be required to apply for a new travel  authorization. This is also required if one of your answers to any of  the VWP eligibility questions changes. The associated fee of $14 will  be charged for each new application.And then saying that I should not have two simultaneous ESTAs:  If you have dual citizenship and have registered with ESTA, you should  use your VWP-eligible passport to board the plane when you leave your  country of departure and when you arrive in the U.S. If both your  countries of citizenship are VWP-eligible, then we strongly recommend  you choose which one you want to claim for purposes of travel to the  U.S., and use that country's passport each time you travel. One person  with two different ESTA authorizations creates confusion that will  only delay your travel.Cancelling the old ESTA would seem a valid way to fulfill both requirements, but there doesn't appear to be any way to do this?\n",
      "\n",
      "Cluster = 0, Raw data index = 48,613, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I am not sure this is the right place to ask this question but assuming any traveler might have come across this situation/have information,requesting to please guide.I had arrived USA 2 months before on B1/B2 visa.As I-94 forms are now paperless, i did not receive one at the time of arrival at USA airport. But i can see details of same on cbs.gov website. In paperless I-94, where do we need to return the form / do we need to return the form when I leave USA? I checked website but it had information regarding the case when paper I-94 is received.\n",
      "\n",
      "Cluster = 0, Raw data index = 55,030, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "My old passport have 2-year valid visa of DRCongo and it is expire on 04.06.2016. Now I am on holiday and going back at DRCongo on 01.05.2016. My old passport have remain 2 blank page so my boss told me to make new passport and I got a new passport.Will the immigration officer accept my visa if it is on my old passport?\n",
      "\n",
      "Cluster = 0, Raw data index = 49,361, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I am flying from London to Central America and back this summer on a bit of an extended holiday. I am considering stopping over in NYC on the way back for a few days. (My flight from Panama to London would be through NYC anyway and got offered a good deal by a travel agent.) I am residing in London as an EU citizen and I always use my EU passport to get around the world. However as I was born in the States I am also a fully fledged US citizen with the blue passport. The only time I've used my US passport in the past was for a US holiday a decade ago. I've never lived in the States so I don't sound American etc. I want to book my flights and travel around Central America using my EU passport for simplicity's sake. However I have come across on the US foreign office website a bit stating that US dual citizens can only enter and exit the State with a US passport. What should I do? I assume that I can't check into my flight on a European passport then enter and exit US border control with a US passport? Can I just ignore the fact that I've got a US passport and hope they don't clock on it? My EU passport will state my place of birth as the States but as I've said I don't sound American or anything. Is that risky? I don't want to be turned back at the gates on my first NYC trip!\n",
      "\n",
      "Cluster = 0, Raw data index = 55,078, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "My wife has a Schengen visa issued by the Italian consulate in the UK.It expires at the beginning of December, and as we want to travel to Europe for the Christmas holiday, we were hoping to cancel the current Schengen visa early in order to apply for another one in time.I have contacted the Italian consulate in London by email, and they have told me that they are unable to do this. After a quick search online, it seems other people have had more luck cancelling their visas. So my question is: has anyone cancelled a Schengen visa issued by Italy, and if so - how?\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 4, Raw data index = 15,061, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "It's always difficult to decide what clothes to take with you when you go to a new place. Usually I check Wikipedia to get an idea of approximate climate and weather conditions, but it often doesn't have much data besides average temperatures. Other factors, such as wind and precipitation, might enter into the equation, and the same temperature can \"feel like\" differently in two distinct locations.Perhaps not the same factors are important whether one travels to tropical/equatorial locations, or to temperate/subarctic places.So, in short:  If I travel to a new place, which weather factors should I look into to decide what to take with me?\n",
      "\n",
      "Cluster = 4, Raw data index = 65,232, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I see the TSA have brought in new rules for devices, in response to intelligence that terrorists may be trying to pack mobile phones with explosive, so checks before flights can include having to prove the device can power on.Although fearing the worst and allowing lots of extra time at airports, I have not yet encountered any checks of this sort over and above the usual taking devices out of bags so they can be scanned separately.From various news articles, there doesn't appear to be any consistent view as to what checks will be carried out.Can anyone here clarify what they do? Do you have to prove a phone can make a call, or just show it is powered on?\n",
      "\n",
      "Cluster = 4, Raw data index = 6,061, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I'm planning to visit Medellin and Bogota sometime in the near future. I've a U.S. DL which endorses motorcycles. Is it legal to ride motorcycles in Colombia with a US driver's license? Is it required to carry any other identification other than the U.S. DL in case if I'm on the road?\n",
      "\n",
      "Cluster = 4, Raw data index = 11,890, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "The way I currently cook kidney beans is to soak them overnight. But still they have to be cooked for a long time on gas before they get tender enough to be edible.Anything that can be added or be done in a different way to reduce the time over heat?\n",
      "\n",
      "Cluster = 4, Raw data index = 57,730, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "To quote Goodman &amp; Gilman :  An alternative way of defining the anesthetic state is to consider it  as a collection of “component” changes in behavior or perception. The  components of the anesthetic state include:  • amnesia  • immobility in  response to noxious stimulation  • attenuation of autonomic responses  to noxious stimulation  • analgesia  • unconsciousnessMy question is, does not the state of Unconsciousness already imply other components of analgesia and amnesia? Analgesia is the absence of the perception of pain, which is granted if there is unconsciousness which would be the absence of all perceptions. I am not certain if unconsciousness also entails amnesia, but it seems that remembering what happened when unconscious seems considerably unlikely.  Apart from a reductionist argument for minimizing the constraints required for classification as a general anesthetic, I am more interested in cases where unconsciousness would be achieved without analgesia or amnesia, which could be a likely rationale behind including the additional caveats in the definition.\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 5, Raw data index = 42,634, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I have designed an SQL aggregate function in Oracle that bitwise XORs all MD5 sums of the values stored in a column.For example, if my table is:+-----+----------+---------+| Key | Sequence |  Value  |+-----+----------+---------+|   1 |        1 | 'Hello' ||   1 |        2 | 'World' ||   2 |        1 | '1234'  ||   3 |        0 | (empty) ||   4 |        1 | 'Hello' ||   4 |        3 | 'World' |+-----+----------+---------+I can run the following query in Oracle:with t AS (select 1 key, 1 sequence, 'Hello' value FROM dual           union all select 1, 2, 'World' from dual           union all select 2, 1, '1234' from dual           union all select 3, 0, '' from dual /* ... */          )   select key, md5_agg(value) from t group by keyand get (unfortunately aggregate functions in Oracle ignore NULL values and '' is considered as NULL)+---+----------------------------------+|key| md5_agg(value)                   |+---+----------------------------------+| 1 | 7EBD0B1DA67F965F802D31DF25C4B321 || 2 | 81DC9BDB52D04DC20036DBD8313ED055 || 3 | 00000000000000000000000000000000 || 4 | 7EBD0B1DA67F965F802D31DF25C4B321 |+---+----------------------------------+I would like to use this approach to compare if the contents of some columns are equal when I compare subsets of the same table (think of finding duplicates in a complex structures that spans over multiple rows in the same table). Here with this results I know that I have the same subsets for keys 1 and 4.What are the limits of such an approach? Here are the ones I could list:This is interesting only if my column contains distinct values. If my columns contains twice the same string, the xor operation will be a no-op.Due to Oracle limitations, if my column contains empty values, they do not count.With those limitations in mind, is it still possible to infer, from two equal md5_agg results computed from distinct and non-empty values, that the original values make up the same sets?In order to reformulate, are there odds that the MD5 sums of distinct strings XOR to 0?\n",
      "\n",
      "Cluster = 5, Raw data index = 69,637, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "For the reasons I cannot go into details, I need to design my own protocol and overall security system which will be used to establish secure data exchange between various devices (most notably desktops of all three major OSes, Android and iOS devices and Raspberry Pi, with the possibility to extend it to other embedded systems). Since I wouldn't dare to do my own crypto algorithms implementation, this implies that I have to rely on tried and tested libraries available for those platforms (i.e. OpenSSL, BouncyCastle, CommonCrypto, …) so I settled with what they all support - RSA for signing/authentication, DHE/ECDHE for session establishment, AES for encryption, PBKDF2 for key derivation and SHA2 for general hashing needs. The key sizes and complexity will depend on the hardware ability of targeted platforms.Now, I've done a fair bit of implementations of existing protocols and I like to think that I know my way around cryptography and perils that await if not applied properly, however I wouldn't dare to consider myself a cryptography expert and thus I decided to query the hive mind. Of course, once everything completed it will be properly audited and tested, but for now I need to know if I'm on the right track, that I haven't done some glaring omissions and if it is possible to improve it even further.The system I'm building should both cover the storage on devices and the communication between them and to preserve forward and backward secrecy.For the storage part I plan to utilize AES in CBC mode, storing the randomly generated IVs with each individual encrypted file. The 'master' key itself will be randomly generated and also AES-encrypted using a key derived from the user's password using PBKDF2, stored along with the salt and iterations used in it. My main concern is the IV part as if generated randomly it might repeat thus compromising the encrypted files if they happen to be similar enough or even the same. It's quite a low chance buy I don't like leaving anything to chance so the question is - given that the IV is public knowledge anyway, is it safe to use incremental progression/timestamp as IV in this case?The communication part will be a bit trickier as the devices will never communicate directly - instead the data exchange between them will be relied through a third party database to which they periodically connect, which is one of the prime reasons I'm designing my own protocol. If we except this oddity, the data exchange itself should function quite the same as if they were communicating directly, namely the devices will establish a session each time they 'contact' each other and then use the session key for encryption.To establish a session I plan to use a variation of STS protocol adapted to this environment. The only oddity here is that in some instances only one of the parties involved in communication will posses the RSA key of the other so it won't be fully authenticated - my understanding is that even in this case no successful MITM attack can be performed as at least one of the parties will reject communication if the signature doesn't match. Is that a safe assumption?Once DH/ECDH keys are exchanged an actual session AES key will be derived from them using SHA2 and the rest of the data exchange will be encrypted using that key, again in CBC mode - until the session expires, when the process repeats. I'm still not clear on how to approach the message integrity and authenticity verification - at first I thought that signing the message with the device's RSA key will be enough, but since it may happen that only one of the parties has the other party's certificate I might add a HMAC alongside with the exchanged messages as well. What would be a recommended, cryptographically secure way to handle that?\n",
      "\n",
      "Cluster = 5, Raw data index = 86,569, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "Apple OS X can create encrypted AES 128/256 DMG volumes. Here is written about a men who was able to hack it. And also that DMGs use PBKDF2-HMAC-SHA-1. I couldn't find more information about encrypted DMGs. So does that mean that apples encrypted DMGs could be hacked?\n",
      "\n",
      "Cluster = 5, Raw data index = 9,433, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "Hashcash is a proof-of-work system in which the Sender needs to find $Y$ such as the first (let's say 20) bits of $H(X+Y)$ are zeros where $H$ is a one-way hash function, $X$ is a fixed value and $+$ means concatenation. The Sender starts with an initial random number $Y$. It then computes the hash of $X+Y$. If the first 20 bits of the hash are zeros, then $Y$ is an acceptable number. If not, then the sender increments the random number and tries again. Since about $1$ in $2^{20}$ headers will have $20$ zeros as the beginning of the hash, the sender will on average have to try $2^{20}$ random numbers to find a valid number.My question is: The average number of tries is $2^{20}$ but is there a number of tries after which Hashcash is guaranted to be solved?\n",
      "\n",
      "Cluster = 5, Raw data index = 28,252, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I've always been interested in encryption but I have never found a good explanation (beginners explanation) of how encryption with public key and decryption with private key works.How does it encrypt something with one key and decipher it with another key?\n",
      "\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 2, Raw data index = 60,884, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I'm trying to put my RV into the breaker box I've got a 30 amp breaker double pole I've got10/2 wire, do I use a single pole or double pole 30 amp breaker hand my RV plug is a 4 prong plug how do I make this work\n",
      "\n",
      "Cluster = 2, Raw data index = 62,339, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I just installed 6 new 4\" halo can lights. When they are on I can smell a slight odor coming from them in the attic. Is this normal? I felt the light housing in the attic and is just warm. I also felt each wire going from light to light and it is cool to the touch.\n",
      "\n",
      "Cluster = 2, Raw data index = 6,276, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I have an odd wiring situation at one of my switches, and like a rookie took it all apart before taking a picture.I have 9 wires running into the box, 3 white, 3 black and 3 ground.The switch is a standard two-way that controls a light in the basement. This appears to be the start of the line, with another switch (controlling a different light) and an outlet further down the line. What's odd, is that one of the lines (BW pair) are both hot. As such, I can't figure out how this switch needs to be connected. Any thoughts?\n",
      "\n",
      "Cluster = 2, Raw data index = 63,446, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I have an existing three way switch hooked up already, it works fine. I would like to add another three way switch by connecting another switch to the existing three way switch. Can this be done with 14/2 romex between the two switches?\n",
      "\n",
      "Cluster = 2, Raw data index = 7,857, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "Can I temporarily ground an outlet by attaching a wire to its central screw and then to a grounding rod situated outside my house?  I want to use an electrical pressure washer, but it requires a ground that none of my outlets have.\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 3, Raw data index = 42,634, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I have designed an SQL aggregate function in Oracle that bitwise XORs all MD5 sums of the values stored in a column.For example, if my table is:+-----+----------+---------+| Key | Sequence |  Value  |+-----+----------+---------+|   1 |        1 | 'Hello' ||   1 |        2 | 'World' ||   2 |        1 | '1234'  ||   3 |        0 | (empty) ||   4 |        1 | 'Hello' ||   4 |        3 | 'World' |+-----+----------+---------+I can run the following query in Oracle:with t AS (select 1 key, 1 sequence, 'Hello' value FROM dual           union all select 1, 2, 'World' from dual           union all select 2, 1, '1234' from dual           union all select 3, 0, '' from dual /* ... */          )   select key, md5_agg(value) from t group by keyand get (unfortunately aggregate functions in Oracle ignore NULL values and '' is considered as NULL)+---+----------------------------------+|key| md5_agg(value)                   |+---+----------------------------------+| 1 | 7EBD0B1DA67F965F802D31DF25C4B321 || 2 | 81DC9BDB52D04DC20036DBD8313ED055 || 3 | 00000000000000000000000000000000 || 4 | 7EBD0B1DA67F965F802D31DF25C4B321 |+---+----------------------------------+I would like to use this approach to compare if the contents of some columns are equal when I compare subsets of the same table (think of finding duplicates in a complex structures that spans over multiple rows in the same table). Here with this results I know that I have the same subsets for keys 1 and 4.What are the limits of such an approach? Here are the ones I could list:This is interesting only if my column contains distinct values. If my columns contains twice the same string, the xor operation will be a no-op.Due to Oracle limitations, if my column contains empty values, they do not count.With those limitations in mind, is it still possible to infer, from two equal md5_agg results computed from distinct and non-empty values, that the original values make up the same sets?In order to reformulate, are there odds that the MD5 sums of distinct strings XOR to 0?\n",
      "\n",
      "Cluster = 3, Raw data index = 69,637, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "For the reasons I cannot go into details, I need to design my own protocol and overall security system which will be used to establish secure data exchange between various devices (most notably desktops of all three major OSes, Android and iOS devices and Raspberry Pi, with the possibility to extend it to other embedded systems). Since I wouldn't dare to do my own crypto algorithms implementation, this implies that I have to rely on tried and tested libraries available for those platforms (i.e. OpenSSL, BouncyCastle, CommonCrypto, …) so I settled with what they all support - RSA for signing/authentication, DHE/ECDHE for session establishment, AES for encryption, PBKDF2 for key derivation and SHA2 for general hashing needs. The key sizes and complexity will depend on the hardware ability of targeted platforms.Now, I've done a fair bit of implementations of existing protocols and I like to think that I know my way around cryptography and perils that await if not applied properly, however I wouldn't dare to consider myself a cryptography expert and thus I decided to query the hive mind. Of course, once everything completed it will be properly audited and tested, but for now I need to know if I'm on the right track, that I haven't done some glaring omissions and if it is possible to improve it even further.The system I'm building should both cover the storage on devices and the communication between them and to preserve forward and backward secrecy.For the storage part I plan to utilize AES in CBC mode, storing the randomly generated IVs with each individual encrypted file. The 'master' key itself will be randomly generated and also AES-encrypted using a key derived from the user's password using PBKDF2, stored along with the salt and iterations used in it. My main concern is the IV part as if generated randomly it might repeat thus compromising the encrypted files if they happen to be similar enough or even the same. It's quite a low chance buy I don't like leaving anything to chance so the question is - given that the IV is public knowledge anyway, is it safe to use incremental progression/timestamp as IV in this case?The communication part will be a bit trickier as the devices will never communicate directly - instead the data exchange between them will be relied through a third party database to which they periodically connect, which is one of the prime reasons I'm designing my own protocol. If we except this oddity, the data exchange itself should function quite the same as if they were communicating directly, namely the devices will establish a session each time they 'contact' each other and then use the session key for encryption.To establish a session I plan to use a variation of STS protocol adapted to this environment. The only oddity here is that in some instances only one of the parties involved in communication will posses the RSA key of the other so it won't be fully authenticated - my understanding is that even in this case no successful MITM attack can be performed as at least one of the parties will reject communication if the signature doesn't match. Is that a safe assumption?Once DH/ECDH keys are exchanged an actual session AES key will be derived from them using SHA2 and the rest of the data exchange will be encrypted using that key, again in CBC mode - until the session expires, when the process repeats. I'm still not clear on how to approach the message integrity and authenticity verification - at first I thought that signing the message with the device's RSA key will be enough, but since it may happen that only one of the parties has the other party's certificate I might add a HMAC alongside with the exchanged messages as well. What would be a recommended, cryptographically secure way to handle that?\n",
      "\n",
      "Cluster = 3, Raw data index = 86,569, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "Apple OS X can create encrypted AES 128/256 DMG volumes. Here is written about a men who was able to hack it. And also that DMGs use PBKDF2-HMAC-SHA-1. I couldn't find more information about encrypted DMGs. So does that mean that apples encrypted DMGs could be hacked?\n",
      "\n",
      "Cluster = 3, Raw data index = 9,433, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "Hashcash is a proof-of-work system in which the Sender needs to find $Y$ such as the first (let's say 20) bits of $H(X+Y)$ are zeros where $H$ is a one-way hash function, $X$ is a fixed value and $+$ means concatenation. The Sender starts with an initial random number $Y$. It then computes the hash of $X+Y$. If the first 20 bits of the hash are zeros, then $Y$ is an acceptable number. If not, then the sender increments the random number and tries again. Since about $1$ in $2^{20}$ headers will have $20$ zeros as the beginning of the hash, the sender will on average have to try $2^{20}$ random numbers to find a valid number.My question is: The average number of tries is $2^{20}$ but is there a number of tries after which Hashcash is guaranted to be solved?\n",
      "\n",
      "Cluster = 3, Raw data index = 28,252, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I've always been interested in encryption but I have never found a good explanation (beginners explanation) of how encryption with public key and decryption with private key works.How does it encrypt something with one key and decipher it with another key?\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 1, Raw data index = 33,566, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I'm a citizen of country X and have a valid United States ESTA in my X passport.  Recently, I became of citizen of Y and now have a Y passport as well, which I would like to use for future travel to the US.  Both countries qualify for the Visa Waiver Program.  Can I have ESTAs in both passports at the same time?The official CBP site seems contradictory, first implying that I should get a new ESTA:  If you obtain a new passport or change your name, gender or country of  citizenship, you will be required to apply for a new travel  authorization. This is also required if one of your answers to any of  the VWP eligibility questions changes. The associated fee of $14 will  be charged for each new application.And then saying that I should not have two simultaneous ESTAs:  If you have dual citizenship and have registered with ESTA, you should  use your VWP-eligible passport to board the plane when you leave your  country of departure and when you arrive in the U.S. If both your  countries of citizenship are VWP-eligible, then we strongly recommend  you choose which one you want to claim for purposes of travel to the  U.S., and use that country's passport each time you travel. One person  with two different ESTA authorizations creates confusion that will  only delay your travel.Cancelling the old ESTA would seem a valid way to fulfill both requirements, but there doesn't appear to be any way to do this?\n",
      "\n",
      "Cluster = 1, Raw data index = 48,613, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I am not sure this is the right place to ask this question but assuming any traveler might have come across this situation/have information,requesting to please guide.I had arrived USA 2 months before on B1/B2 visa.As I-94 forms are now paperless, i did not receive one at the time of arrival at USA airport. But i can see details of same on cbs.gov website. In paperless I-94, where do we need to return the form / do we need to return the form when I leave USA? I checked website but it had information regarding the case when paper I-94 is received.\n",
      "\n",
      "Cluster = 1, Raw data index = 55,030, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "My old passport have 2-year valid visa of DRCongo and it is expire on 04.06.2016. Now I am on holiday and going back at DRCongo on 01.05.2016. My old passport have remain 2 blank page so my boss told me to make new passport and I got a new passport.Will the immigration officer accept my visa if it is on my old passport?\n",
      "\n",
      "Cluster = 1, Raw data index = 49,361, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I am flying from London to Central America and back this summer on a bit of an extended holiday. I am considering stopping over in NYC on the way back for a few days. (My flight from Panama to London would be through NYC anyway and got offered a good deal by a travel agent.) I am residing in London as an EU citizen and I always use my EU passport to get around the world. However as I was born in the States I am also a fully fledged US citizen with the blue passport. The only time I've used my US passport in the past was for a US holiday a decade ago. I've never lived in the States so I don't sound American etc. I want to book my flights and travel around Central America using my EU passport for simplicity's sake. However I have come across on the US foreign office website a bit stating that US dual citizens can only enter and exit the State with a US passport. What should I do? I assume that I can't check into my flight on a European passport then enter and exit US border control with a US passport? Can I just ignore the fact that I've got a US passport and hope they don't clock on it? My EU passport will state my place of birth as the States but as I've said I don't sound American or anything. Is that risky? I don't want to be turned back at the gates on my first NYC trip!\n",
      "\n",
      "Cluster = 1, Raw data index = 55,078, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "My wife has a Schengen visa issued by the Italian consulate in the UK.It expires at the beginning of December, and as we want to travel to Europe for the Christmas holiday, we were hoping to cancel the current Schengen visa early in order to apply for another one in time.I have contacted the Italian consulate in London by email, and they have told me that they are unable to do this. After a quick search online, it seems other people have had more luck cancelling their visas. So my question is: has anyone cancelled a Schengen visa issued by Italy, and if so - how?\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 0, Raw data index = 81,864, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I live in the Midwest of the United States, and we not-too-rarely get a large amount of rain coming down at one time both in the spring and sometimes in the fall. Last night was no different (aside from random earthquakes..) than usual, but after I went to bed, my smoke alarm went off. I quickly determined that there was in fact no fire, so I went to take the smoke alarm off of its mounting and when I removed it, I found that there was a decent amount of water in the smoke detector. If I had to guess I'd say about 50 mL. So not a huge amount, but enough to set it off.I left it off for a time, and did not notice any more water coming from the opening in the ceiling (which is a recess where the detector and power wiring sits, not fully open to the attic (just where the wires come in, as far as I know. I didn't examine it terribly closely), even though it was still raining fairly hard (though not nearly as hard as it had been). This morning, I went to have a look around the attic to see if I could see anywhere it was leaking (it is still misting outside, but not raining any longer), but I was unable to detect any wet spots in the roof.What should my next step be? The roof (and indeed the house) is 1 year old, so I would hope that it hasn't sprung a leak, but I can't think of how else water would have gotten into the smoke detector. I also suspect paying someone to go and try to find a leak is going to be fairly expensive as well.The detector itself appears to be working. If I test it, and it functions, should I still replace it because of potential water damage?UpdateHere is a picture of the socket in question, and there is indeed cool air coming from it. I'm not totally convinced it is just condensation, elsewise this would have happened last year during the winter, I would think, but am unsure.\n",
      "\n",
      "Cluster = 0, Raw data index = 22,211, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "We discovered a bath tub leak from our second floor bathroom which dripped through the sidings. The bathroom has the original fixtures from 1989. It leaks when there's excess amount of water used.Would this be a simple problem of refinishing everything using plumber's putty?\n",
      "\n",
      "Cluster = 0, Raw data index = 74,198, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "The air quality in my basement is unpleasant. I don't know if I have mold. How to test for it? How is the smell of mold?I know that we had a water problem in the basement, the walls were cracked so every rainy day, we had humidity and water in the basement. But I have never seen signs of mold. How to check for mold?\n",
      "\n",
      "Cluster = 0, Raw data index = 44,660, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "Many instances of this worm-like creature were found in a water system for a mountain cabin in the Sierra Nevada mountains of the US, in late June / early July.  The water system collects water from an enclosed spring.  Can you help identify this creature?  Clues:The worms have two \"points\" on their heads. They can stretch out and be long and thin, or when poked (or are resting) they contract into a small blob.  Here is a picture of a single worm with markings shown.Here is a picture of a few worms, somewhat contracted. Here is a movie of them moving, in natural light.  Here is a movie of them moving, with backlight.Here are pictures of their undersides and their internal structures.Whenever I pull some out of the water and put them into a tupperware with the same water, they only survive for around 24 hours, after which they seem to disintegrate.  Here is a picture of about 20 of the worms after about 24 hours, the bulk of them have halfway-decomposed and form a heap in the upper right.  After another day it'll just look like debris in the water, you wouldn't even recognize that there were worms in it.  There is a piece of bacon in there because some suggested putting it there to test if they were leeches, but this disintegration happens repeatably and regardless of the bacon; please ignore the bacon.Someone suggested that they are trematodes, but there are no snails, frogs, or other creatures in the storage and collection sections of the water system;  we have looked very closely.  There may be something within a 30-foot section of pipe, but we doubt it.  Can you help us identify this creature?  Even just possible families of creatures or general categories would be helpful for us.\n",
      "\n",
      "Cluster = 0, Raw data index = 83,398, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I have a reliance model 5 30 NORS971 gas HOT WATER tank. The basement flooded a little and put out the pilot. When it would not light, I replaced the pilot tip and went ahead and replaced the thermocouple. All went well and it lit and fired the burner. One week later, the pilot would light but go out when button released. Replaced the gas control with one from another tank and it worked for about a week. The pressure relief was then leaking a little so replaced it. One more week and not working so bought new gas control and replaced and all lit.Now 2 weeks later, not working and pilot will light but, goes out on release. used multimeter and get 20 mv on thermocouple. What would be cause of gas controls burning out?\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 4, Raw data index = 63,096, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I bought a new house about a month ago, and have since noticed some plumbing issues in the laundry room:laundry tub drains slowlyoccasional \"musty\" smell, which seems to come from the drainsI did some research online and found that lack of drain ventilation could cause both of these problems. So I checked the plumbing and it looks like both the washing machine and adjacent wash basin drain into the same pipe. As far as I can tell, there is no ventilation on these drains (photo below); it looks like a stacked pair of S-traps.The laundry room is in a little addition at the back of the house. So I probably cannot tie this back in to the main house venting stack without a lot of work. I gather the simplest solution is to locally install an air admittance valve (AAV). Does that sound like a reasonable approach here?If so, am I on the right track with one of these:http://www.rona.ca/en/air-admittance-valvehttp://www.amazon.ca/gp/product/B000H5SLWM?psc=1&amp;redirect=true&amp;ref_=ox_sc_act_title_1&amp;smid=A23X8TYK8IHNZFMy plan is to remove the upper S-trap. Then install a sanitary T, going to: AAV (top) and P-trap (horizontal). Does that sound right?\n",
      "\n",
      "Cluster = 4, Raw data index = 31,500, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I have read a lot about proper insulation and ventilation, including some posts on this site, but none adequately answer my questions.My goal is to operate an electric heat source in the winter and have ~60 &deg;F temperature maintained when working in the garage.  In the summer, I think we will typically leave the garage door open, however it would be nice to one day have it stay cool in there if it's 90-100 &deg;F outside.This is in Ohio, where we typically have temps of 0-95 &deg;F throughout the year, it can also get pretty humid.I do not have soffit vents, but there is a ridge vent on the roof already installed.  I do not want to drywall nor do I want to build a ceiling.As you see in the photos I have already insulated the walls with R15 Batt installation.  Now I'm unsure where to go from here for roof 2x6's.  I bought some radiant barrier R11-equivelent insulation (seen in photos as well), which I was planning to attach to the end of the 2x6's above, which leaves plenty of ventilation behind them, should be \"ok\" in the winter and pretty decent in the summer.  However, not having soffit vents, I'm unsure if that is the proper use-case.You'll see from the wall install that I have no concerns about a vapor barrier, and do not care to seal my garage 100% (I only got faced insulation because it was cheaper =)  ).  However, I am concerned about mold/moisture problems in the space.  I would love some feedback as to the proper way to proceed here.  Ideally I can make use of my radiant barriers, and ideally I won't have to cut in soffit vents.Full resolution images here for reference: http://imgur.com/a/4Wd9Q and http://imgur.com/a/ud8os\n",
      "\n",
      "Cluster = 4, Raw data index = 8,153, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "What's the best way for a DIY granite counter top to be cut?  What tools do I need that will do the job without breaking the bank?\n",
      "\n",
      "Cluster = 4, Raw data index = 6,644, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I'm remodeling my bathroom and shower and I'll be replacing the insulation on the external wall. This wall is the \"back\" of the shower (opposite from where the water supply lines are). With this in mind, I should be able to just choose some insulation and then plop it in when I have the wall torn down.The main question and concern I have is about vapor barrier. I will be using cement board with a liquid topical membrane (like Redgard) for waterproofing the shower which means I'm not supposed to put a vapor barrier on the back side of the wall because it is bad to trap moisture. How does this affect insulating? Am I safe to nix the vapor barrier around the shower? What should I do for the rest of the bathroom?I'm not too concerned with price so if there are other options besides batting insulation (such as foam, etc...) that would solve my problem, I'm willing to hear those ideas as well.\n",
      "\n",
      "Cluster = 4, Raw data index = 65,112, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I am doing some minor renovations to my basement with the drop ceiling and found that one of the geniuses that owned the house before me, used fibreglass ceiling tiles to seal off an old vent for a gas fireplace. Obviously this will not do. I'm thinking of building a section of 2x4's around the old exhaust and then filling it with rigid foam and spray foam. I can't take the old exhaust off the side of the house, since it is a condo and I doubt that I'm going to convince them to replace the siding where this exhaust vent is, not to mention it will probably cost me. Open to any suggestions. I would post a pic but the settings don't allow it, kinda odd.\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 5, Raw data index = 15,061, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "It's always difficult to decide what clothes to take with you when you go to a new place. Usually I check Wikipedia to get an idea of approximate climate and weather conditions, but it often doesn't have much data besides average temperatures. Other factors, such as wind and precipitation, might enter into the equation, and the same temperature can \"feel like\" differently in two distinct locations.Perhaps not the same factors are important whether one travels to tropical/equatorial locations, or to temperate/subarctic places.So, in short:  If I travel to a new place, which weather factors should I look into to decide what to take with me?\n",
      "\n",
      "Cluster = 5, Raw data index = 65,232, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I see the TSA have brought in new rules for devices, in response to intelligence that terrorists may be trying to pack mobile phones with explosive, so checks before flights can include having to prove the device can power on.Although fearing the worst and allowing lots of extra time at airports, I have not yet encountered any checks of this sort over and above the usual taking devices out of bags so they can be scanned separately.From various news articles, there doesn't appear to be any consistent view as to what checks will be carried out.Can anyone here clarify what they do? Do you have to prove a phone can make a call, or just show it is powered on?\n",
      "\n",
      "Cluster = 5, Raw data index = 6,061, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I'm planning to visit Medellin and Bogota sometime in the near future. I've a U.S. DL which endorses motorcycles. Is it legal to ride motorcycles in Colombia with a US driver's license? Is it required to carry any other identification other than the U.S. DL in case if I'm on the road?\n",
      "\n",
      "Cluster = 5, Raw data index = 11,890, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "The way I currently cook kidney beans is to soak them overnight. But still they have to be cooked for a long time on gas before they get tender enough to be edible.Anything that can be added or be done in a different way to reduce the time over heat?\n",
      "\n",
      "Cluster = 5, Raw data index = 57,730, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "To quote Goodman &amp; Gilman :  An alternative way of defining the anesthetic state is to consider it  as a collection of “component” changes in behavior or perception. The  components of the anesthetic state include:  • amnesia  • immobility in  response to noxious stimulation  • attenuation of autonomic responses  to noxious stimulation  • analgesia  • unconsciousnessMy question is, does not the state of Unconsciousness already imply other components of analgesia and amnesia? Analgesia is the absence of the perception of pain, which is granted if there is unconsciousness which would be the absence of all perceptions. I am not certain if unconsciousness also entails amnesia, but it seems that remembering what happened when unconscious seems considerably unlikely.  Apart from a reductionist argument for minimizing the constraints required for classification as a general anesthetic, I am more interested in cases where unconsciousness would be achieved without analgesia or amnesia, which could be a likely rationale behind including the additional caveats in the definition.\n",
      "\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 2, Raw data index = 81,864, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I live in the Midwest of the United States, and we not-too-rarely get a large amount of rain coming down at one time both in the spring and sometimes in the fall. Last night was no different (aside from random earthquakes..) than usual, but after I went to bed, my smoke alarm went off. I quickly determined that there was in fact no fire, so I went to take the smoke alarm off of its mounting and when I removed it, I found that there was a decent amount of water in the smoke detector. If I had to guess I'd say about 50 mL. So not a huge amount, but enough to set it off.I left it off for a time, and did not notice any more water coming from the opening in the ceiling (which is a recess where the detector and power wiring sits, not fully open to the attic (just where the wires come in, as far as I know. I didn't examine it terribly closely), even though it was still raining fairly hard (though not nearly as hard as it had been). This morning, I went to have a look around the attic to see if I could see anywhere it was leaking (it is still misting outside, but not raining any longer), but I was unable to detect any wet spots in the roof.What should my next step be? The roof (and indeed the house) is 1 year old, so I would hope that it hasn't sprung a leak, but I can't think of how else water would have gotten into the smoke detector. I also suspect paying someone to go and try to find a leak is going to be fairly expensive as well.The detector itself appears to be working. If I test it, and it functions, should I still replace it because of potential water damage?UpdateHere is a picture of the socket in question, and there is indeed cool air coming from it. I'm not totally convinced it is just condensation, elsewise this would have happened last year during the winter, I would think, but am unsure.\n",
      "\n",
      "Cluster = 2, Raw data index = 22,211, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "We discovered a bath tub leak from our second floor bathroom which dripped through the sidings. The bathroom has the original fixtures from 1989. It leaks when there's excess amount of water used.Would this be a simple problem of refinishing everything using plumber's putty?\n",
      "\n",
      "Cluster = 2, Raw data index = 74,198, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "The air quality in my basement is unpleasant. I don't know if I have mold. How to test for it? How is the smell of mold?I know that we had a water problem in the basement, the walls were cracked so every rainy day, we had humidity and water in the basement. But I have never seen signs of mold. How to check for mold?\n",
      "\n",
      "Cluster = 2, Raw data index = 44,660, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "Many instances of this worm-like creature were found in a water system for a mountain cabin in the Sierra Nevada mountains of the US, in late June / early July.  The water system collects water from an enclosed spring.  Can you help identify this creature?  Clues:The worms have two \"points\" on their heads. They can stretch out and be long and thin, or when poked (or are resting) they contract into a small blob.  Here is a picture of a single worm with markings shown.Here is a picture of a few worms, somewhat contracted. Here is a movie of them moving, in natural light.  Here is a movie of them moving, with backlight.Here are pictures of their undersides and their internal structures.Whenever I pull some out of the water and put them into a tupperware with the same water, they only survive for around 24 hours, after which they seem to disintegrate.  Here is a picture of about 20 of the worms after about 24 hours, the bulk of them have halfway-decomposed and form a heap in the upper right.  After another day it'll just look like debris in the water, you wouldn't even recognize that there were worms in it.  There is a piece of bacon in there because some suggested putting it there to test if they were leeches, but this disintegration happens repeatably and regardless of the bacon; please ignore the bacon.Someone suggested that they are trematodes, but there are no snails, frogs, or other creatures in the storage and collection sections of the water system;  we have looked very closely.  There may be something within a 30-foot section of pipe, but we doubt it.  Can you help us identify this creature?  Even just possible families of creatures or general categories would be helpful for us.\n",
      "\n",
      "Cluster = 2, Raw data index = 45,540, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "People may tend to spend time in a hot water spring. Is it possible to get hyperthermia (like a sun stroke) due to this?\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 3, Raw data index = 63,096, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I bought a new house about a month ago, and have since noticed some plumbing issues in the laundry room:laundry tub drains slowlyoccasional \"musty\" smell, which seems to come from the drainsI did some research online and found that lack of drain ventilation could cause both of these problems. So I checked the plumbing and it looks like both the washing machine and adjacent wash basin drain into the same pipe. As far as I can tell, there is no ventilation on these drains (photo below); it looks like a stacked pair of S-traps.The laundry room is in a little addition at the back of the house. So I probably cannot tie this back in to the main house venting stack without a lot of work. I gather the simplest solution is to locally install an air admittance valve (AAV). Does that sound like a reasonable approach here?If so, am I on the right track with one of these:http://www.rona.ca/en/air-admittance-valvehttp://www.amazon.ca/gp/product/B000H5SLWM?psc=1&amp;redirect=true&amp;ref_=ox_sc_act_title_1&amp;smid=A23X8TYK8IHNZFMy plan is to remove the upper S-trap. Then install a sanitary T, going to: AAV (top) and P-trap (horizontal). Does that sound right?\n",
      "\n",
      "Cluster = 3, Raw data index = 31,500, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I have read a lot about proper insulation and ventilation, including some posts on this site, but none adequately answer my questions.My goal is to operate an electric heat source in the winter and have ~60 &deg;F temperature maintained when working in the garage.  In the summer, I think we will typically leave the garage door open, however it would be nice to one day have it stay cool in there if it's 90-100 &deg;F outside.This is in Ohio, where we typically have temps of 0-95 &deg;F throughout the year, it can also get pretty humid.I do not have soffit vents, but there is a ridge vent on the roof already installed.  I do not want to drywall nor do I want to build a ceiling.As you see in the photos I have already insulated the walls with R15 Batt installation.  Now I'm unsure where to go from here for roof 2x6's.  I bought some radiant barrier R11-equivelent insulation (seen in photos as well), which I was planning to attach to the end of the 2x6's above, which leaves plenty of ventilation behind them, should be \"ok\" in the winter and pretty decent in the summer.  However, not having soffit vents, I'm unsure if that is the proper use-case.You'll see from the wall install that I have no concerns about a vapor barrier, and do not care to seal my garage 100% (I only got faced insulation because it was cheaper =)  ).  However, I am concerned about mold/moisture problems in the space.  I would love some feedback as to the proper way to proceed here.  Ideally I can make use of my radiant barriers, and ideally I won't have to cut in soffit vents.Full resolution images here for reference: http://imgur.com/a/4Wd9Q and http://imgur.com/a/ud8os\n",
      "\n",
      "Cluster = 3, Raw data index = 8,153, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "What's the best way for a DIY granite counter top to be cut?  What tools do I need that will do the job without breaking the bank?\n",
      "\n",
      "Cluster = 3, Raw data index = 6,644, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I'm remodeling my bathroom and shower and I'll be replacing the insulation on the external wall. This wall is the \"back\" of the shower (opposite from where the water supply lines are). With this in mind, I should be able to just choose some insulation and then plop it in when I have the wall torn down.The main question and concern I have is about vapor barrier. I will be using cement board with a liquid topical membrane (like Redgard) for waterproofing the shower which means I'm not supposed to put a vapor barrier on the back side of the wall because it is bad to trap moisture. How does this affect insulating? Am I safe to nix the vapor barrier around the shower? What should I do for the rest of the bathroom?I'm not too concerned with price so if there are other options besides batting insulation (such as foam, etc...) that would solve my problem, I'm willing to hear those ideas as well.\n",
      "\n",
      "Cluster = 3, Raw data index = 65,112, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I am doing some minor renovations to my basement with the drop ceiling and found that one of the geniuses that owned the house before me, used fibreglass ceiling tiles to seal off an old vent for a gas fireplace. Obviously this will not do. I'm thinking of building a section of 2x4's around the old exhaust and then filling it with rigid foam and spray foam. I can't take the old exhaust off the side of the house, since it is a condo and I doubt that I'm going to convince them to replace the siding where this exhaust vent is, not to mention it will probably cost me. Open to any suggestions. I would post a pic but the settings don't allow it, kinda odd.\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 1, Raw data index = 60,884, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I'm trying to put my RV into the breaker box I've got a 30 amp breaker double pole I've got10/2 wire, do I use a single pole or double pole 30 amp breaker hand my RV plug is a 4 prong plug how do I make this work\n",
      "\n",
      "Cluster = 1, Raw data index = 62,339, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I just installed 6 new 4\" halo can lights. When they are on I can smell a slight odor coming from them in the attic. Is this normal? I felt the light housing in the attic and is just warm. I also felt each wire going from light to light and it is cool to the touch.\n",
      "\n",
      "Cluster = 1, Raw data index = 6,276, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I have an odd wiring situation at one of my switches, and like a rookie took it all apart before taking a picture.I have 9 wires running into the box, 3 white, 3 black and 3 ground.The switch is a standard two-way that controls a light in the basement. This appears to be the start of the line, with another switch (controlling a different light) and an outlet further down the line. What's odd, is that one of the lines (BW pair) are both hot. As such, I can't figure out how this switch needs to be connected. Any thoughts?\n",
      "\n",
      "Cluster = 1, Raw data index = 63,446, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I have an existing three way switch hooked up already, it works fine. I would like to add another three way switch by connecting another switch to the existing three way switch. Can this be done with 14/2 romex between the two switches?\n",
      "\n",
      "Cluster = 1, Raw data index = 7,857, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "Can I temporarily ground an outlet by attaching a wire to its central screw and then to a grounding rod situated outside my house?  I want to use an electrical pressure washer, but it requires a ground that none of my outlets have.\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 0, Raw data index = 33,566, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I'm a citizen of country X and have a valid United States ESTA in my X passport.  Recently, I became of citizen of Y and now have a Y passport as well, which I would like to use for future travel to the US.  Both countries qualify for the Visa Waiver Program.  Can I have ESTAs in both passports at the same time?The official CBP site seems contradictory, first implying that I should get a new ESTA:  If you obtain a new passport or change your name, gender or country of  citizenship, you will be required to apply for a new travel  authorization. This is also required if one of your answers to any of  the VWP eligibility questions changes. The associated fee of $14 will  be charged for each new application.And then saying that I should not have two simultaneous ESTAs:  If you have dual citizenship and have registered with ESTA, you should  use your VWP-eligible passport to board the plane when you leave your  country of departure and when you arrive in the U.S. If both your  countries of citizenship are VWP-eligible, then we strongly recommend  you choose which one you want to claim for purposes of travel to the  U.S., and use that country's passport each time you travel. One person  with two different ESTA authorizations creates confusion that will  only delay your travel.Cancelling the old ESTA would seem a valid way to fulfill both requirements, but there doesn't appear to be any way to do this?\n",
      "\n",
      "Cluster = 0, Raw data index = 48,613, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I am not sure this is the right place to ask this question but assuming any traveler might have come across this situation/have information,requesting to please guide.I had arrived USA 2 months before on B1/B2 visa.As I-94 forms are now paperless, i did not receive one at the time of arrival at USA airport. But i can see details of same on cbs.gov website. In paperless I-94, where do we need to return the form / do we need to return the form when I leave USA? I checked website but it had information regarding the case when paper I-94 is received.\n",
      "\n",
      "Cluster = 0, Raw data index = 55,030, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "My old passport have 2-year valid visa of DRCongo and it is expire on 04.06.2016. Now I am on holiday and going back at DRCongo on 01.05.2016. My old passport have remain 2 blank page so my boss told me to make new passport and I got a new passport.Will the immigration officer accept my visa if it is on my old passport?\n",
      "\n",
      "Cluster = 0, Raw data index = 49,361, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I am flying from London to Central America and back this summer on a bit of an extended holiday. I am considering stopping over in NYC on the way back for a few days. (My flight from Panama to London would be through NYC anyway and got offered a good deal by a travel agent.) I am residing in London as an EU citizen and I always use my EU passport to get around the world. However as I was born in the States I am also a fully fledged US citizen with the blue passport. The only time I've used my US passport in the past was for a US holiday a decade ago. I've never lived in the States so I don't sound American etc. I want to book my flights and travel around Central America using my EU passport for simplicity's sake. However I have come across on the US foreign office website a bit stating that US dual citizens can only enter and exit the State with a US passport. What should I do? I assume that I can't check into my flight on a European passport then enter and exit US border control with a US passport? Can I just ignore the fact that I've got a US passport and hope they don't clock on it? My EU passport will state my place of birth as the States but as I've said I don't sound American or anything. Is that risky? I don't want to be turned back at the gates on my first NYC trip!\n",
      "\n",
      "Cluster = 0, Raw data index = 55,078, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "My wife has a Schengen visa issued by the Italian consulate in the UK.It expires at the beginning of December, and as we want to travel to Europe for the Christmas holiday, we were hoping to cancel the current Schengen visa early in order to apply for another one in time.I have contacted the Italian consulate in London by email, and they have told me that they are unable to do this. After a quick search online, it seems other people have had more luck cancelling their visas. So my question is: has anyone cancelled a Schengen visa issued by Italy, and if so - how?\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 4, Raw data index = 15,061, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "It's always difficult to decide what clothes to take with you when you go to a new place. Usually I check Wikipedia to get an idea of approximate climate and weather conditions, but it often doesn't have much data besides average temperatures. Other factors, such as wind and precipitation, might enter into the equation, and the same temperature can \"feel like\" differently in two distinct locations.Perhaps not the same factors are important whether one travels to tropical/equatorial locations, or to temperate/subarctic places.So, in short:  If I travel to a new place, which weather factors should I look into to decide what to take with me?\n",
      "\n",
      "Cluster = 4, Raw data index = 65,232, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I see the TSA have brought in new rules for devices, in response to intelligence that terrorists may be trying to pack mobile phones with explosive, so checks before flights can include having to prove the device can power on.Although fearing the worst and allowing lots of extra time at airports, I have not yet encountered any checks of this sort over and above the usual taking devices out of bags so they can be scanned separately.From various news articles, there doesn't appear to be any consistent view as to what checks will be carried out.Can anyone here clarify what they do? Do you have to prove a phone can make a call, or just show it is powered on?\n",
      "\n",
      "Cluster = 4, Raw data index = 6,061, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I'm planning to visit Medellin and Bogota sometime in the near future. I've a U.S. DL which endorses motorcycles. Is it legal to ride motorcycles in Colombia with a US driver's license? Is it required to carry any other identification other than the U.S. DL in case if I'm on the road?\n",
      "\n",
      "Cluster = 4, Raw data index = 11,890, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "The way I currently cook kidney beans is to soak them overnight. But still they have to be cooked for a long time on gas before they get tender enough to be edible.Anything that can be added or be done in a different way to reduce the time over heat?\n",
      "\n",
      "Cluster = 4, Raw data index = 57,730, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "To quote Goodman &amp; Gilman :  An alternative way of defining the anesthetic state is to consider it  as a collection of “component” changes in behavior or perception. The  components of the anesthetic state include:  • amnesia  • immobility in  response to noxious stimulation  • attenuation of autonomic responses  to noxious stimulation  • analgesia  • unconsciousnessMy question is, does not the state of Unconsciousness already imply other components of analgesia and amnesia? Analgesia is the absence of the perception of pain, which is granted if there is unconsciousness which would be the absence of all perceptions. I am not certain if unconsciousness also entails amnesia, but it seems that remembering what happened when unconscious seems considerably unlikely.  Apart from a reductionist argument for minimizing the constraints required for classification as a general anesthetic, I am more interested in cases where unconsciousness would be achieved without analgesia or amnesia, which could be a likely rationale behind including the additional caveats in the definition.\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 5, Raw data index = 42,634, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I have designed an SQL aggregate function in Oracle that bitwise XORs all MD5 sums of the values stored in a column.For example, if my table is:+-----+----------+---------+| Key | Sequence |  Value  |+-----+----------+---------+|   1 |        1 | 'Hello' ||   1 |        2 | 'World' ||   2 |        1 | '1234'  ||   3 |        0 | (empty) ||   4 |        1 | 'Hello' ||   4 |        3 | 'World' |+-----+----------+---------+I can run the following query in Oracle:with t AS (select 1 key, 1 sequence, 'Hello' value FROM dual           union all select 1, 2, 'World' from dual           union all select 2, 1, '1234' from dual           union all select 3, 0, '' from dual /* ... */          )   select key, md5_agg(value) from t group by keyand get (unfortunately aggregate functions in Oracle ignore NULL values and '' is considered as NULL)+---+----------------------------------+|key| md5_agg(value)                   |+---+----------------------------------+| 1 | 7EBD0B1DA67F965F802D31DF25C4B321 || 2 | 81DC9BDB52D04DC20036DBD8313ED055 || 3 | 00000000000000000000000000000000 || 4 | 7EBD0B1DA67F965F802D31DF25C4B321 |+---+----------------------------------+I would like to use this approach to compare if the contents of some columns are equal when I compare subsets of the same table (think of finding duplicates in a complex structures that spans over multiple rows in the same table). Here with this results I know that I have the same subsets for keys 1 and 4.What are the limits of such an approach? Here are the ones I could list:This is interesting only if my column contains distinct values. If my columns contains twice the same string, the xor operation will be a no-op.Due to Oracle limitations, if my column contains empty values, they do not count.With those limitations in mind, is it still possible to infer, from two equal md5_agg results computed from distinct and non-empty values, that the original values make up the same sets?In order to reformulate, are there odds that the MD5 sums of distinct strings XOR to 0?\n",
      "\n",
      "Cluster = 5, Raw data index = 69,637, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "For the reasons I cannot go into details, I need to design my own protocol and overall security system which will be used to establish secure data exchange between various devices (most notably desktops of all three major OSes, Android and iOS devices and Raspberry Pi, with the possibility to extend it to other embedded systems). Since I wouldn't dare to do my own crypto algorithms implementation, this implies that I have to rely on tried and tested libraries available for those platforms (i.e. OpenSSL, BouncyCastle, CommonCrypto, …) so I settled with what they all support - RSA for signing/authentication, DHE/ECDHE for session establishment, AES for encryption, PBKDF2 for key derivation and SHA2 for general hashing needs. The key sizes and complexity will depend on the hardware ability of targeted platforms.Now, I've done a fair bit of implementations of existing protocols and I like to think that I know my way around cryptography and perils that await if not applied properly, however I wouldn't dare to consider myself a cryptography expert and thus I decided to query the hive mind. Of course, once everything completed it will be properly audited and tested, but for now I need to know if I'm on the right track, that I haven't done some glaring omissions and if it is possible to improve it even further.The system I'm building should both cover the storage on devices and the communication between them and to preserve forward and backward secrecy.For the storage part I plan to utilize AES in CBC mode, storing the randomly generated IVs with each individual encrypted file. The 'master' key itself will be randomly generated and also AES-encrypted using a key derived from the user's password using PBKDF2, stored along with the salt and iterations used in it. My main concern is the IV part as if generated randomly it might repeat thus compromising the encrypted files if they happen to be similar enough or even the same. It's quite a low chance buy I don't like leaving anything to chance so the question is - given that the IV is public knowledge anyway, is it safe to use incremental progression/timestamp as IV in this case?The communication part will be a bit trickier as the devices will never communicate directly - instead the data exchange between them will be relied through a third party database to which they periodically connect, which is one of the prime reasons I'm designing my own protocol. If we except this oddity, the data exchange itself should function quite the same as if they were communicating directly, namely the devices will establish a session each time they 'contact' each other and then use the session key for encryption.To establish a session I plan to use a variation of STS protocol adapted to this environment. The only oddity here is that in some instances only one of the parties involved in communication will posses the RSA key of the other so it won't be fully authenticated - my understanding is that even in this case no successful MITM attack can be performed as at least one of the parties will reject communication if the signature doesn't match. Is that a safe assumption?Once DH/ECDH keys are exchanged an actual session AES key will be derived from them using SHA2 and the rest of the data exchange will be encrypted using that key, again in CBC mode - until the session expires, when the process repeats. I'm still not clear on how to approach the message integrity and authenticity verification - at first I thought that signing the message with the device's RSA key will be enough, but since it may happen that only one of the parties has the other party's certificate I might add a HMAC alongside with the exchanged messages as well. What would be a recommended, cryptographically secure way to handle that?\n",
      "\n",
      "Cluster = 5, Raw data index = 86,569, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "Apple OS X can create encrypted AES 128/256 DMG volumes. Here is written about a men who was able to hack it. And also that DMGs use PBKDF2-HMAC-SHA-1. I couldn't find more information about encrypted DMGs. So does that mean that apples encrypted DMGs could be hacked?\n",
      "\n",
      "Cluster = 5, Raw data index = 9,433, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "Hashcash is a proof-of-work system in which the Sender needs to find $Y$ such as the first (let's say 20) bits of $H(X+Y)$ are zeros where $H$ is a one-way hash function, $X$ is a fixed value and $+$ means concatenation. The Sender starts with an initial random number $Y$. It then computes the hash of $X+Y$. If the first 20 bits of the hash are zeros, then $Y$ is an acceptable number. If not, then the sender increments the random number and tries again. Since about $1$ in $2^{20}$ headers will have $20$ zeros as the beginning of the hash, the sender will on average have to try $2^{20}$ random numbers to find a valid number.My question is: The average number of tries is $2^{20}$ but is there a number of tries after which Hashcash is guaranted to be solved?\n",
      "\n",
      "Cluster = 5, Raw data index = 28,252, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I've always been interested in encryption but I have never found a good explanation (beginners explanation) of how encryption with public key and decryption with private key works.How does it encrypt something with one key and decipher it with another key?\n",
      "\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 2, Raw data index = 60,884, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I'm trying to put my RV into the breaker box I've got a 30 amp breaker double pole I've got10/2 wire, do I use a single pole or double pole 30 amp breaker hand my RV plug is a 4 prong plug how do I make this work\n",
      "\n",
      "Cluster = 2, Raw data index = 62,339, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I just installed 6 new 4\" halo can lights. When they are on I can smell a slight odor coming from them in the attic. Is this normal? I felt the light housing in the attic and is just warm. I also felt each wire going from light to light and it is cool to the touch.\n",
      "\n",
      "Cluster = 2, Raw data index = 6,276, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I have an odd wiring situation at one of my switches, and like a rookie took it all apart before taking a picture.I have 9 wires running into the box, 3 white, 3 black and 3 ground.The switch is a standard two-way that controls a light in the basement. This appears to be the start of the line, with another switch (controlling a different light) and an outlet further down the line. What's odd, is that one of the lines (BW pair) are both hot. As such, I can't figure out how this switch needs to be connected. Any thoughts?\n",
      "\n",
      "Cluster = 2, Raw data index = 63,446, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I have an existing three way switch hooked up already, it works fine. I would like to add another three way switch by connecting another switch to the existing three way switch. Can this be done with 14/2 romex between the two switches?\n",
      "\n",
      "Cluster = 2, Raw data index = 7,857, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "Can I temporarily ground an outlet by attaching a wire to its central screw and then to a grounding rod situated outside my house?  I want to use an electrical pressure washer, but it requires a ground that none of my outlets have.\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 3, Raw data index = 42,634, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I have designed an SQL aggregate function in Oracle that bitwise XORs all MD5 sums of the values stored in a column.For example, if my table is:+-----+----------+---------+| Key | Sequence |  Value  |+-----+----------+---------+|   1 |        1 | 'Hello' ||   1 |        2 | 'World' ||   2 |        1 | '1234'  ||   3 |        0 | (empty) ||   4 |        1 | 'Hello' ||   4 |        3 | 'World' |+-----+----------+---------+I can run the following query in Oracle:with t AS (select 1 key, 1 sequence, 'Hello' value FROM dual           union all select 1, 2, 'World' from dual           union all select 2, 1, '1234' from dual           union all select 3, 0, '' from dual /* ... */          )   select key, md5_agg(value) from t group by keyand get (unfortunately aggregate functions in Oracle ignore NULL values and '' is considered as NULL)+---+----------------------------------+|key| md5_agg(value)                   |+---+----------------------------------+| 1 | 7EBD0B1DA67F965F802D31DF25C4B321 || 2 | 81DC9BDB52D04DC20036DBD8313ED055 || 3 | 00000000000000000000000000000000 || 4 | 7EBD0B1DA67F965F802D31DF25C4B321 |+---+----------------------------------+I would like to use this approach to compare if the contents of some columns are equal when I compare subsets of the same table (think of finding duplicates in a complex structures that spans over multiple rows in the same table). Here with this results I know that I have the same subsets for keys 1 and 4.What are the limits of such an approach? Here are the ones I could list:This is interesting only if my column contains distinct values. If my columns contains twice the same string, the xor operation will be a no-op.Due to Oracle limitations, if my column contains empty values, they do not count.With those limitations in mind, is it still possible to infer, from two equal md5_agg results computed from distinct and non-empty values, that the original values make up the same sets?In order to reformulate, are there odds that the MD5 sums of distinct strings XOR to 0?\n",
      "\n",
      "Cluster = 3, Raw data index = 69,637, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "For the reasons I cannot go into details, I need to design my own protocol and overall security system which will be used to establish secure data exchange between various devices (most notably desktops of all three major OSes, Android and iOS devices and Raspberry Pi, with the possibility to extend it to other embedded systems). Since I wouldn't dare to do my own crypto algorithms implementation, this implies that I have to rely on tried and tested libraries available for those platforms (i.e. OpenSSL, BouncyCastle, CommonCrypto, …) so I settled with what they all support - RSA for signing/authentication, DHE/ECDHE for session establishment, AES for encryption, PBKDF2 for key derivation and SHA2 for general hashing needs. The key sizes and complexity will depend on the hardware ability of targeted platforms.Now, I've done a fair bit of implementations of existing protocols and I like to think that I know my way around cryptography and perils that await if not applied properly, however I wouldn't dare to consider myself a cryptography expert and thus I decided to query the hive mind. Of course, once everything completed it will be properly audited and tested, but for now I need to know if I'm on the right track, that I haven't done some glaring omissions and if it is possible to improve it even further.The system I'm building should both cover the storage on devices and the communication between them and to preserve forward and backward secrecy.For the storage part I plan to utilize AES in CBC mode, storing the randomly generated IVs with each individual encrypted file. The 'master' key itself will be randomly generated and also AES-encrypted using a key derived from the user's password using PBKDF2, stored along with the salt and iterations used in it. My main concern is the IV part as if generated randomly it might repeat thus compromising the encrypted files if they happen to be similar enough or even the same. It's quite a low chance buy I don't like leaving anything to chance so the question is - given that the IV is public knowledge anyway, is it safe to use incremental progression/timestamp as IV in this case?The communication part will be a bit trickier as the devices will never communicate directly - instead the data exchange between them will be relied through a third party database to which they periodically connect, which is one of the prime reasons I'm designing my own protocol. If we except this oddity, the data exchange itself should function quite the same as if they were communicating directly, namely the devices will establish a session each time they 'contact' each other and then use the session key for encryption.To establish a session I plan to use a variation of STS protocol adapted to this environment. The only oddity here is that in some instances only one of the parties involved in communication will posses the RSA key of the other so it won't be fully authenticated - my understanding is that even in this case no successful MITM attack can be performed as at least one of the parties will reject communication if the signature doesn't match. Is that a safe assumption?Once DH/ECDH keys are exchanged an actual session AES key will be derived from them using SHA2 and the rest of the data exchange will be encrypted using that key, again in CBC mode - until the session expires, when the process repeats. I'm still not clear on how to approach the message integrity and authenticity verification - at first I thought that signing the message with the device's RSA key will be enough, but since it may happen that only one of the parties has the other party's certificate I might add a HMAC alongside with the exchanged messages as well. What would be a recommended, cryptographically secure way to handle that?\n",
      "\n",
      "Cluster = 3, Raw data index = 86,569, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "Apple OS X can create encrypted AES 128/256 DMG volumes. Here is written about a men who was able to hack it. And also that DMGs use PBKDF2-HMAC-SHA-1. I couldn't find more information about encrypted DMGs. So does that mean that apples encrypted DMGs could be hacked?\n",
      "\n",
      "Cluster = 3, Raw data index = 9,433, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "Hashcash is a proof-of-work system in which the Sender needs to find $Y$ such as the first (let's say 20) bits of $H(X+Y)$ are zeros where $H$ is a one-way hash function, $X$ is a fixed value and $+$ means concatenation. The Sender starts with an initial random number $Y$. It then computes the hash of $X+Y$. If the first 20 bits of the hash are zeros, then $Y$ is an acceptable number. If not, then the sender increments the random number and tries again. Since about $1$ in $2^{20}$ headers will have $20$ zeros as the beginning of the hash, the sender will on average have to try $2^{20}$ random numbers to find a valid number.My question is: The average number of tries is $2^{20}$ but is there a number of tries after which Hashcash is guaranted to be solved?\n",
      "\n",
      "Cluster = 3, Raw data index = 28,252, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I've always been interested in encryption but I have never found a good explanation (beginners explanation) of how encryption with public key and decryption with private key works.How does it encrypt something with one key and decipher it with another key?\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 1, Raw data index = 33,566, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I'm a citizen of country X and have a valid United States ESTA in my X passport.  Recently, I became of citizen of Y and now have a Y passport as well, which I would like to use for future travel to the US.  Both countries qualify for the Visa Waiver Program.  Can I have ESTAs in both passports at the same time?The official CBP site seems contradictory, first implying that I should get a new ESTA:  If you obtain a new passport or change your name, gender or country of  citizenship, you will be required to apply for a new travel  authorization. This is also required if one of your answers to any of  the VWP eligibility questions changes. The associated fee of $14 will  be charged for each new application.And then saying that I should not have two simultaneous ESTAs:  If you have dual citizenship and have registered with ESTA, you should  use your VWP-eligible passport to board the plane when you leave your  country of departure and when you arrive in the U.S. If both your  countries of citizenship are VWP-eligible, then we strongly recommend  you choose which one you want to claim for purposes of travel to the  U.S., and use that country's passport each time you travel. One person  with two different ESTA authorizations creates confusion that will  only delay your travel.Cancelling the old ESTA would seem a valid way to fulfill both requirements, but there doesn't appear to be any way to do this?\n",
      "\n",
      "Cluster = 1, Raw data index = 48,613, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I am not sure this is the right place to ask this question but assuming any traveler might have come across this situation/have information,requesting to please guide.I had arrived USA 2 months before on B1/B2 visa.As I-94 forms are now paperless, i did not receive one at the time of arrival at USA airport. But i can see details of same on cbs.gov website. In paperless I-94, where do we need to return the form / do we need to return the form when I leave USA? I checked website but it had information regarding the case when paper I-94 is received.\n",
      "\n",
      "Cluster = 1, Raw data index = 55,030, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "My old passport have 2-year valid visa of DRCongo and it is expire on 04.06.2016. Now I am on holiday and going back at DRCongo on 01.05.2016. My old passport have remain 2 blank page so my boss told me to make new passport and I got a new passport.Will the immigration officer accept my visa if it is on my old passport?\n",
      "\n",
      "Cluster = 1, Raw data index = 49,361, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I am flying from London to Central America and back this summer on a bit of an extended holiday. I am considering stopping over in NYC on the way back for a few days. (My flight from Panama to London would be through NYC anyway and got offered a good deal by a travel agent.) I am residing in London as an EU citizen and I always use my EU passport to get around the world. However as I was born in the States I am also a fully fledged US citizen with the blue passport. The only time I've used my US passport in the past was for a US holiday a decade ago. I've never lived in the States so I don't sound American etc. I want to book my flights and travel around Central America using my EU passport for simplicity's sake. However I have come across on the US foreign office website a bit stating that US dual citizens can only enter and exit the State with a US passport. What should I do? I assume that I can't check into my flight on a European passport then enter and exit US border control with a US passport? Can I just ignore the fact that I've got a US passport and hope they don't clock on it? My EU passport will state my place of birth as the States but as I've said I don't sound American or anything. Is that risky? I don't want to be turned back at the gates on my first NYC trip!\n",
      "\n",
      "Cluster = 1, Raw data index = 55,078, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "My wife has a Schengen visa issued by the Italian consulate in the UK.It expires at the beginning of December, and as we want to travel to Europe for the Christmas holiday, we were hoping to cancel the current Schengen visa early in order to apply for another one in time.I have contacted the Italian consulate in London by email, and they have told me that they are unable to do this. After a quick search online, it seems other people have had more luck cancelling their visas. So my question is: has anyone cancelled a Schengen visa issued by Italy, and if so - how?\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 0, Raw data index = 81,864, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I live in the Midwest of the United States, and we not-too-rarely get a large amount of rain coming down at one time both in the spring and sometimes in the fall. Last night was no different (aside from random earthquakes..) than usual, but after I went to bed, my smoke alarm went off. I quickly determined that there was in fact no fire, so I went to take the smoke alarm off of its mounting and when I removed it, I found that there was a decent amount of water in the smoke detector. If I had to guess I'd say about 50 mL. So not a huge amount, but enough to set it off.I left it off for a time, and did not notice any more water coming from the opening in the ceiling (which is a recess where the detector and power wiring sits, not fully open to the attic (just where the wires come in, as far as I know. I didn't examine it terribly closely), even though it was still raining fairly hard (though not nearly as hard as it had been). This morning, I went to have a look around the attic to see if I could see anywhere it was leaking (it is still misting outside, but not raining any longer), but I was unable to detect any wet spots in the roof.What should my next step be? The roof (and indeed the house) is 1 year old, so I would hope that it hasn't sprung a leak, but I can't think of how else water would have gotten into the smoke detector. I also suspect paying someone to go and try to find a leak is going to be fairly expensive as well.The detector itself appears to be working. If I test it, and it functions, should I still replace it because of potential water damage?UpdateHere is a picture of the socket in question, and there is indeed cool air coming from it. I'm not totally convinced it is just condensation, elsewise this would have happened last year during the winter, I would think, but am unsure.\n",
      "\n",
      "Cluster = 0, Raw data index = 22,211, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "We discovered a bath tub leak from our second floor bathroom which dripped through the sidings. The bathroom has the original fixtures from 1989. It leaks when there's excess amount of water used.Would this be a simple problem of refinishing everything using plumber's putty?\n",
      "\n",
      "Cluster = 0, Raw data index = 74,198, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "The air quality in my basement is unpleasant. I don't know if I have mold. How to test for it? How is the smell of mold?I know that we had a water problem in the basement, the walls were cracked so every rainy day, we had humidity and water in the basement. But I have never seen signs of mold. How to check for mold?\n",
      "\n",
      "Cluster = 0, Raw data index = 44,660, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "Many instances of this worm-like creature were found in a water system for a mountain cabin in the Sierra Nevada mountains of the US, in late June / early July.  The water system collects water from an enclosed spring.  Can you help identify this creature?  Clues:The worms have two \"points\" on their heads. They can stretch out and be long and thin, or when poked (or are resting) they contract into a small blob.  Here is a picture of a single worm with markings shown.Here is a picture of a few worms, somewhat contracted. Here is a movie of them moving, in natural light.  Here is a movie of them moving, with backlight.Here are pictures of their undersides and their internal structures.Whenever I pull some out of the water and put them into a tupperware with the same water, they only survive for around 24 hours, after which they seem to disintegrate.  Here is a picture of about 20 of the worms after about 24 hours, the bulk of them have halfway-decomposed and form a heap in the upper right.  After another day it'll just look like debris in the water, you wouldn't even recognize that there were worms in it.  There is a piece of bacon in there because some suggested putting it there to test if they were leeches, but this disintegration happens repeatably and regardless of the bacon; please ignore the bacon.Someone suggested that they are trematodes, but there are no snails, frogs, or other creatures in the storage and collection sections of the water system;  we have looked very closely.  There may be something within a 30-foot section of pipe, but we doubt it.  Can you help us identify this creature?  Even just possible families of creatures or general categories would be helpful for us.\n",
      "\n",
      "Cluster = 0, Raw data index = 83,398, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I have a reliance model 5 30 NORS971 gas HOT WATER tank. The basement flooded a little and put out the pilot. When it would not light, I replaced the pilot tip and went ahead and replaced the thermocouple. All went well and it lit and fired the burner. One week later, the pilot would light but go out when button released. Replaced the gas control with one from another tank and it worked for about a week. The pressure relief was then leaking a little so replaced it. One more week and not working so bought new gas control and replaced and all lit.Now 2 weeks later, not working and pilot will light but, goes out on release. used multimeter and get 20 mv on thermocouple. What would be cause of gas controls burning out?\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 4, Raw data index = 63,096, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I bought a new house about a month ago, and have since noticed some plumbing issues in the laundry room:laundry tub drains slowlyoccasional \"musty\" smell, which seems to come from the drainsI did some research online and found that lack of drain ventilation could cause both of these problems. So I checked the plumbing and it looks like both the washing machine and adjacent wash basin drain into the same pipe. As far as I can tell, there is no ventilation on these drains (photo below); it looks like a stacked pair of S-traps.The laundry room is in a little addition at the back of the house. So I probably cannot tie this back in to the main house venting stack without a lot of work. I gather the simplest solution is to locally install an air admittance valve (AAV). Does that sound like a reasonable approach here?If so, am I on the right track with one of these:http://www.rona.ca/en/air-admittance-valvehttp://www.amazon.ca/gp/product/B000H5SLWM?psc=1&amp;redirect=true&amp;ref_=ox_sc_act_title_1&amp;smid=A23X8TYK8IHNZFMy plan is to remove the upper S-trap. Then install a sanitary T, going to: AAV (top) and P-trap (horizontal). Does that sound right?\n",
      "\n",
      "Cluster = 4, Raw data index = 31,500, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I have read a lot about proper insulation and ventilation, including some posts on this site, but none adequately answer my questions.My goal is to operate an electric heat source in the winter and have ~60 &deg;F temperature maintained when working in the garage.  In the summer, I think we will typically leave the garage door open, however it would be nice to one day have it stay cool in there if it's 90-100 &deg;F outside.This is in Ohio, where we typically have temps of 0-95 &deg;F throughout the year, it can also get pretty humid.I do not have soffit vents, but there is a ridge vent on the roof already installed.  I do not want to drywall nor do I want to build a ceiling.As you see in the photos I have already insulated the walls with R15 Batt installation.  Now I'm unsure where to go from here for roof 2x6's.  I bought some radiant barrier R11-equivelent insulation (seen in photos as well), which I was planning to attach to the end of the 2x6's above, which leaves plenty of ventilation behind them, should be \"ok\" in the winter and pretty decent in the summer.  However, not having soffit vents, I'm unsure if that is the proper use-case.You'll see from the wall install that I have no concerns about a vapor barrier, and do not care to seal my garage 100% (I only got faced insulation because it was cheaper =)  ).  However, I am concerned about mold/moisture problems in the space.  I would love some feedback as to the proper way to proceed here.  Ideally I can make use of my radiant barriers, and ideally I won't have to cut in soffit vents.Full resolution images here for reference: http://imgur.com/a/4Wd9Q and http://imgur.com/a/ud8os\n",
      "\n",
      "Cluster = 4, Raw data index = 8,153, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "What's the best way for a DIY granite counter top to be cut?  What tools do I need that will do the job without breaking the bank?\n",
      "\n",
      "Cluster = 4, Raw data index = 6,644, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I'm remodeling my bathroom and shower and I'll be replacing the insulation on the external wall. This wall is the \"back\" of the shower (opposite from where the water supply lines are). With this in mind, I should be able to just choose some insulation and then plop it in when I have the wall torn down.The main question and concern I have is about vapor barrier. I will be using cement board with a liquid topical membrane (like Redgard) for waterproofing the shower which means I'm not supposed to put a vapor barrier on the back side of the wall because it is bad to trap moisture. How does this affect insulating? Am I safe to nix the vapor barrier around the shower? What should I do for the rest of the bathroom?I'm not too concerned with price so if there are other options besides batting insulation (such as foam, etc...) that would solve my problem, I'm willing to hear those ideas as well.\n",
      "\n",
      "Cluster = 4, Raw data index = 65,112, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I am doing some minor renovations to my basement with the drop ceiling and found that one of the geniuses that owned the house before me, used fibreglass ceiling tiles to seal off an old vent for a gas fireplace. Obviously this will not do. I'm thinking of building a section of 2x4's around the old exhaust and then filling it with rigid foam and spray foam. I can't take the old exhaust off the side of the house, since it is a condo and I doubt that I'm going to convince them to replace the siding where this exhaust vent is, not to mention it will probably cost me. Open to any suggestions. I would post a pic but the settings don't allow it, kinda odd.\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 5, Raw data index = 15,061, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "It's always difficult to decide what clothes to take with you when you go to a new place. Usually I check Wikipedia to get an idea of approximate climate and weather conditions, but it often doesn't have much data besides average temperatures. Other factors, such as wind and precipitation, might enter into the equation, and the same temperature can \"feel like\" differently in two distinct locations.Perhaps not the same factors are important whether one travels to tropical/equatorial locations, or to temperate/subarctic places.So, in short:  If I travel to a new place, which weather factors should I look into to decide what to take with me?\n",
      "\n",
      "Cluster = 5, Raw data index = 65,232, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I see the TSA have brought in new rules for devices, in response to intelligence that terrorists may be trying to pack mobile phones with explosive, so checks before flights can include having to prove the device can power on.Although fearing the worst and allowing lots of extra time at airports, I have not yet encountered any checks of this sort over and above the usual taking devices out of bags so they can be scanned separately.From various news articles, there doesn't appear to be any consistent view as to what checks will be carried out.Can anyone here clarify what they do? Do you have to prove a phone can make a call, or just show it is powered on?\n",
      "\n",
      "Cluster = 5, Raw data index = 6,061, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I'm planning to visit Medellin and Bogota sometime in the near future. I've a U.S. DL which endorses motorcycles. Is it legal to ride motorcycles in Colombia with a US driver's license? Is it required to carry any other identification other than the U.S. DL in case if I'm on the road?\n",
      "\n",
      "Cluster = 5, Raw data index = 11,890, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "The way I currently cook kidney beans is to soak them overnight. But still they have to be cooked for a long time on gas before they get tender enough to be edible.Anything that can be added or be done in a different way to reduce the time over heat?\n",
      "\n",
      "Cluster = 5, Raw data index = 57,730, Hyper-Parameters = {'clusterer__max_iter': 500, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "To quote Goodman &amp; Gilman :  An alternative way of defining the anesthetic state is to consider it  as a collection of “component” changes in behavior or perception. The  components of the anesthetic state include:  • amnesia  • immobility in  response to noxious stimulation  • attenuation of autonomic responses  to noxious stimulation  • analgesia  • unconsciousnessMy question is, does not the state of Unconsciousness already imply other components of analgesia and amnesia? Analgesia is the absence of the perception of pain, which is granted if there is unconsciousness which would be the absence of all perceptions. I am not certain if unconsciousness also entails amnesia, but it seems that remembering what happened when unconscious seems considerably unlikely.  Apart from a reductionist argument for minimizing the constraints required for classification as a general anesthetic, I am more interested in cases where unconsciousness would be achieved without analgesia or amnesia, which could be a likely rationale behind including the additional caveats in the definition.\n",
      "\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 2, Raw data index = 81,864, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I live in the Midwest of the United States, and we not-too-rarely get a large amount of rain coming down at one time both in the spring and sometimes in the fall. Last night was no different (aside from random earthquakes..) than usual, but after I went to bed, my smoke alarm went off. I quickly determined that there was in fact no fire, so I went to take the smoke alarm off of its mounting and when I removed it, I found that there was a decent amount of water in the smoke detector. If I had to guess I'd say about 50 mL. So not a huge amount, but enough to set it off.I left it off for a time, and did not notice any more water coming from the opening in the ceiling (which is a recess where the detector and power wiring sits, not fully open to the attic (just where the wires come in, as far as I know. I didn't examine it terribly closely), even though it was still raining fairly hard (though not nearly as hard as it had been). This morning, I went to have a look around the attic to see if I could see anywhere it was leaking (it is still misting outside, but not raining any longer), but I was unable to detect any wet spots in the roof.What should my next step be? The roof (and indeed the house) is 1 year old, so I would hope that it hasn't sprung a leak, but I can't think of how else water would have gotten into the smoke detector. I also suspect paying someone to go and try to find a leak is going to be fairly expensive as well.The detector itself appears to be working. If I test it, and it functions, should I still replace it because of potential water damage?UpdateHere is a picture of the socket in question, and there is indeed cool air coming from it. I'm not totally convinced it is just condensation, elsewise this would have happened last year during the winter, I would think, but am unsure.\n",
      "\n",
      "Cluster = 2, Raw data index = 22,211, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "We discovered a bath tub leak from our second floor bathroom which dripped through the sidings. The bathroom has the original fixtures from 1989. It leaks when there's excess amount of water used.Would this be a simple problem of refinishing everything using plumber's putty?\n",
      "\n",
      "Cluster = 2, Raw data index = 74,198, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "The air quality in my basement is unpleasant. I don't know if I have mold. How to test for it? How is the smell of mold?I know that we had a water problem in the basement, the walls were cracked so every rainy day, we had humidity and water in the basement. But I have never seen signs of mold. How to check for mold?\n",
      "\n",
      "Cluster = 2, Raw data index = 44,660, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "Many instances of this worm-like creature were found in a water system for a mountain cabin in the Sierra Nevada mountains of the US, in late June / early July.  The water system collects water from an enclosed spring.  Can you help identify this creature?  Clues:The worms have two \"points\" on their heads. They can stretch out and be long and thin, or when poked (or are resting) they contract into a small blob.  Here is a picture of a single worm with markings shown.Here is a picture of a few worms, somewhat contracted. Here is a movie of them moving, in natural light.  Here is a movie of them moving, with backlight.Here are pictures of their undersides and their internal structures.Whenever I pull some out of the water and put them into a tupperware with the same water, they only survive for around 24 hours, after which they seem to disintegrate.  Here is a picture of about 20 of the worms after about 24 hours, the bulk of them have halfway-decomposed and form a heap in the upper right.  After another day it'll just look like debris in the water, you wouldn't even recognize that there were worms in it.  There is a piece of bacon in there because some suggested putting it there to test if they were leeches, but this disintegration happens repeatably and regardless of the bacon; please ignore the bacon.Someone suggested that they are trematodes, but there are no snails, frogs, or other creatures in the storage and collection sections of the water system;  we have looked very closely.  There may be something within a 30-foot section of pipe, but we doubt it.  Can you help us identify this creature?  Even just possible families of creatures or general categories would be helpful for us.\n",
      "\n",
      "Cluster = 2, Raw data index = 45,540, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "People may tend to spend time in a hot water spring. Is it possible to get hyperthermia (like a sun stroke) due to this?\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 3, Raw data index = 63,096, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I bought a new house about a month ago, and have since noticed some plumbing issues in the laundry room:laundry tub drains slowlyoccasional \"musty\" smell, which seems to come from the drainsI did some research online and found that lack of drain ventilation could cause both of these problems. So I checked the plumbing and it looks like both the washing machine and adjacent wash basin drain into the same pipe. As far as I can tell, there is no ventilation on these drains (photo below); it looks like a stacked pair of S-traps.The laundry room is in a little addition at the back of the house. So I probably cannot tie this back in to the main house venting stack without a lot of work. I gather the simplest solution is to locally install an air admittance valve (AAV). Does that sound like a reasonable approach here?If so, am I on the right track with one of these:http://www.rona.ca/en/air-admittance-valvehttp://www.amazon.ca/gp/product/B000H5SLWM?psc=1&amp;redirect=true&amp;ref_=ox_sc_act_title_1&amp;smid=A23X8TYK8IHNZFMy plan is to remove the upper S-trap. Then install a sanitary T, going to: AAV (top) and P-trap (horizontal). Does that sound right?\n",
      "\n",
      "Cluster = 3, Raw data index = 31,500, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I have read a lot about proper insulation and ventilation, including some posts on this site, but none adequately answer my questions.My goal is to operate an electric heat source in the winter and have ~60 &deg;F temperature maintained when working in the garage.  In the summer, I think we will typically leave the garage door open, however it would be nice to one day have it stay cool in there if it's 90-100 &deg;F outside.This is in Ohio, where we typically have temps of 0-95 &deg;F throughout the year, it can also get pretty humid.I do not have soffit vents, but there is a ridge vent on the roof already installed.  I do not want to drywall nor do I want to build a ceiling.As you see in the photos I have already insulated the walls with R15 Batt installation.  Now I'm unsure where to go from here for roof 2x6's.  I bought some radiant barrier R11-equivelent insulation (seen in photos as well), which I was planning to attach to the end of the 2x6's above, which leaves plenty of ventilation behind them, should be \"ok\" in the winter and pretty decent in the summer.  However, not having soffit vents, I'm unsure if that is the proper use-case.You'll see from the wall install that I have no concerns about a vapor barrier, and do not care to seal my garage 100% (I only got faced insulation because it was cheaper =)  ).  However, I am concerned about mold/moisture problems in the space.  I would love some feedback as to the proper way to proceed here.  Ideally I can make use of my radiant barriers, and ideally I won't have to cut in soffit vents.Full resolution images here for reference: http://imgur.com/a/4Wd9Q and http://imgur.com/a/ud8os\n",
      "\n",
      "Cluster = 3, Raw data index = 8,153, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "What's the best way for a DIY granite counter top to be cut?  What tools do I need that will do the job without breaking the bank?\n",
      "\n",
      "Cluster = 3, Raw data index = 6,644, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I'm remodeling my bathroom and shower and I'll be replacing the insulation on the external wall. This wall is the \"back\" of the shower (opposite from where the water supply lines are). With this in mind, I should be able to just choose some insulation and then plop it in when I have the wall torn down.The main question and concern I have is about vapor barrier. I will be using cement board with a liquid topical membrane (like Redgard) for waterproofing the shower which means I'm not supposed to put a vapor barrier on the back side of the wall because it is bad to trap moisture. How does this affect insulating? Am I safe to nix the vapor barrier around the shower? What should I do for the rest of the bathroom?I'm not too concerned with price so if there are other options besides batting insulation (such as foam, etc...) that would solve my problem, I'm willing to hear those ideas as well.\n",
      "\n",
      "Cluster = 3, Raw data index = 65,112, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I am doing some minor renovations to my basement with the drop ceiling and found that one of the geniuses that owned the house before me, used fibreglass ceiling tiles to seal off an old vent for a gas fireplace. Obviously this will not do. I'm thinking of building a section of 2x4's around the old exhaust and then filling it with rigid foam and spray foam. I can't take the old exhaust off the side of the house, since it is a condo and I doubt that I'm going to convince them to replace the siding where this exhaust vent is, not to mention it will probably cost me. Open to any suggestions. I would post a pic but the settings don't allow it, kinda odd.\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 1, Raw data index = 60,884, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I'm trying to put my RV into the breaker box I've got a 30 amp breaker double pole I've got10/2 wire, do I use a single pole or double pole 30 amp breaker hand my RV plug is a 4 prong plug how do I make this work\n",
      "\n",
      "Cluster = 1, Raw data index = 62,339, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I just installed 6 new 4\" halo can lights. When they are on I can smell a slight odor coming from them in the attic. Is this normal? I felt the light housing in the attic and is just warm. I also felt each wire going from light to light and it is cool to the touch.\n",
      "\n",
      "Cluster = 1, Raw data index = 6,276, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I have an odd wiring situation at one of my switches, and like a rookie took it all apart before taking a picture.I have 9 wires running into the box, 3 white, 3 black and 3 ground.The switch is a standard two-way that controls a light in the basement. This appears to be the start of the line, with another switch (controlling a different light) and an outlet further down the line. What's odd, is that one of the lines (BW pair) are both hot. As such, I can't figure out how this switch needs to be connected. Any thoughts?\n",
      "\n",
      "Cluster = 1, Raw data index = 63,446, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I have an existing three way switch hooked up already, it works fine. I would like to add another three way switch by connecting another switch to the existing three way switch. Can this be done with 14/2 romex between the two switches?\n",
      "\n",
      "Cluster = 1, Raw data index = 7,857, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "Can I temporarily ground an outlet by attaching a wire to its central screw and then to a grounding rod situated outside my house?  I want to use an electrical pressure washer, but it requires a ground that none of my outlets have.\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 0, Raw data index = 33,566, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I'm a citizen of country X and have a valid United States ESTA in my X passport.  Recently, I became of citizen of Y and now have a Y passport as well, which I would like to use for future travel to the US.  Both countries qualify for the Visa Waiver Program.  Can I have ESTAs in both passports at the same time?The official CBP site seems contradictory, first implying that I should get a new ESTA:  If you obtain a new passport or change your name, gender or country of  citizenship, you will be required to apply for a new travel  authorization. This is also required if one of your answers to any of  the VWP eligibility questions changes. The associated fee of $14 will  be charged for each new application.And then saying that I should not have two simultaneous ESTAs:  If you have dual citizenship and have registered with ESTA, you should  use your VWP-eligible passport to board the plane when you leave your  country of departure and when you arrive in the U.S. If both your  countries of citizenship are VWP-eligible, then we strongly recommend  you choose which one you want to claim for purposes of travel to the  U.S., and use that country's passport each time you travel. One person  with two different ESTA authorizations creates confusion that will  only delay your travel.Cancelling the old ESTA would seem a valid way to fulfill both requirements, but there doesn't appear to be any way to do this?\n",
      "\n",
      "Cluster = 0, Raw data index = 48,613, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I am not sure this is the right place to ask this question but assuming any traveler might have come across this situation/have information,requesting to please guide.I had arrived USA 2 months before on B1/B2 visa.As I-94 forms are now paperless, i did not receive one at the time of arrival at USA airport. But i can see details of same on cbs.gov website. In paperless I-94, where do we need to return the form / do we need to return the form when I leave USA? I checked website but it had information regarding the case when paper I-94 is received.\n",
      "\n",
      "Cluster = 0, Raw data index = 55,030, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "My old passport have 2-year valid visa of DRCongo and it is expire on 04.06.2016. Now I am on holiday and going back at DRCongo on 01.05.2016. My old passport have remain 2 blank page so my boss told me to make new passport and I got a new passport.Will the immigration officer accept my visa if it is on my old passport?\n",
      "\n",
      "Cluster = 0, Raw data index = 49,361, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I am flying from London to Central America and back this summer on a bit of an extended holiday. I am considering stopping over in NYC on the way back for a few days. (My flight from Panama to London would be through NYC anyway and got offered a good deal by a travel agent.) I am residing in London as an EU citizen and I always use my EU passport to get around the world. However as I was born in the States I am also a fully fledged US citizen with the blue passport. The only time I've used my US passport in the past was for a US holiday a decade ago. I've never lived in the States so I don't sound American etc. I want to book my flights and travel around Central America using my EU passport for simplicity's sake. However I have come across on the US foreign office website a bit stating that US dual citizens can only enter and exit the State with a US passport. What should I do? I assume that I can't check into my flight on a European passport then enter and exit US border control with a US passport? Can I just ignore the fact that I've got a US passport and hope they don't clock on it? My EU passport will state my place of birth as the States but as I've said I don't sound American or anything. Is that risky? I don't want to be turned back at the gates on my first NYC trip!\n",
      "\n",
      "Cluster = 0, Raw data index = 55,078, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "My wife has a Schengen visa issued by the Italian consulate in the UK.It expires at the beginning of December, and as we want to travel to Europe for the Christmas holiday, we were hoping to cancel the current Schengen visa early in order to apply for another one in time.I have contacted the Italian consulate in London by email, and they have told me that they are unable to do this. After a quick search online, it seems other people have had more luck cancelling their visas. So my question is: has anyone cancelled a Schengen visa issued by Italy, and if so - how?\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 4, Raw data index = 15,061, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "It's always difficult to decide what clothes to take with you when you go to a new place. Usually I check Wikipedia to get an idea of approximate climate and weather conditions, but it often doesn't have much data besides average temperatures. Other factors, such as wind and precipitation, might enter into the equation, and the same temperature can \"feel like\" differently in two distinct locations.Perhaps not the same factors are important whether one travels to tropical/equatorial locations, or to temperate/subarctic places.So, in short:  If I travel to a new place, which weather factors should I look into to decide what to take with me?\n",
      "\n",
      "Cluster = 4, Raw data index = 65,232, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I see the TSA have brought in new rules for devices, in response to intelligence that terrorists may be trying to pack mobile phones with explosive, so checks before flights can include having to prove the device can power on.Although fearing the worst and allowing lots of extra time at airports, I have not yet encountered any checks of this sort over and above the usual taking devices out of bags so they can be scanned separately.From various news articles, there doesn't appear to be any consistent view as to what checks will be carried out.Can anyone here clarify what they do? Do you have to prove a phone can make a call, or just show it is powered on?\n",
      "\n",
      "Cluster = 4, Raw data index = 6,061, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I'm planning to visit Medellin and Bogota sometime in the near future. I've a U.S. DL which endorses motorcycles. Is it legal to ride motorcycles in Colombia with a US driver's license? Is it required to carry any other identification other than the U.S. DL in case if I'm on the road?\n",
      "\n",
      "Cluster = 4, Raw data index = 11,890, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "The way I currently cook kidney beans is to soak them overnight. But still they have to be cooked for a long time on gas before they get tender enough to be edible.Anything that can be added or be done in a different way to reduce the time over heat?\n",
      "\n",
      "Cluster = 4, Raw data index = 57,730, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "To quote Goodman &amp; Gilman :  An alternative way of defining the anesthetic state is to consider it  as a collection of “component” changes in behavior or perception. The  components of the anesthetic state include:  • amnesia  • immobility in  response to noxious stimulation  • attenuation of autonomic responses  to noxious stimulation  • analgesia  • unconsciousnessMy question is, does not the state of Unconsciousness already imply other components of analgesia and amnesia? Analgesia is the absence of the perception of pain, which is granted if there is unconsciousness which would be the absence of all perceptions. I am not certain if unconsciousness also entails amnesia, but it seems that remembering what happened when unconscious seems considerably unlikely.  Apart from a reductionist argument for minimizing the constraints required for classification as a general anesthetic, I am more interested in cases where unconsciousness would be achieved without analgesia or amnesia, which could be a likely rationale behind including the additional caveats in the definition.\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 5, Raw data index = 42,634, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I have designed an SQL aggregate function in Oracle that bitwise XORs all MD5 sums of the values stored in a column.For example, if my table is:+-----+----------+---------+| Key | Sequence |  Value  |+-----+----------+---------+|   1 |        1 | 'Hello' ||   1 |        2 | 'World' ||   2 |        1 | '1234'  ||   3 |        0 | (empty) ||   4 |        1 | 'Hello' ||   4 |        3 | 'World' |+-----+----------+---------+I can run the following query in Oracle:with t AS (select 1 key, 1 sequence, 'Hello' value FROM dual           union all select 1, 2, 'World' from dual           union all select 2, 1, '1234' from dual           union all select 3, 0, '' from dual /* ... */          )   select key, md5_agg(value) from t group by keyand get (unfortunately aggregate functions in Oracle ignore NULL values and '' is considered as NULL)+---+----------------------------------+|key| md5_agg(value)                   |+---+----------------------------------+| 1 | 7EBD0B1DA67F965F802D31DF25C4B321 || 2 | 81DC9BDB52D04DC20036DBD8313ED055 || 3 | 00000000000000000000000000000000 || 4 | 7EBD0B1DA67F965F802D31DF25C4B321 |+---+----------------------------------+I would like to use this approach to compare if the contents of some columns are equal when I compare subsets of the same table (think of finding duplicates in a complex structures that spans over multiple rows in the same table). Here with this results I know that I have the same subsets for keys 1 and 4.What are the limits of such an approach? Here are the ones I could list:This is interesting only if my column contains distinct values. If my columns contains twice the same string, the xor operation will be a no-op.Due to Oracle limitations, if my column contains empty values, they do not count.With those limitations in mind, is it still possible to infer, from two equal md5_agg results computed from distinct and non-empty values, that the original values make up the same sets?In order to reformulate, are there odds that the MD5 sums of distinct strings XOR to 0?\n",
      "\n",
      "Cluster = 5, Raw data index = 69,637, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "For the reasons I cannot go into details, I need to design my own protocol and overall security system which will be used to establish secure data exchange between various devices (most notably desktops of all three major OSes, Android and iOS devices and Raspberry Pi, with the possibility to extend it to other embedded systems). Since I wouldn't dare to do my own crypto algorithms implementation, this implies that I have to rely on tried and tested libraries available for those platforms (i.e. OpenSSL, BouncyCastle, CommonCrypto, …) so I settled with what they all support - RSA for signing/authentication, DHE/ECDHE for session establishment, AES for encryption, PBKDF2 for key derivation and SHA2 for general hashing needs. The key sizes and complexity will depend on the hardware ability of targeted platforms.Now, I've done a fair bit of implementations of existing protocols and I like to think that I know my way around cryptography and perils that await if not applied properly, however I wouldn't dare to consider myself a cryptography expert and thus I decided to query the hive mind. Of course, once everything completed it will be properly audited and tested, but for now I need to know if I'm on the right track, that I haven't done some glaring omissions and if it is possible to improve it even further.The system I'm building should both cover the storage on devices and the communication between them and to preserve forward and backward secrecy.For the storage part I plan to utilize AES in CBC mode, storing the randomly generated IVs with each individual encrypted file. The 'master' key itself will be randomly generated and also AES-encrypted using a key derived from the user's password using PBKDF2, stored along with the salt and iterations used in it. My main concern is the IV part as if generated randomly it might repeat thus compromising the encrypted files if they happen to be similar enough or even the same. It's quite a low chance buy I don't like leaving anything to chance so the question is - given that the IV is public knowledge anyway, is it safe to use incremental progression/timestamp as IV in this case?The communication part will be a bit trickier as the devices will never communicate directly - instead the data exchange between them will be relied through a third party database to which they periodically connect, which is one of the prime reasons I'm designing my own protocol. If we except this oddity, the data exchange itself should function quite the same as if they were communicating directly, namely the devices will establish a session each time they 'contact' each other and then use the session key for encryption.To establish a session I plan to use a variation of STS protocol adapted to this environment. The only oddity here is that in some instances only one of the parties involved in communication will posses the RSA key of the other so it won't be fully authenticated - my understanding is that even in this case no successful MITM attack can be performed as at least one of the parties will reject communication if the signature doesn't match. Is that a safe assumption?Once DH/ECDH keys are exchanged an actual session AES key will be derived from them using SHA2 and the rest of the data exchange will be encrypted using that key, again in CBC mode - until the session expires, when the process repeats. I'm still not clear on how to approach the message integrity and authenticity verification - at first I thought that signing the message with the device's RSA key will be enough, but since it may happen that only one of the parties has the other party's certificate I might add a HMAC alongside with the exchanged messages as well. What would be a recommended, cryptographically secure way to handle that?\n",
      "\n",
      "Cluster = 5, Raw data index = 86,569, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "Apple OS X can create encrypted AES 128/256 DMG volumes. Here is written about a men who was able to hack it. And also that DMGs use PBKDF2-HMAC-SHA-1. I couldn't find more information about encrypted DMGs. So does that mean that apples encrypted DMGs could be hacked?\n",
      "\n",
      "Cluster = 5, Raw data index = 9,433, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "Hashcash is a proof-of-work system in which the Sender needs to find $Y$ such as the first (let's say 20) bits of $H(X+Y)$ are zeros where $H$ is a one-way hash function, $X$ is a fixed value and $+$ means concatenation. The Sender starts with an initial random number $Y$. It then computes the hash of $X+Y$. If the first 20 bits of the hash are zeros, then $Y$ is an acceptable number. If not, then the sender increments the random number and tries again. Since about $1$ in $2^{20}$ headers will have $20$ zeros as the beginning of the hash, the sender will on average have to try $2^{20}$ random numbers to find a valid number.My question is: The average number of tries is $2^{20}$ but is there a number of tries after which Hashcash is guaranted to be solved?\n",
      "\n",
      "Cluster = 5, Raw data index = 28,252, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 15}\n",
      "I've always been interested in encryption but I have never found a good explanation (beginners explanation) of how encryption with public key and decryption with private key works.How does it encrypt something with one key and decipher it with another key?\n",
      "\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 2, Raw data index = 60,884, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I'm trying to put my RV into the breaker box I've got a 30 amp breaker double pole I've got10/2 wire, do I use a single pole or double pole 30 amp breaker hand my RV plug is a 4 prong plug how do I make this work\n",
      "\n",
      "Cluster = 2, Raw data index = 62,339, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I just installed 6 new 4\" halo can lights. When they are on I can smell a slight odor coming from them in the attic. Is this normal? I felt the light housing in the attic and is just warm. I also felt each wire going from light to light and it is cool to the touch.\n",
      "\n",
      "Cluster = 2, Raw data index = 6,276, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I have an odd wiring situation at one of my switches, and like a rookie took it all apart before taking a picture.I have 9 wires running into the box, 3 white, 3 black and 3 ground.The switch is a standard two-way that controls a light in the basement. This appears to be the start of the line, with another switch (controlling a different light) and an outlet further down the line. What's odd, is that one of the lines (BW pair) are both hot. As such, I can't figure out how this switch needs to be connected. Any thoughts?\n",
      "\n",
      "Cluster = 2, Raw data index = 63,446, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I have an existing three way switch hooked up already, it works fine. I would like to add another three way switch by connecting another switch to the existing three way switch. Can this be done with 14/2 romex between the two switches?\n",
      "\n",
      "Cluster = 2, Raw data index = 7,857, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "Can I temporarily ground an outlet by attaching a wire to its central screw and then to a grounding rod situated outside my house?  I want to use an electrical pressure washer, but it requires a ground that none of my outlets have.\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 3, Raw data index = 42,634, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I have designed an SQL aggregate function in Oracle that bitwise XORs all MD5 sums of the values stored in a column.For example, if my table is:+-----+----------+---------+| Key | Sequence |  Value  |+-----+----------+---------+|   1 |        1 | 'Hello' ||   1 |        2 | 'World' ||   2 |        1 | '1234'  ||   3 |        0 | (empty) ||   4 |        1 | 'Hello' ||   4 |        3 | 'World' |+-----+----------+---------+I can run the following query in Oracle:with t AS (select 1 key, 1 sequence, 'Hello' value FROM dual           union all select 1, 2, 'World' from dual           union all select 2, 1, '1234' from dual           union all select 3, 0, '' from dual /* ... */          )   select key, md5_agg(value) from t group by keyand get (unfortunately aggregate functions in Oracle ignore NULL values and '' is considered as NULL)+---+----------------------------------+|key| md5_agg(value)                   |+---+----------------------------------+| 1 | 7EBD0B1DA67F965F802D31DF25C4B321 || 2 | 81DC9BDB52D04DC20036DBD8313ED055 || 3 | 00000000000000000000000000000000 || 4 | 7EBD0B1DA67F965F802D31DF25C4B321 |+---+----------------------------------+I would like to use this approach to compare if the contents of some columns are equal when I compare subsets of the same table (think of finding duplicates in a complex structures that spans over multiple rows in the same table). Here with this results I know that I have the same subsets for keys 1 and 4.What are the limits of such an approach? Here are the ones I could list:This is interesting only if my column contains distinct values. If my columns contains twice the same string, the xor operation will be a no-op.Due to Oracle limitations, if my column contains empty values, they do not count.With those limitations in mind, is it still possible to infer, from two equal md5_agg results computed from distinct and non-empty values, that the original values make up the same sets?In order to reformulate, are there odds that the MD5 sums of distinct strings XOR to 0?\n",
      "\n",
      "Cluster = 3, Raw data index = 69,637, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "For the reasons I cannot go into details, I need to design my own protocol and overall security system which will be used to establish secure data exchange between various devices (most notably desktops of all three major OSes, Android and iOS devices and Raspberry Pi, with the possibility to extend it to other embedded systems). Since I wouldn't dare to do my own crypto algorithms implementation, this implies that I have to rely on tried and tested libraries available for those platforms (i.e. OpenSSL, BouncyCastle, CommonCrypto, …) so I settled with what they all support - RSA for signing/authentication, DHE/ECDHE for session establishment, AES for encryption, PBKDF2 for key derivation and SHA2 for general hashing needs. The key sizes and complexity will depend on the hardware ability of targeted platforms.Now, I've done a fair bit of implementations of existing protocols and I like to think that I know my way around cryptography and perils that await if not applied properly, however I wouldn't dare to consider myself a cryptography expert and thus I decided to query the hive mind. Of course, once everything completed it will be properly audited and tested, but for now I need to know if I'm on the right track, that I haven't done some glaring omissions and if it is possible to improve it even further.The system I'm building should both cover the storage on devices and the communication between them and to preserve forward and backward secrecy.For the storage part I plan to utilize AES in CBC mode, storing the randomly generated IVs with each individual encrypted file. The 'master' key itself will be randomly generated and also AES-encrypted using a key derived from the user's password using PBKDF2, stored along with the salt and iterations used in it. My main concern is the IV part as if generated randomly it might repeat thus compromising the encrypted files if they happen to be similar enough or even the same. It's quite a low chance buy I don't like leaving anything to chance so the question is - given that the IV is public knowledge anyway, is it safe to use incremental progression/timestamp as IV in this case?The communication part will be a bit trickier as the devices will never communicate directly - instead the data exchange between them will be relied through a third party database to which they periodically connect, which is one of the prime reasons I'm designing my own protocol. If we except this oddity, the data exchange itself should function quite the same as if they were communicating directly, namely the devices will establish a session each time they 'contact' each other and then use the session key for encryption.To establish a session I plan to use a variation of STS protocol adapted to this environment. The only oddity here is that in some instances only one of the parties involved in communication will posses the RSA key of the other so it won't be fully authenticated - my understanding is that even in this case no successful MITM attack can be performed as at least one of the parties will reject communication if the signature doesn't match. Is that a safe assumption?Once DH/ECDH keys are exchanged an actual session AES key will be derived from them using SHA2 and the rest of the data exchange will be encrypted using that key, again in CBC mode - until the session expires, when the process repeats. I'm still not clear on how to approach the message integrity and authenticity verification - at first I thought that signing the message with the device's RSA key will be enough, but since it may happen that only one of the parties has the other party's certificate I might add a HMAC alongside with the exchanged messages as well. What would be a recommended, cryptographically secure way to handle that?\n",
      "\n",
      "Cluster = 3, Raw data index = 86,569, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "Apple OS X can create encrypted AES 128/256 DMG volumes. Here is written about a men who was able to hack it. And also that DMGs use PBKDF2-HMAC-SHA-1. I couldn't find more information about encrypted DMGs. So does that mean that apples encrypted DMGs could be hacked?\n",
      "\n",
      "Cluster = 3, Raw data index = 9,433, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "Hashcash is a proof-of-work system in which the Sender needs to find $Y$ such as the first (let's say 20) bits of $H(X+Y)$ are zeros where $H$ is a one-way hash function, $X$ is a fixed value and $+$ means concatenation. The Sender starts with an initial random number $Y$. It then computes the hash of $X+Y$. If the first 20 bits of the hash are zeros, then $Y$ is an acceptable number. If not, then the sender increments the random number and tries again. Since about $1$ in $2^{20}$ headers will have $20$ zeros as the beginning of the hash, the sender will on average have to try $2^{20}$ random numbers to find a valid number.My question is: The average number of tries is $2^{20}$ but is there a number of tries after which Hashcash is guaranted to be solved?\n",
      "\n",
      "Cluster = 3, Raw data index = 28,252, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I've always been interested in encryption but I have never found a good explanation (beginners explanation) of how encryption with public key and decryption with private key works.How does it encrypt something with one key and decipher it with another key?\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 1, Raw data index = 33,566, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I'm a citizen of country X and have a valid United States ESTA in my X passport.  Recently, I became of citizen of Y and now have a Y passport as well, which I would like to use for future travel to the US.  Both countries qualify for the Visa Waiver Program.  Can I have ESTAs in both passports at the same time?The official CBP site seems contradictory, first implying that I should get a new ESTA:  If you obtain a new passport or change your name, gender or country of  citizenship, you will be required to apply for a new travel  authorization. This is also required if one of your answers to any of  the VWP eligibility questions changes. The associated fee of $14 will  be charged for each new application.And then saying that I should not have two simultaneous ESTAs:  If you have dual citizenship and have registered with ESTA, you should  use your VWP-eligible passport to board the plane when you leave your  country of departure and when you arrive in the U.S. If both your  countries of citizenship are VWP-eligible, then we strongly recommend  you choose which one you want to claim for purposes of travel to the  U.S., and use that country's passport each time you travel. One person  with two different ESTA authorizations creates confusion that will  only delay your travel.Cancelling the old ESTA would seem a valid way to fulfill both requirements, but there doesn't appear to be any way to do this?\n",
      "\n",
      "Cluster = 1, Raw data index = 48,613, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I am not sure this is the right place to ask this question but assuming any traveler might have come across this situation/have information,requesting to please guide.I had arrived USA 2 months before on B1/B2 visa.As I-94 forms are now paperless, i did not receive one at the time of arrival at USA airport. But i can see details of same on cbs.gov website. In paperless I-94, where do we need to return the form / do we need to return the form when I leave USA? I checked website but it had information regarding the case when paper I-94 is received.\n",
      "\n",
      "Cluster = 1, Raw data index = 55,030, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "My old passport have 2-year valid visa of DRCongo and it is expire on 04.06.2016. Now I am on holiday and going back at DRCongo on 01.05.2016. My old passport have remain 2 blank page so my boss told me to make new passport and I got a new passport.Will the immigration officer accept my visa if it is on my old passport?\n",
      "\n",
      "Cluster = 1, Raw data index = 49,361, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I am flying from London to Central America and back this summer on a bit of an extended holiday. I am considering stopping over in NYC on the way back for a few days. (My flight from Panama to London would be through NYC anyway and got offered a good deal by a travel agent.) I am residing in London as an EU citizen and I always use my EU passport to get around the world. However as I was born in the States I am also a fully fledged US citizen with the blue passport. The only time I've used my US passport in the past was for a US holiday a decade ago. I've never lived in the States so I don't sound American etc. I want to book my flights and travel around Central America using my EU passport for simplicity's sake. However I have come across on the US foreign office website a bit stating that US dual citizens can only enter and exit the State with a US passport. What should I do? I assume that I can't check into my flight on a European passport then enter and exit US border control with a US passport? Can I just ignore the fact that I've got a US passport and hope they don't clock on it? My EU passport will state my place of birth as the States but as I've said I don't sound American or anything. Is that risky? I don't want to be turned back at the gates on my first NYC trip!\n",
      "\n",
      "Cluster = 1, Raw data index = 55,078, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "My wife has a Schengen visa issued by the Italian consulate in the UK.It expires at the beginning of December, and as we want to travel to Europe for the Christmas holiday, we were hoping to cancel the current Schengen visa early in order to apply for another one in time.I have contacted the Italian consulate in London by email, and they have told me that they are unable to do this. After a quick search online, it seems other people have had more luck cancelling their visas. So my question is: has anyone cancelled a Schengen visa issued by Italy, and if so - how?\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 0, Raw data index = 81,864, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I live in the Midwest of the United States, and we not-too-rarely get a large amount of rain coming down at one time both in the spring and sometimes in the fall. Last night was no different (aside from random earthquakes..) than usual, but after I went to bed, my smoke alarm went off. I quickly determined that there was in fact no fire, so I went to take the smoke alarm off of its mounting and when I removed it, I found that there was a decent amount of water in the smoke detector. If I had to guess I'd say about 50 mL. So not a huge amount, but enough to set it off.I left it off for a time, and did not notice any more water coming from the opening in the ceiling (which is a recess where the detector and power wiring sits, not fully open to the attic (just where the wires come in, as far as I know. I didn't examine it terribly closely), even though it was still raining fairly hard (though not nearly as hard as it had been). This morning, I went to have a look around the attic to see if I could see anywhere it was leaking (it is still misting outside, but not raining any longer), but I was unable to detect any wet spots in the roof.What should my next step be? The roof (and indeed the house) is 1 year old, so I would hope that it hasn't sprung a leak, but I can't think of how else water would have gotten into the smoke detector. I also suspect paying someone to go and try to find a leak is going to be fairly expensive as well.The detector itself appears to be working. If I test it, and it functions, should I still replace it because of potential water damage?UpdateHere is a picture of the socket in question, and there is indeed cool air coming from it. I'm not totally convinced it is just condensation, elsewise this would have happened last year during the winter, I would think, but am unsure.\n",
      "\n",
      "Cluster = 0, Raw data index = 22,211, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "We discovered a bath tub leak from our second floor bathroom which dripped through the sidings. The bathroom has the original fixtures from 1989. It leaks when there's excess amount of water used.Would this be a simple problem of refinishing everything using plumber's putty?\n",
      "\n",
      "Cluster = 0, Raw data index = 74,198, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "The air quality in my basement is unpleasant. I don't know if I have mold. How to test for it? How is the smell of mold?I know that we had a water problem in the basement, the walls were cracked so every rainy day, we had humidity and water in the basement. But I have never seen signs of mold. How to check for mold?\n",
      "\n",
      "Cluster = 0, Raw data index = 44,660, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "Many instances of this worm-like creature were found in a water system for a mountain cabin in the Sierra Nevada mountains of the US, in late June / early July.  The water system collects water from an enclosed spring.  Can you help identify this creature?  Clues:The worms have two \"points\" on their heads. They can stretch out and be long and thin, or when poked (or are resting) they contract into a small blob.  Here is a picture of a single worm with markings shown.Here is a picture of a few worms, somewhat contracted. Here is a movie of them moving, in natural light.  Here is a movie of them moving, with backlight.Here are pictures of their undersides and their internal structures.Whenever I pull some out of the water and put them into a tupperware with the same water, they only survive for around 24 hours, after which they seem to disintegrate.  Here is a picture of about 20 of the worms after about 24 hours, the bulk of them have halfway-decomposed and form a heap in the upper right.  After another day it'll just look like debris in the water, you wouldn't even recognize that there were worms in it.  There is a piece of bacon in there because some suggested putting it there to test if they were leeches, but this disintegration happens repeatably and regardless of the bacon; please ignore the bacon.Someone suggested that they are trematodes, but there are no snails, frogs, or other creatures in the storage and collection sections of the water system;  we have looked very closely.  There may be something within a 30-foot section of pipe, but we doubt it.  Can you help us identify this creature?  Even just possible families of creatures or general categories would be helpful for us.\n",
      "\n",
      "Cluster = 0, Raw data index = 83,398, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I have a reliance model 5 30 NORS971 gas HOT WATER tank. The basement flooded a little and put out the pilot. When it would not light, I replaced the pilot tip and went ahead and replaced the thermocouple. All went well and it lit and fired the burner. One week later, the pilot would light but go out when button released. Replaced the gas control with one from another tank and it worked for about a week. The pressure relief was then leaking a little so replaced it. One more week and not working so bought new gas control and replaced and all lit.Now 2 weeks later, not working and pilot will light but, goes out on release. used multimeter and get 20 mv on thermocouple. What would be cause of gas controls burning out?\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 4, Raw data index = 63,096, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I bought a new house about a month ago, and have since noticed some plumbing issues in the laundry room:laundry tub drains slowlyoccasional \"musty\" smell, which seems to come from the drainsI did some research online and found that lack of drain ventilation could cause both of these problems. So I checked the plumbing and it looks like both the washing machine and adjacent wash basin drain into the same pipe. As far as I can tell, there is no ventilation on these drains (photo below); it looks like a stacked pair of S-traps.The laundry room is in a little addition at the back of the house. So I probably cannot tie this back in to the main house venting stack without a lot of work. I gather the simplest solution is to locally install an air admittance valve (AAV). Does that sound like a reasonable approach here?If so, am I on the right track with one of these:http://www.rona.ca/en/air-admittance-valvehttp://www.amazon.ca/gp/product/B000H5SLWM?psc=1&amp;redirect=true&amp;ref_=ox_sc_act_title_1&amp;smid=A23X8TYK8IHNZFMy plan is to remove the upper S-trap. Then install a sanitary T, going to: AAV (top) and P-trap (horizontal). Does that sound right?\n",
      "\n",
      "Cluster = 4, Raw data index = 31,500, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I have read a lot about proper insulation and ventilation, including some posts on this site, but none adequately answer my questions.My goal is to operate an electric heat source in the winter and have ~60 &deg;F temperature maintained when working in the garage.  In the summer, I think we will typically leave the garage door open, however it would be nice to one day have it stay cool in there if it's 90-100 &deg;F outside.This is in Ohio, where we typically have temps of 0-95 &deg;F throughout the year, it can also get pretty humid.I do not have soffit vents, but there is a ridge vent on the roof already installed.  I do not want to drywall nor do I want to build a ceiling.As you see in the photos I have already insulated the walls with R15 Batt installation.  Now I'm unsure where to go from here for roof 2x6's.  I bought some radiant barrier R11-equivelent insulation (seen in photos as well), which I was planning to attach to the end of the 2x6's above, which leaves plenty of ventilation behind them, should be \"ok\" in the winter and pretty decent in the summer.  However, not having soffit vents, I'm unsure if that is the proper use-case.You'll see from the wall install that I have no concerns about a vapor barrier, and do not care to seal my garage 100% (I only got faced insulation because it was cheaper =)  ).  However, I am concerned about mold/moisture problems in the space.  I would love some feedback as to the proper way to proceed here.  Ideally I can make use of my radiant barriers, and ideally I won't have to cut in soffit vents.Full resolution images here for reference: http://imgur.com/a/4Wd9Q and http://imgur.com/a/ud8os\n",
      "\n",
      "Cluster = 4, Raw data index = 8,153, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "What's the best way for a DIY granite counter top to be cut?  What tools do I need that will do the job without breaking the bank?\n",
      "\n",
      "Cluster = 4, Raw data index = 6,644, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I'm remodeling my bathroom and shower and I'll be replacing the insulation on the external wall. This wall is the \"back\" of the shower (opposite from where the water supply lines are). With this in mind, I should be able to just choose some insulation and then plop it in when I have the wall torn down.The main question and concern I have is about vapor barrier. I will be using cement board with a liquid topical membrane (like Redgard) for waterproofing the shower which means I'm not supposed to put a vapor barrier on the back side of the wall because it is bad to trap moisture. How does this affect insulating? Am I safe to nix the vapor barrier around the shower? What should I do for the rest of the bathroom?I'm not too concerned with price so if there are other options besides batting insulation (such as foam, etc...) that would solve my problem, I'm willing to hear those ideas as well.\n",
      "\n",
      "Cluster = 4, Raw data index = 65,112, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I am doing some minor renovations to my basement with the drop ceiling and found that one of the geniuses that owned the house before me, used fibreglass ceiling tiles to seal off an old vent for a gas fireplace. Obviously this will not do. I'm thinking of building a section of 2x4's around the old exhaust and then filling it with rigid foam and spray foam. I can't take the old exhaust off the side of the house, since it is a condo and I doubt that I'm going to convince them to replace the siding where this exhaust vent is, not to mention it will probably cost me. Open to any suggestions. I would post a pic but the settings don't allow it, kinda odd.\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 5, Raw data index = 15,061, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "It's always difficult to decide what clothes to take with you when you go to a new place. Usually I check Wikipedia to get an idea of approximate climate and weather conditions, but it often doesn't have much data besides average temperatures. Other factors, such as wind and precipitation, might enter into the equation, and the same temperature can \"feel like\" differently in two distinct locations.Perhaps not the same factors are important whether one travels to tropical/equatorial locations, or to temperate/subarctic places.So, in short:  If I travel to a new place, which weather factors should I look into to decide what to take with me?\n",
      "\n",
      "Cluster = 5, Raw data index = 65,232, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I see the TSA have brought in new rules for devices, in response to intelligence that terrorists may be trying to pack mobile phones with explosive, so checks before flights can include having to prove the device can power on.Although fearing the worst and allowing lots of extra time at airports, I have not yet encountered any checks of this sort over and above the usual taking devices out of bags so they can be scanned separately.From various news articles, there doesn't appear to be any consistent view as to what checks will be carried out.Can anyone here clarify what they do? Do you have to prove a phone can make a call, or just show it is powered on?\n",
      "\n",
      "Cluster = 5, Raw data index = 6,061, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "I'm planning to visit Medellin and Bogota sometime in the near future. I've a U.S. DL which endorses motorcycles. Is it legal to ride motorcycles in Colombia with a US driver's license? Is it required to carry any other identification other than the U.S. DL in case if I'm on the road?\n",
      "\n",
      "Cluster = 5, Raw data index = 11,890, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "The way I currently cook kidney beans is to soak them overnight. But still they have to be cooked for a long time on gas before they get tender enough to be edible.Anything that can be added or be done in a different way to reduce the time over heat?\n",
      "\n",
      "Cluster = 5, Raw data index = 57,730, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.85, 'vectorizer__min_df': 50}\n",
      "To quote Goodman &amp; Gilman :  An alternative way of defining the anesthetic state is to consider it  as a collection of “component” changes in behavior or perception. The  components of the anesthetic state include:  • amnesia  • immobility in  response to noxious stimulation  • attenuation of autonomic responses  to noxious stimulation  • analgesia  • unconsciousnessMy question is, does not the state of Unconsciousness already imply other components of analgesia and amnesia? Analgesia is the absence of the perception of pain, which is granted if there is unconsciousness which would be the absence of all perceptions. I am not certain if unconsciousness also entails amnesia, but it seems that remembering what happened when unconscious seems considerably unlikely.  Apart from a reductionist argument for minimizing the constraints required for classification as a general anesthetic, I am more interested in cases where unconsciousness would be achieved without analgesia or amnesia, which could be a likely rationale behind including the additional caveats in the definition.\n",
      "\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 2, Raw data index = 81,864, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I live in the Midwest of the United States, and we not-too-rarely get a large amount of rain coming down at one time both in the spring and sometimes in the fall. Last night was no different (aside from random earthquakes..) than usual, but after I went to bed, my smoke alarm went off. I quickly determined that there was in fact no fire, so I went to take the smoke alarm off of its mounting and when I removed it, I found that there was a decent amount of water in the smoke detector. If I had to guess I'd say about 50 mL. So not a huge amount, but enough to set it off.I left it off for a time, and did not notice any more water coming from the opening in the ceiling (which is a recess where the detector and power wiring sits, not fully open to the attic (just where the wires come in, as far as I know. I didn't examine it terribly closely), even though it was still raining fairly hard (though not nearly as hard as it had been). This morning, I went to have a look around the attic to see if I could see anywhere it was leaking (it is still misting outside, but not raining any longer), but I was unable to detect any wet spots in the roof.What should my next step be? The roof (and indeed the house) is 1 year old, so I would hope that it hasn't sprung a leak, but I can't think of how else water would have gotten into the smoke detector. I also suspect paying someone to go and try to find a leak is going to be fairly expensive as well.The detector itself appears to be working. If I test it, and it functions, should I still replace it because of potential water damage?UpdateHere is a picture of the socket in question, and there is indeed cool air coming from it. I'm not totally convinced it is just condensation, elsewise this would have happened last year during the winter, I would think, but am unsure.\n",
      "\n",
      "Cluster = 2, Raw data index = 22,211, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "We discovered a bath tub leak from our second floor bathroom which dripped through the sidings. The bathroom has the original fixtures from 1989. It leaks when there's excess amount of water used.Would this be a simple problem of refinishing everything using plumber's putty?\n",
      "\n",
      "Cluster = 2, Raw data index = 74,198, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "The air quality in my basement is unpleasant. I don't know if I have mold. How to test for it? How is the smell of mold?I know that we had a water problem in the basement, the walls were cracked so every rainy day, we had humidity and water in the basement. But I have never seen signs of mold. How to check for mold?\n",
      "\n",
      "Cluster = 2, Raw data index = 44,660, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "Many instances of this worm-like creature were found in a water system for a mountain cabin in the Sierra Nevada mountains of the US, in late June / early July.  The water system collects water from an enclosed spring.  Can you help identify this creature?  Clues:The worms have two \"points\" on their heads. They can stretch out and be long and thin, or when poked (or are resting) they contract into a small blob.  Here is a picture of a single worm with markings shown.Here is a picture of a few worms, somewhat contracted. Here is a movie of them moving, in natural light.  Here is a movie of them moving, with backlight.Here are pictures of their undersides and their internal structures.Whenever I pull some out of the water and put them into a tupperware with the same water, they only survive for around 24 hours, after which they seem to disintegrate.  Here is a picture of about 20 of the worms after about 24 hours, the bulk of them have halfway-decomposed and form a heap in the upper right.  After another day it'll just look like debris in the water, you wouldn't even recognize that there were worms in it.  There is a piece of bacon in there because some suggested putting it there to test if they were leeches, but this disintegration happens repeatably and regardless of the bacon; please ignore the bacon.Someone suggested that they are trematodes, but there are no snails, frogs, or other creatures in the storage and collection sections of the water system;  we have looked very closely.  There may be something within a 30-foot section of pipe, but we doubt it.  Can you help us identify this creature?  Even just possible families of creatures or general categories would be helpful for us.\n",
      "\n",
      "Cluster = 2, Raw data index = 45,540, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "People may tend to spend time in a hot water spring. Is it possible to get hyperthermia (like a sun stroke) due to this?\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 3, Raw data index = 63,096, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I bought a new house about a month ago, and have since noticed some plumbing issues in the laundry room:laundry tub drains slowlyoccasional \"musty\" smell, which seems to come from the drainsI did some research online and found that lack of drain ventilation could cause both of these problems. So I checked the plumbing and it looks like both the washing machine and adjacent wash basin drain into the same pipe. As far as I can tell, there is no ventilation on these drains (photo below); it looks like a stacked pair of S-traps.The laundry room is in a little addition at the back of the house. So I probably cannot tie this back in to the main house venting stack without a lot of work. I gather the simplest solution is to locally install an air admittance valve (AAV). Does that sound like a reasonable approach here?If so, am I on the right track with one of these:http://www.rona.ca/en/air-admittance-valvehttp://www.amazon.ca/gp/product/B000H5SLWM?psc=1&amp;redirect=true&amp;ref_=ox_sc_act_title_1&amp;smid=A23X8TYK8IHNZFMy plan is to remove the upper S-trap. Then install a sanitary T, going to: AAV (top) and P-trap (horizontal). Does that sound right?\n",
      "\n",
      "Cluster = 3, Raw data index = 31,500, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I have read a lot about proper insulation and ventilation, including some posts on this site, but none adequately answer my questions.My goal is to operate an electric heat source in the winter and have ~60 &deg;F temperature maintained when working in the garage.  In the summer, I think we will typically leave the garage door open, however it would be nice to one day have it stay cool in there if it's 90-100 &deg;F outside.This is in Ohio, where we typically have temps of 0-95 &deg;F throughout the year, it can also get pretty humid.I do not have soffit vents, but there is a ridge vent on the roof already installed.  I do not want to drywall nor do I want to build a ceiling.As you see in the photos I have already insulated the walls with R15 Batt installation.  Now I'm unsure where to go from here for roof 2x6's.  I bought some radiant barrier R11-equivelent insulation (seen in photos as well), which I was planning to attach to the end of the 2x6's above, which leaves plenty of ventilation behind them, should be \"ok\" in the winter and pretty decent in the summer.  However, not having soffit vents, I'm unsure if that is the proper use-case.You'll see from the wall install that I have no concerns about a vapor barrier, and do not care to seal my garage 100% (I only got faced insulation because it was cheaper =)  ).  However, I am concerned about mold/moisture problems in the space.  I would love some feedback as to the proper way to proceed here.  Ideally I can make use of my radiant barriers, and ideally I won't have to cut in soffit vents.Full resolution images here for reference: http://imgur.com/a/4Wd9Q and http://imgur.com/a/ud8os\n",
      "\n",
      "Cluster = 3, Raw data index = 8,153, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "What's the best way for a DIY granite counter top to be cut?  What tools do I need that will do the job without breaking the bank?\n",
      "\n",
      "Cluster = 3, Raw data index = 6,644, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I'm remodeling my bathroom and shower and I'll be replacing the insulation on the external wall. This wall is the \"back\" of the shower (opposite from where the water supply lines are). With this in mind, I should be able to just choose some insulation and then plop it in when I have the wall torn down.The main question and concern I have is about vapor barrier. I will be using cement board with a liquid topical membrane (like Redgard) for waterproofing the shower which means I'm not supposed to put a vapor barrier on the back side of the wall because it is bad to trap moisture. How does this affect insulating? Am I safe to nix the vapor barrier around the shower? What should I do for the rest of the bathroom?I'm not too concerned with price so if there are other options besides batting insulation (such as foam, etc...) that would solve my problem, I'm willing to hear those ideas as well.\n",
      "\n",
      "Cluster = 3, Raw data index = 65,112, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I am doing some minor renovations to my basement with the drop ceiling and found that one of the geniuses that owned the house before me, used fibreglass ceiling tiles to seal off an old vent for a gas fireplace. Obviously this will not do. I'm thinking of building a section of 2x4's around the old exhaust and then filling it with rigid foam and spray foam. I can't take the old exhaust off the side of the house, since it is a condo and I doubt that I'm going to convince them to replace the siding where this exhaust vent is, not to mention it will probably cost me. Open to any suggestions. I would post a pic but the settings don't allow it, kinda odd.\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 1, Raw data index = 60,884, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I'm trying to put my RV into the breaker box I've got a 30 amp breaker double pole I've got10/2 wire, do I use a single pole or double pole 30 amp breaker hand my RV plug is a 4 prong plug how do I make this work\n",
      "\n",
      "Cluster = 1, Raw data index = 62,339, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I just installed 6 new 4\" halo can lights. When they are on I can smell a slight odor coming from them in the attic. Is this normal? I felt the light housing in the attic and is just warm. I also felt each wire going from light to light and it is cool to the touch.\n",
      "\n",
      "Cluster = 1, Raw data index = 6,276, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I have an odd wiring situation at one of my switches, and like a rookie took it all apart before taking a picture.I have 9 wires running into the box, 3 white, 3 black and 3 ground.The switch is a standard two-way that controls a light in the basement. This appears to be the start of the line, with another switch (controlling a different light) and an outlet further down the line. What's odd, is that one of the lines (BW pair) are both hot. As such, I can't figure out how this switch needs to be connected. Any thoughts?\n",
      "\n",
      "Cluster = 1, Raw data index = 63,446, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I have an existing three way switch hooked up already, it works fine. I would like to add another three way switch by connecting another switch to the existing three way switch. Can this be done with 14/2 romex between the two switches?\n",
      "\n",
      "Cluster = 1, Raw data index = 7,857, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "Can I temporarily ground an outlet by attaching a wire to its central screw and then to a grounding rod situated outside my house?  I want to use an electrical pressure washer, but it requires a ground that none of my outlets have.\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 0, Raw data index = 33,566, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I'm a citizen of country X and have a valid United States ESTA in my X passport.  Recently, I became of citizen of Y and now have a Y passport as well, which I would like to use for future travel to the US.  Both countries qualify for the Visa Waiver Program.  Can I have ESTAs in both passports at the same time?The official CBP site seems contradictory, first implying that I should get a new ESTA:  If you obtain a new passport or change your name, gender or country of  citizenship, you will be required to apply for a new travel  authorization. This is also required if one of your answers to any of  the VWP eligibility questions changes. The associated fee of $14 will  be charged for each new application.And then saying that I should not have two simultaneous ESTAs:  If you have dual citizenship and have registered with ESTA, you should  use your VWP-eligible passport to board the plane when you leave your  country of departure and when you arrive in the U.S. If both your  countries of citizenship are VWP-eligible, then we strongly recommend  you choose which one you want to claim for purposes of travel to the  U.S., and use that country's passport each time you travel. One person  with two different ESTA authorizations creates confusion that will  only delay your travel.Cancelling the old ESTA would seem a valid way to fulfill both requirements, but there doesn't appear to be any way to do this?\n",
      "\n",
      "Cluster = 0, Raw data index = 48,613, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I am not sure this is the right place to ask this question but assuming any traveler might have come across this situation/have information,requesting to please guide.I had arrived USA 2 months before on B1/B2 visa.As I-94 forms are now paperless, i did not receive one at the time of arrival at USA airport. But i can see details of same on cbs.gov website. In paperless I-94, where do we need to return the form / do we need to return the form when I leave USA? I checked website but it had information regarding the case when paper I-94 is received.\n",
      "\n",
      "Cluster = 0, Raw data index = 55,030, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "My old passport have 2-year valid visa of DRCongo and it is expire on 04.06.2016. Now I am on holiday and going back at DRCongo on 01.05.2016. My old passport have remain 2 blank page so my boss told me to make new passport and I got a new passport.Will the immigration officer accept my visa if it is on my old passport?\n",
      "\n",
      "Cluster = 0, Raw data index = 49,361, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I am flying from London to Central America and back this summer on a bit of an extended holiday. I am considering stopping over in NYC on the way back for a few days. (My flight from Panama to London would be through NYC anyway and got offered a good deal by a travel agent.) I am residing in London as an EU citizen and I always use my EU passport to get around the world. However as I was born in the States I am also a fully fledged US citizen with the blue passport. The only time I've used my US passport in the past was for a US holiday a decade ago. I've never lived in the States so I don't sound American etc. I want to book my flights and travel around Central America using my EU passport for simplicity's sake. However I have come across on the US foreign office website a bit stating that US dual citizens can only enter and exit the State with a US passport. What should I do? I assume that I can't check into my flight on a European passport then enter and exit US border control with a US passport? Can I just ignore the fact that I've got a US passport and hope they don't clock on it? My EU passport will state my place of birth as the States but as I've said I don't sound American or anything. Is that risky? I don't want to be turned back at the gates on my first NYC trip!\n",
      "\n",
      "Cluster = 0, Raw data index = 55,078, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "My wife has a Schengen visa issued by the Italian consulate in the UK.It expires at the beginning of December, and as we want to travel to Europe for the Christmas holiday, we were hoping to cancel the current Schengen visa early in order to apply for another one in time.I have contacted the Italian consulate in London by email, and they have told me that they are unable to do this. After a quick search online, it seems other people have had more luck cancelling their visas. So my question is: has anyone cancelled a Schengen visa issued by Italy, and if so - how?\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 4, Raw data index = 15,061, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "It's always difficult to decide what clothes to take with you when you go to a new place. Usually I check Wikipedia to get an idea of approximate climate and weather conditions, but it often doesn't have much data besides average temperatures. Other factors, such as wind and precipitation, might enter into the equation, and the same temperature can \"feel like\" differently in two distinct locations.Perhaps not the same factors are important whether one travels to tropical/equatorial locations, or to temperate/subarctic places.So, in short:  If I travel to a new place, which weather factors should I look into to decide what to take with me?\n",
      "\n",
      "Cluster = 4, Raw data index = 65,232, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I see the TSA have brought in new rules for devices, in response to intelligence that terrorists may be trying to pack mobile phones with explosive, so checks before flights can include having to prove the device can power on.Although fearing the worst and allowing lots of extra time at airports, I have not yet encountered any checks of this sort over and above the usual taking devices out of bags so they can be scanned separately.From various news articles, there doesn't appear to be any consistent view as to what checks will be carried out.Can anyone here clarify what they do? Do you have to prove a phone can make a call, or just show it is powered on?\n",
      "\n",
      "Cluster = 4, Raw data index = 6,061, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I'm planning to visit Medellin and Bogota sometime in the near future. I've a U.S. DL which endorses motorcycles. Is it legal to ride motorcycles in Colombia with a US driver's license? Is it required to carry any other identification other than the U.S. DL in case if I'm on the road?\n",
      "\n",
      "Cluster = 4, Raw data index = 11,890, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "The way I currently cook kidney beans is to soak them overnight. But still they have to be cooked for a long time on gas before they get tender enough to be edible.Anything that can be added or be done in a different way to reduce the time over heat?\n",
      "\n",
      "Cluster = 4, Raw data index = 57,730, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "To quote Goodman &amp; Gilman :  An alternative way of defining the anesthetic state is to consider it  as a collection of “component” changes in behavior or perception. The  components of the anesthetic state include:  • amnesia  • immobility in  response to noxious stimulation  • attenuation of autonomic responses  to noxious stimulation  • analgesia  • unconsciousnessMy question is, does not the state of Unconsciousness already imply other components of analgesia and amnesia? Analgesia is the absence of the perception of pain, which is granted if there is unconsciousness which would be the absence of all perceptions. I am not certain if unconsciousness also entails amnesia, but it seems that remembering what happened when unconscious seems considerably unlikely.  Apart from a reductionist argument for minimizing the constraints required for classification as a general anesthetic, I am more interested in cases where unconsciousness would be achieved without analgesia or amnesia, which could be a likely rationale behind including the additional caveats in the definition.\n",
      "\n",
      "Cluster 0: visa, passport, uk, schengen, us, travel, days, need, transit, visit\n",
      "Cluster 1: wire, switch, light, wires, box, breaker, fan, outlet, ground, black\n",
      "Cluster 2: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 3: wall, house, floor, door, would, wood, concrete, like, paint, room\n",
      "Cluster 4: would, like, one, know, use, get, time, make, find, way\n",
      "Cluster 5: key, encryption, message, hash, public, aes, cipher, keys, data, random\n",
      "\n",
      "Cluster = 5, Raw data index = 42,634, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I have designed an SQL aggregate function in Oracle that bitwise XORs all MD5 sums of the values stored in a column.For example, if my table is:+-----+----------+---------+| Key | Sequence |  Value  |+-----+----------+---------+|   1 |        1 | 'Hello' ||   1 |        2 | 'World' ||   2 |        1 | '1234'  ||   3 |        0 | (empty) ||   4 |        1 | 'Hello' ||   4 |        3 | 'World' |+-----+----------+---------+I can run the following query in Oracle:with t AS (select 1 key, 1 sequence, 'Hello' value FROM dual           union all select 1, 2, 'World' from dual           union all select 2, 1, '1234' from dual           union all select 3, 0, '' from dual /* ... */          )   select key, md5_agg(value) from t group by keyand get (unfortunately aggregate functions in Oracle ignore NULL values and '' is considered as NULL)+---+----------------------------------+|key| md5_agg(value)                   |+---+----------------------------------+| 1 | 7EBD0B1DA67F965F802D31DF25C4B321 || 2 | 81DC9BDB52D04DC20036DBD8313ED055 || 3 | 00000000000000000000000000000000 || 4 | 7EBD0B1DA67F965F802D31DF25C4B321 |+---+----------------------------------+I would like to use this approach to compare if the contents of some columns are equal when I compare subsets of the same table (think of finding duplicates in a complex structures that spans over multiple rows in the same table). Here with this results I know that I have the same subsets for keys 1 and 4.What are the limits of such an approach? Here are the ones I could list:This is interesting only if my column contains distinct values. If my columns contains twice the same string, the xor operation will be a no-op.Due to Oracle limitations, if my column contains empty values, they do not count.With those limitations in mind, is it still possible to infer, from two equal md5_agg results computed from distinct and non-empty values, that the original values make up the same sets?In order to reformulate, are there odds that the MD5 sums of distinct strings XOR to 0?\n",
      "\n",
      "Cluster = 5, Raw data index = 69,637, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "For the reasons I cannot go into details, I need to design my own protocol and overall security system which will be used to establish secure data exchange between various devices (most notably desktops of all three major OSes, Android and iOS devices and Raspberry Pi, with the possibility to extend it to other embedded systems). Since I wouldn't dare to do my own crypto algorithms implementation, this implies that I have to rely on tried and tested libraries available for those platforms (i.e. OpenSSL, BouncyCastle, CommonCrypto, …) so I settled with what they all support - RSA for signing/authentication, DHE/ECDHE for session establishment, AES for encryption, PBKDF2 for key derivation and SHA2 for general hashing needs. The key sizes and complexity will depend on the hardware ability of targeted platforms.Now, I've done a fair bit of implementations of existing protocols and I like to think that I know my way around cryptography and perils that await if not applied properly, however I wouldn't dare to consider myself a cryptography expert and thus I decided to query the hive mind. Of course, once everything completed it will be properly audited and tested, but for now I need to know if I'm on the right track, that I haven't done some glaring omissions and if it is possible to improve it even further.The system I'm building should both cover the storage on devices and the communication between them and to preserve forward and backward secrecy.For the storage part I plan to utilize AES in CBC mode, storing the randomly generated IVs with each individual encrypted file. The 'master' key itself will be randomly generated and also AES-encrypted using a key derived from the user's password using PBKDF2, stored along with the salt and iterations used in it. My main concern is the IV part as if generated randomly it might repeat thus compromising the encrypted files if they happen to be similar enough or even the same. It's quite a low chance buy I don't like leaving anything to chance so the question is - given that the IV is public knowledge anyway, is it safe to use incremental progression/timestamp as IV in this case?The communication part will be a bit trickier as the devices will never communicate directly - instead the data exchange between them will be relied through a third party database to which they periodically connect, which is one of the prime reasons I'm designing my own protocol. If we except this oddity, the data exchange itself should function quite the same as if they were communicating directly, namely the devices will establish a session each time they 'contact' each other and then use the session key for encryption.To establish a session I plan to use a variation of STS protocol adapted to this environment. The only oddity here is that in some instances only one of the parties involved in communication will posses the RSA key of the other so it won't be fully authenticated - my understanding is that even in this case no successful MITM attack can be performed as at least one of the parties will reject communication if the signature doesn't match. Is that a safe assumption?Once DH/ECDH keys are exchanged an actual session AES key will be derived from them using SHA2 and the rest of the data exchange will be encrypted using that key, again in CBC mode - until the session expires, when the process repeats. I'm still not clear on how to approach the message integrity and authenticity verification - at first I thought that signing the message with the device's RSA key will be enough, but since it may happen that only one of the parties has the other party's certificate I might add a HMAC alongside with the exchanged messages as well. What would be a recommended, cryptographically secure way to handle that?\n",
      "\n",
      "Cluster = 5, Raw data index = 86,569, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "Apple OS X can create encrypted AES 128/256 DMG volumes. Here is written about a men who was able to hack it. And also that DMGs use PBKDF2-HMAC-SHA-1. I couldn't find more information about encrypted DMGs. So does that mean that apples encrypted DMGs could be hacked?\n",
      "\n",
      "Cluster = 5, Raw data index = 9,433, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "Hashcash is a proof-of-work system in which the Sender needs to find $Y$ such as the first (let's say 20) bits of $H(X+Y)$ are zeros where $H$ is a one-way hash function, $X$ is a fixed value and $+$ means concatenation. The Sender starts with an initial random number $Y$. It then computes the hash of $X+Y$. If the first 20 bits of the hash are zeros, then $Y$ is an acceptable number. If not, then the sender increments the random number and tries again. Since about $1$ in $2^{20}$ headers will have $20$ zeros as the beginning of the hash, the sender will on average have to try $2^{20}$ random numbers to find a valid number.My question is: The average number of tries is $2^{20}$ but is there a number of tries after which Hashcash is guaranted to be solved?\n",
      "\n",
      "Cluster = 5, Raw data index = 28,252, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 15}\n",
      "I've always been interested in encryption but I have never found a good explanation (beginners explanation) of how encryption with public key and decryption with private key works.How does it encrypt something with one key and decipher it with another key?\n",
      "\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 2, Raw data index = 60,884, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I'm trying to put my RV into the breaker box I've got a 30 amp breaker double pole I've got10/2 wire, do I use a single pole or double pole 30 amp breaker hand my RV plug is a 4 prong plug how do I make this work\n",
      "\n",
      "Cluster = 2, Raw data index = 62,339, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I just installed 6 new 4\" halo can lights. When they are on I can smell a slight odor coming from them in the attic. Is this normal? I felt the light housing in the attic and is just warm. I also felt each wire going from light to light and it is cool to the touch.\n",
      "\n",
      "Cluster = 2, Raw data index = 6,276, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I have an odd wiring situation at one of my switches, and like a rookie took it all apart before taking a picture.I have 9 wires running into the box, 3 white, 3 black and 3 ground.The switch is a standard two-way that controls a light in the basement. This appears to be the start of the line, with another switch (controlling a different light) and an outlet further down the line. What's odd, is that one of the lines (BW pair) are both hot. As such, I can't figure out how this switch needs to be connected. Any thoughts?\n",
      "\n",
      "Cluster = 2, Raw data index = 63,446, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I have an existing three way switch hooked up already, it works fine. I would like to add another three way switch by connecting another switch to the existing three way switch. Can this be done with 14/2 romex between the two switches?\n",
      "\n",
      "Cluster = 2, Raw data index = 7,857, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "Can I temporarily ground an outlet by attaching a wire to its central screw and then to a grounding rod situated outside my house?  I want to use an electrical pressure washer, but it requires a ground that none of my outlets have.\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 3, Raw data index = 42,634, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I have designed an SQL aggregate function in Oracle that bitwise XORs all MD5 sums of the values stored in a column.For example, if my table is:+-----+----------+---------+| Key | Sequence |  Value  |+-----+----------+---------+|   1 |        1 | 'Hello' ||   1 |        2 | 'World' ||   2 |        1 | '1234'  ||   3 |        0 | (empty) ||   4 |        1 | 'Hello' ||   4 |        3 | 'World' |+-----+----------+---------+I can run the following query in Oracle:with t AS (select 1 key, 1 sequence, 'Hello' value FROM dual           union all select 1, 2, 'World' from dual           union all select 2, 1, '1234' from dual           union all select 3, 0, '' from dual /* ... */          )   select key, md5_agg(value) from t group by keyand get (unfortunately aggregate functions in Oracle ignore NULL values and '' is considered as NULL)+---+----------------------------------+|key| md5_agg(value)                   |+---+----------------------------------+| 1 | 7EBD0B1DA67F965F802D31DF25C4B321 || 2 | 81DC9BDB52D04DC20036DBD8313ED055 || 3 | 00000000000000000000000000000000 || 4 | 7EBD0B1DA67F965F802D31DF25C4B321 |+---+----------------------------------+I would like to use this approach to compare if the contents of some columns are equal when I compare subsets of the same table (think of finding duplicates in a complex structures that spans over multiple rows in the same table). Here with this results I know that I have the same subsets for keys 1 and 4.What are the limits of such an approach? Here are the ones I could list:This is interesting only if my column contains distinct values. If my columns contains twice the same string, the xor operation will be a no-op.Due to Oracle limitations, if my column contains empty values, they do not count.With those limitations in mind, is it still possible to infer, from two equal md5_agg results computed from distinct and non-empty values, that the original values make up the same sets?In order to reformulate, are there odds that the MD5 sums of distinct strings XOR to 0?\n",
      "\n",
      "Cluster = 3, Raw data index = 69,637, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "For the reasons I cannot go into details, I need to design my own protocol and overall security system which will be used to establish secure data exchange between various devices (most notably desktops of all three major OSes, Android and iOS devices and Raspberry Pi, with the possibility to extend it to other embedded systems). Since I wouldn't dare to do my own crypto algorithms implementation, this implies that I have to rely on tried and tested libraries available for those platforms (i.e. OpenSSL, BouncyCastle, CommonCrypto, …) so I settled with what they all support - RSA for signing/authentication, DHE/ECDHE for session establishment, AES for encryption, PBKDF2 for key derivation and SHA2 for general hashing needs. The key sizes and complexity will depend on the hardware ability of targeted platforms.Now, I've done a fair bit of implementations of existing protocols and I like to think that I know my way around cryptography and perils that await if not applied properly, however I wouldn't dare to consider myself a cryptography expert and thus I decided to query the hive mind. Of course, once everything completed it will be properly audited and tested, but for now I need to know if I'm on the right track, that I haven't done some glaring omissions and if it is possible to improve it even further.The system I'm building should both cover the storage on devices and the communication between them and to preserve forward and backward secrecy.For the storage part I plan to utilize AES in CBC mode, storing the randomly generated IVs with each individual encrypted file. The 'master' key itself will be randomly generated and also AES-encrypted using a key derived from the user's password using PBKDF2, stored along with the salt and iterations used in it. My main concern is the IV part as if generated randomly it might repeat thus compromising the encrypted files if they happen to be similar enough or even the same. It's quite a low chance buy I don't like leaving anything to chance so the question is - given that the IV is public knowledge anyway, is it safe to use incremental progression/timestamp as IV in this case?The communication part will be a bit trickier as the devices will never communicate directly - instead the data exchange between them will be relied through a third party database to which they periodically connect, which is one of the prime reasons I'm designing my own protocol. If we except this oddity, the data exchange itself should function quite the same as if they were communicating directly, namely the devices will establish a session each time they 'contact' each other and then use the session key for encryption.To establish a session I plan to use a variation of STS protocol adapted to this environment. The only oddity here is that in some instances only one of the parties involved in communication will posses the RSA key of the other so it won't be fully authenticated - my understanding is that even in this case no successful MITM attack can be performed as at least one of the parties will reject communication if the signature doesn't match. Is that a safe assumption?Once DH/ECDH keys are exchanged an actual session AES key will be derived from them using SHA2 and the rest of the data exchange will be encrypted using that key, again in CBC mode - until the session expires, when the process repeats. I'm still not clear on how to approach the message integrity and authenticity verification - at first I thought that signing the message with the device's RSA key will be enough, but since it may happen that only one of the parties has the other party's certificate I might add a HMAC alongside with the exchanged messages as well. What would be a recommended, cryptographically secure way to handle that?\n",
      "\n",
      "Cluster = 3, Raw data index = 86,569, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "Apple OS X can create encrypted AES 128/256 DMG volumes. Here is written about a men who was able to hack it. And also that DMGs use PBKDF2-HMAC-SHA-1. I couldn't find more information about encrypted DMGs. So does that mean that apples encrypted DMGs could be hacked?\n",
      "\n",
      "Cluster = 3, Raw data index = 9,433, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "Hashcash is a proof-of-work system in which the Sender needs to find $Y$ such as the first (let's say 20) bits of $H(X+Y)$ are zeros where $H$ is a one-way hash function, $X$ is a fixed value and $+$ means concatenation. The Sender starts with an initial random number $Y$. It then computes the hash of $X+Y$. If the first 20 bits of the hash are zeros, then $Y$ is an acceptable number. If not, then the sender increments the random number and tries again. Since about $1$ in $2^{20}$ headers will have $20$ zeros as the beginning of the hash, the sender will on average have to try $2^{20}$ random numbers to find a valid number.My question is: The average number of tries is $2^{20}$ but is there a number of tries after which Hashcash is guaranted to be solved?\n",
      "\n",
      "Cluster = 3, Raw data index = 28,252, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I've always been interested in encryption but I have never found a good explanation (beginners explanation) of how encryption with public key and decryption with private key works.How does it encrypt something with one key and decipher it with another key?\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 1, Raw data index = 33,566, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I'm a citizen of country X and have a valid United States ESTA in my X passport.  Recently, I became of citizen of Y and now have a Y passport as well, which I would like to use for future travel to the US.  Both countries qualify for the Visa Waiver Program.  Can I have ESTAs in both passports at the same time?The official CBP site seems contradictory, first implying that I should get a new ESTA:  If you obtain a new passport or change your name, gender or country of  citizenship, you will be required to apply for a new travel  authorization. This is also required if one of your answers to any of  the VWP eligibility questions changes. The associated fee of $14 will  be charged for each new application.And then saying that I should not have two simultaneous ESTAs:  If you have dual citizenship and have registered with ESTA, you should  use your VWP-eligible passport to board the plane when you leave your  country of departure and when you arrive in the U.S. If both your  countries of citizenship are VWP-eligible, then we strongly recommend  you choose which one you want to claim for purposes of travel to the  U.S., and use that country's passport each time you travel. One person  with two different ESTA authorizations creates confusion that will  only delay your travel.Cancelling the old ESTA would seem a valid way to fulfill both requirements, but there doesn't appear to be any way to do this?\n",
      "\n",
      "Cluster = 1, Raw data index = 48,613, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I am not sure this is the right place to ask this question but assuming any traveler might have come across this situation/have information,requesting to please guide.I had arrived USA 2 months before on B1/B2 visa.As I-94 forms are now paperless, i did not receive one at the time of arrival at USA airport. But i can see details of same on cbs.gov website. In paperless I-94, where do we need to return the form / do we need to return the form when I leave USA? I checked website but it had information regarding the case when paper I-94 is received.\n",
      "\n",
      "Cluster = 1, Raw data index = 55,030, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "My old passport have 2-year valid visa of DRCongo and it is expire on 04.06.2016. Now I am on holiday and going back at DRCongo on 01.05.2016. My old passport have remain 2 blank page so my boss told me to make new passport and I got a new passport.Will the immigration officer accept my visa if it is on my old passport?\n",
      "\n",
      "Cluster = 1, Raw data index = 49,361, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I am flying from London to Central America and back this summer on a bit of an extended holiday. I am considering stopping over in NYC on the way back for a few days. (My flight from Panama to London would be through NYC anyway and got offered a good deal by a travel agent.) I am residing in London as an EU citizen and I always use my EU passport to get around the world. However as I was born in the States I am also a fully fledged US citizen with the blue passport. The only time I've used my US passport in the past was for a US holiday a decade ago. I've never lived in the States so I don't sound American etc. I want to book my flights and travel around Central America using my EU passport for simplicity's sake. However I have come across on the US foreign office website a bit stating that US dual citizens can only enter and exit the State with a US passport. What should I do? I assume that I can't check into my flight on a European passport then enter and exit US border control with a US passport? Can I just ignore the fact that I've got a US passport and hope they don't clock on it? My EU passport will state my place of birth as the States but as I've said I don't sound American or anything. Is that risky? I don't want to be turned back at the gates on my first NYC trip!\n",
      "\n",
      "Cluster = 1, Raw data index = 55,078, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "My wife has a Schengen visa issued by the Italian consulate in the UK.It expires at the beginning of December, and as we want to travel to Europe for the Christmas holiday, we were hoping to cancel the current Schengen visa early in order to apply for another one in time.I have contacted the Italian consulate in London by email, and they have told me that they are unable to do this. After a quick search online, it seems other people have had more luck cancelling their visas. So my question is: has anyone cancelled a Schengen visa issued by Italy, and if so - how?\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 0, Raw data index = 81,864, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I live in the Midwest of the United States, and we not-too-rarely get a large amount of rain coming down at one time both in the spring and sometimes in the fall. Last night was no different (aside from random earthquakes..) than usual, but after I went to bed, my smoke alarm went off. I quickly determined that there was in fact no fire, so I went to take the smoke alarm off of its mounting and when I removed it, I found that there was a decent amount of water in the smoke detector. If I had to guess I'd say about 50 mL. So not a huge amount, but enough to set it off.I left it off for a time, and did not notice any more water coming from the opening in the ceiling (which is a recess where the detector and power wiring sits, not fully open to the attic (just where the wires come in, as far as I know. I didn't examine it terribly closely), even though it was still raining fairly hard (though not nearly as hard as it had been). This morning, I went to have a look around the attic to see if I could see anywhere it was leaking (it is still misting outside, but not raining any longer), but I was unable to detect any wet spots in the roof.What should my next step be? The roof (and indeed the house) is 1 year old, so I would hope that it hasn't sprung a leak, but I can't think of how else water would have gotten into the smoke detector. I also suspect paying someone to go and try to find a leak is going to be fairly expensive as well.The detector itself appears to be working. If I test it, and it functions, should I still replace it because of potential water damage?UpdateHere is a picture of the socket in question, and there is indeed cool air coming from it. I'm not totally convinced it is just condensation, elsewise this would have happened last year during the winter, I would think, but am unsure.\n",
      "\n",
      "Cluster = 0, Raw data index = 22,211, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "We discovered a bath tub leak from our second floor bathroom which dripped through the sidings. The bathroom has the original fixtures from 1989. It leaks when there's excess amount of water used.Would this be a simple problem of refinishing everything using plumber's putty?\n",
      "\n",
      "Cluster = 0, Raw data index = 74,198, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "The air quality in my basement is unpleasant. I don't know if I have mold. How to test for it? How is the smell of mold?I know that we had a water problem in the basement, the walls were cracked so every rainy day, we had humidity and water in the basement. But I have never seen signs of mold. How to check for mold?\n",
      "\n",
      "Cluster = 0, Raw data index = 44,660, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "Many instances of this worm-like creature were found in a water system for a mountain cabin in the Sierra Nevada mountains of the US, in late June / early July.  The water system collects water from an enclosed spring.  Can you help identify this creature?  Clues:The worms have two \"points\" on their heads. They can stretch out and be long and thin, or when poked (or are resting) they contract into a small blob.  Here is a picture of a single worm with markings shown.Here is a picture of a few worms, somewhat contracted. Here is a movie of them moving, in natural light.  Here is a movie of them moving, with backlight.Here are pictures of their undersides and their internal structures.Whenever I pull some out of the water and put them into a tupperware with the same water, they only survive for around 24 hours, after which they seem to disintegrate.  Here is a picture of about 20 of the worms after about 24 hours, the bulk of them have halfway-decomposed and form a heap in the upper right.  After another day it'll just look like debris in the water, you wouldn't even recognize that there were worms in it.  There is a piece of bacon in there because some suggested putting it there to test if they were leeches, but this disintegration happens repeatably and regardless of the bacon; please ignore the bacon.Someone suggested that they are trematodes, but there are no snails, frogs, or other creatures in the storage and collection sections of the water system;  we have looked very closely.  There may be something within a 30-foot section of pipe, but we doubt it.  Can you help us identify this creature?  Even just possible families of creatures or general categories would be helpful for us.\n",
      "\n",
      "Cluster = 0, Raw data index = 83,398, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I have a reliance model 5 30 NORS971 gas HOT WATER tank. The basement flooded a little and put out the pilot. When it would not light, I replaced the pilot tip and went ahead and replaced the thermocouple. All went well and it lit and fired the burner. One week later, the pilot would light but go out when button released. Replaced the gas control with one from another tank and it worked for about a week. The pressure relief was then leaking a little so replaced it. One more week and not working so bought new gas control and replaced and all lit.Now 2 weeks later, not working and pilot will light but, goes out on release. used multimeter and get 20 mv on thermocouple. What would be cause of gas controls burning out?\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 4, Raw data index = 63,096, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I bought a new house about a month ago, and have since noticed some plumbing issues in the laundry room:laundry tub drains slowlyoccasional \"musty\" smell, which seems to come from the drainsI did some research online and found that lack of drain ventilation could cause both of these problems. So I checked the plumbing and it looks like both the washing machine and adjacent wash basin drain into the same pipe. As far as I can tell, there is no ventilation on these drains (photo below); it looks like a stacked pair of S-traps.The laundry room is in a little addition at the back of the house. So I probably cannot tie this back in to the main house venting stack without a lot of work. I gather the simplest solution is to locally install an air admittance valve (AAV). Does that sound like a reasonable approach here?If so, am I on the right track with one of these:http://www.rona.ca/en/air-admittance-valvehttp://www.amazon.ca/gp/product/B000H5SLWM?psc=1&amp;redirect=true&amp;ref_=ox_sc_act_title_1&amp;smid=A23X8TYK8IHNZFMy plan is to remove the upper S-trap. Then install a sanitary T, going to: AAV (top) and P-trap (horizontal). Does that sound right?\n",
      "\n",
      "Cluster = 4, Raw data index = 31,500, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I have read a lot about proper insulation and ventilation, including some posts on this site, but none adequately answer my questions.My goal is to operate an electric heat source in the winter and have ~60 &deg;F temperature maintained when working in the garage.  In the summer, I think we will typically leave the garage door open, however it would be nice to one day have it stay cool in there if it's 90-100 &deg;F outside.This is in Ohio, where we typically have temps of 0-95 &deg;F throughout the year, it can also get pretty humid.I do not have soffit vents, but there is a ridge vent on the roof already installed.  I do not want to drywall nor do I want to build a ceiling.As you see in the photos I have already insulated the walls with R15 Batt installation.  Now I'm unsure where to go from here for roof 2x6's.  I bought some radiant barrier R11-equivelent insulation (seen in photos as well), which I was planning to attach to the end of the 2x6's above, which leaves plenty of ventilation behind them, should be \"ok\" in the winter and pretty decent in the summer.  However, not having soffit vents, I'm unsure if that is the proper use-case.You'll see from the wall install that I have no concerns about a vapor barrier, and do not care to seal my garage 100% (I only got faced insulation because it was cheaper =)  ).  However, I am concerned about mold/moisture problems in the space.  I would love some feedback as to the proper way to proceed here.  Ideally I can make use of my radiant barriers, and ideally I won't have to cut in soffit vents.Full resolution images here for reference: http://imgur.com/a/4Wd9Q and http://imgur.com/a/ud8os\n",
      "\n",
      "Cluster = 4, Raw data index = 8,153, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "What's the best way for a DIY granite counter top to be cut?  What tools do I need that will do the job without breaking the bank?\n",
      "\n",
      "Cluster = 4, Raw data index = 6,644, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I'm remodeling my bathroom and shower and I'll be replacing the insulation on the external wall. This wall is the \"back\" of the shower (opposite from where the water supply lines are). With this in mind, I should be able to just choose some insulation and then plop it in when I have the wall torn down.The main question and concern I have is about vapor barrier. I will be using cement board with a liquid topical membrane (like Redgard) for waterproofing the shower which means I'm not supposed to put a vapor barrier on the back side of the wall because it is bad to trap moisture. How does this affect insulating? Am I safe to nix the vapor barrier around the shower? What should I do for the rest of the bathroom?I'm not too concerned with price so if there are other options besides batting insulation (such as foam, etc...) that would solve my problem, I'm willing to hear those ideas as well.\n",
      "\n",
      "Cluster = 4, Raw data index = 65,112, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I am doing some minor renovations to my basement with the drop ceiling and found that one of the geniuses that owned the house before me, used fibreglass ceiling tiles to seal off an old vent for a gas fireplace. Obviously this will not do. I'm thinking of building a section of 2x4's around the old exhaust and then filling it with rigid foam and spray foam. I can't take the old exhaust off the side of the house, since it is a condo and I doubt that I'm going to convince them to replace the siding where this exhaust vent is, not to mention it will probably cost me. Open to any suggestions. I would post a pic but the settings don't allow it, kinda odd.\n",
      "\n",
      "Cluster 0: water, hot, heater, pressure, valve, tank, shower, cold, pipe, house\n",
      "Cluster 1: visa, passport, uk, schengen, us, travel, need, transit, days, visit\n",
      "Cluster 2: wire, switch, light, wires, breaker, box, fan, outlet, ground, lights\n",
      "Cluster 3: key, encryption, message, hash, public, aes, cipher, data, keys, random\n",
      "Cluster 4: wall, house, floor, door, would, wood, concrete, paint, like, room\n",
      "Cluster 5: would, like, one, know, use, get, time, make, find, way\n",
      "\n",
      "Cluster = 5, Raw data index = 15,061, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "It's always difficult to decide what clothes to take with you when you go to a new place. Usually I check Wikipedia to get an idea of approximate climate and weather conditions, but it often doesn't have much data besides average temperatures. Other factors, such as wind and precipitation, might enter into the equation, and the same temperature can \"feel like\" differently in two distinct locations.Perhaps not the same factors are important whether one travels to tropical/equatorial locations, or to temperate/subarctic places.So, in short:  If I travel to a new place, which weather factors should I look into to decide what to take with me?\n",
      "\n",
      "Cluster = 5, Raw data index = 65,232, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I see the TSA have brought in new rules for devices, in response to intelligence that terrorists may be trying to pack mobile phones with explosive, so checks before flights can include having to prove the device can power on.Although fearing the worst and allowing lots of extra time at airports, I have not yet encountered any checks of this sort over and above the usual taking devices out of bags so they can be scanned separately.From various news articles, there doesn't appear to be any consistent view as to what checks will be carried out.Can anyone here clarify what they do? Do you have to prove a phone can make a call, or just show it is powered on?\n",
      "\n",
      "Cluster = 5, Raw data index = 6,061, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "I'm planning to visit Medellin and Bogota sometime in the near future. I've a U.S. DL which endorses motorcycles. Is it legal to ride motorcycles in Colombia with a US driver's license? Is it required to carry any other identification other than the U.S. DL in case if I'm on the road?\n",
      "\n",
      "Cluster = 5, Raw data index = 11,890, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "The way I currently cook kidney beans is to soak them overnight. But still they have to be cooked for a long time on gas before they get tender enough to be edible.Anything that can be added or be done in a different way to reduce the time over heat?\n",
      "\n",
      "Cluster = 5, Raw data index = 57,730, Hyper-Parameters = {'clusterer__max_iter': 750, 'clusterer__n_clusters': 6, 'clusterer__n_init': 10, 'vectorizer__max_df': 0.75, 'vectorizer__min_df': 50}\n",
      "To quote Goodman &amp; Gilman :  An alternative way of defining the anesthetic state is to consider it  as a collection of “component” changes in behavior or perception. The  components of the anesthetic state include:  • amnesia  • immobility in  response to noxious stimulation  • attenuation of autonomic responses  to noxious stimulation  • analgesia  • unconsciousnessMy question is, does not the state of Unconsciousness already imply other components of analgesia and amnesia? Analgesia is the absence of the perception of pain, which is granted if there is unconsciousness which would be the absence of all perceptions. I am not certain if unconsciousness also entails amnesia, but it seems that remembering what happened when unconscious seems considerably unlikely.  Apart from a reductionist argument for minimizing the constraints required for classification as a general anesthetic, I am more interested in cases where unconsciousness would be achieved without analgesia or amnesia, which could be a likely rationale behind including the additional caveats in the definition.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs_str, posts_str = [state.result()[k].result() for k in range(2)]\n",
    "df_flow_output = pd.read_json(dfs_str, orient=\"split\")\n",
    "with pd.option_context(\"display.max_colwidth\", 100):\n",
    "    display(df_flow_output)\n",
    "print(posts_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145c7d4-3e76-47a5-9829-40c09392a43b",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e1b7b-925c-40bf-8397-1590bd870909",
   "metadata": {},
   "source": [
    "Accomplished\n",
    "1. Used ML to cluster stackexchange posts using text of the post\n",
    "2. Read through the posts in each cluster and Assigned names to each cluster\n",
    "   - most clusters' posts covered a single topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde976f0-d0cf-4b9d-9924-9b160188483b",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90918a48-495a-4169-9a02-e8b95088b646",
   "metadata": {},
   "source": [
    "Looking Forward\n",
    "1. Iterate over more hyper-parameters of the text vectorizer (TFIDF)\n",
    "2. Text Pre-processing (stemming)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
